{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of features and test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What do you want to test?  \n",
    "2) Integration or unit test?  \n",
    "3) Structure of test case - \n",
    "    + Create inputs\n",
    "    + Invoke the code to be tested\n",
    "    + Compare the output\n",
    "4) Handling expected failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get started with unit tests  \n",
    "1) **Dope**  \n",
    "2) Registry  \n",
    "3) **Algorithms in arch/sklearn**  \n",
    "4) get_best_model from optimizers/tune  \n",
    "5) **classes from adapters**  \n",
    "6) **layers and losses**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cases for Dope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Inputs -- primal_model, abstract_model, adapter  \n",
    " - Behaviour -- When provided with primal_model or abstract+adapter, \n",
    "   dope should provide a mapped dnn model.\n",
    " - mapped dnn model\n",
    " - Test expected failure cases as well\n",
    " \n",
    "1) Test if all existing algorithms are supported by dope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cases for Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Compare `predict` values from primal and proxy  \n",
    "    + Different variations and combinations\n",
    "2) Generic config checks  \n",
    "3) **Adding failure cases**  \n",
    "4) Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-07-26 12:02:58,032\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-26_12-02-58_7151/logs.\n",
      "2019-07-26 12:02:58,146\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:28265 to respond...\n",
      "2019-07-26 12:02:58,259\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:44235 to respond...\n",
      "2019-07-26 12:02:58,261\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-07-26 12:02:58,300\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    }
   ],
   "source": [
    "from mlsquare import dope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"../data/iris.csv\"\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2019-07-26 12:02:59,453\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-07-26 12:02:59,454\tINFO tune.py:211 -- Starting a new experiment.\n",
      "2019-07-26 12:02:59,634\tWARNING util.py:62 -- The `start_trial` operation took 0.17476582527160645 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.4/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.4/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m 2019-07-26 12:03:01,974\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m epochs ---  500\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m 2019-07-26 12:03:02.722376: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m 2019-07-26 12:03:02.730533: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m 2019-07-26 12:03:02.731121: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a4d3b219d0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m 2019-07-26 12:03:02.731135: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-26 12:03:03,639\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''sigmoid'', ''optimizer'': ''adam'', ''loss'': ''binary_crossentropy''}.h5'\n",
      "  date: 2019-07-26_12-03-03\n",
      "  done: false\n",
      "  experiment_id: b93712234d8b4550a6775c2f454d6d46\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 1.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 7443\n",
      "  time_since_restore: 1.4653124809265137\n",
      "  time_this_iter_s: 1.4653124809265137\n",
      "  time_total_s: 1.4653124809265137\n",
      "  timestamp: 1564122783\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m 32/40 [=======================>......] - ETA: \n",
      "\u001b[2m\u001b[36m(pid=7443)\u001b[0m 40/40 [==============================] - 0s 409us/step\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.6/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - train_model_0:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=7443], 1 s, 1 iter, 1 acc\n",
      "\n",
      "Creating model...\n",
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_2019-07-26_12-02-59834ddwq_/weights_tune_{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'sigmoid', 'optimizer': 'adam', 'loss': 'binary_crossentropy'}.h5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlsquare import dope\n",
    "\n",
    "model = LogisticRegression()\n",
    "m = dope(model)\n",
    "trained_model = m.fit(x_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 7.\n"
     ]
    }
   ],
   "source": [
    "m.save('test_onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/onnx_tf/common/__init__.py:87: UserWarning: onnx_tf.common.get_outputs_names is deprecated. It will be removed in future release. Use TensorflowGraph.get_outputs_names instead.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model = onnx.load(\"test_onnx.onnx\")  # load onnx model\n",
    "# output = prepare(onnx_model).run(x_test)  # run the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "sess = onnxruntime.InferenceSession('test_onnx.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input name  : dense_2_input_0\n",
      "Input shape : [1, 4]\n",
      "Input type  : tensor(float)\n"
     ]
    }
   ],
   "source": [
    "input_name = sess.get_inputs()[0].name\n",
    "print(\"Input name  :\", input_name)\n",
    "input_shape = sess.get_inputs()[0].shape\n",
    "print(\"Input shape :\", input_shape)\n",
    "input_type = sess.get_inputs()[0].type\n",
    "print(\"Input type  :\", input_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output name  : dense_2_Sigmoid_01\n",
      "Output shape : [1, 1]\n",
      "Output type  : tensor(float)\n"
     ]
    }
   ],
   "source": [
    "output_name = sess.get_outputs()[0].name\n",
    "print(\"Output name  :\", output_name)  \n",
    "output_shape = sess.get_outputs()[0].shape\n",
    "print(\"Output shape :\", output_shape)\n",
    "output_type = sess.get_outputs()[0].type\n",
    "print(\"Output type  :\", output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5. , 3.4, 1.6, 0.4],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [6.9, 3.1, 4.9, 1.5]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x = x_test.values\n",
    "_x = _x.astype(np.float32)\n",
    "_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sess.run([output_name], {input_name: _x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (result[0]>0.6).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = trained_model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((4,5)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=3.0, pvalue=1.0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.chisquare(a.reshape(60)+1,b.reshape(60)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=1.0, pvalue=1.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "pred1 = model.predict(x_test)\n",
    "\n",
    "pred2 = m.final_model.predict_classes(x_test)\n",
    "pred2 = pred2.reshape(60,)\n",
    "pred2 = pred2.astype('int64')\n",
    "pred2 += 1\n",
    "pred1 += 1\n",
    "# pred1 = pred1.astype('float64')\n",
    "stats.chisquare(pred2,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.stats._continuous_distns.chi2_gen at 0x7fa4a31ace80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats.chisquare([16, 8, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8])\n",
    "stats.chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function scipy.stats.stats.chisquare(f_obs, f_exp=None, ddof=0, axis=0)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-24 08:51:30,913\tERROR worker.py:1780 -- The node with client ID 3520b7657a79686fc9725a17b83b1a64c7cf3c14 has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m E0724 08:51:39.482097  9441 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m E0724 08:51:39.482125  9450 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m E0724 08:51:39.482096  9448 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=9381)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=9379)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=9378)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n"
     ]
    }
   ],
   "source": [
    "stats.chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-3.9995108708727924, pvalue=7.308240219166128e-05)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.random.seed(12345678) \n",
    "\n",
    "rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
    "rvs2 = (stats.norm.rvs(loc=5,scale=10,size=500) +\n",
    "        stats.norm.rvs(scale=0.2,size=500))\n",
    "stats.ttest_rel(rvs1,rvs2)\n",
    "\n",
    "rvs3 = (stats.norm.rvs(loc=8,scale=10,size=500) +\n",
    "        stats.norm.rvs(scale=0.2,size=500))\n",
    "stats.ttest_rel(rvs1,rvs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rvs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvs2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.imly import registry\n",
    "\n",
    "model_skeleton, _ = registry[('sklearn', 'LogisticRegression')]['default']\n",
    "default_params = model_skeleton.get_params()\n",
    "test_params = {'new_param1': 1, 'new_param2':2}\n",
    "model_skeleton.update_params(test_params)\n",
    "# default_params.update(test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1.units': 1,\n",
       " 'layer_1.l1': 0,\n",
       " 'layer_1.l2': 0,\n",
       " 'layer_1.activation': 'sigmoid',\n",
       " 'optimizer': 'adam',\n",
       " 'loss': 'binary_crossentropy',\n",
       " 'new_param1': 1,\n",
       " 'new_param2': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_params.update(test_params)\n",
    "default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-20 09:45:37,552\tERROR worker.py:1780 -- The node with client ID 72d68030b26203cb162235b3e84dbbd45686f8e5 has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m E0720 09:45:45.979614 28555 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=28489)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m E0720 09:45:45.983363 28556 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=28487)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m E0720 09:45:45.976848 28560 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=28488)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m E0720 09:45:45.970896 28558 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=28486)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ray_import_thread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/redis/connection.py\", line 182, in _read_from_socket\n",
      "    data = recv(self._sock, socket_read_size)\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/redis/_compat.py\", line 58, in recv\n",
      "    return sock.recv(*args, **kwargs)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/import_thread.py\", line 70, in _run\n",
      "    msg = import_pubsub_client.get_message()\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/redis/client.py\", line 3135, in get_message\n",
      "    response = self.parse_response(block=False, timeout=timeout)\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/redis/client.py\", line 3036, in parse_response\n",
      "    return self._execute(connection, connection.read_response)\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/redis/client.py\", line 3013, in _execute\n",
      "    return command(*args)\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/redis/connection.py\", line 637, in read_response\n",
      "    response = self._parser.read_response()\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/redis/connection.py\", line 290, in read_response\n",
      "    response = self._buffer.readline()\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/redis/connection.py\", line 224, in readline\n",
      "    self._read_from_socket()\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/redis/connection.py\", line 199, in _read_from_socket\n",
      "    (e.args,))\n",
      "redis.exceptions.ConnectionError: Error while reading from socket: (104, 'Connection reset by peer')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_skeleton.get_params() == default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
    "\n",
    "rvs1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    }
   ],
   "source": [
    "from mlsquare import dope\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "model = LinearRegression()\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "Y = diabetes.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "m = dope(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-22 17:49:46,466\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-07-22 17:49:46,467\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.2/8.2 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-22 17:49:49,715\tWARNING util.py:62 -- The `start_trial` operation took 3.2396037578582764 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.2/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m 2019-07-22 17:52:46,724\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m epochs ---  250\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m 2019-07-22 17:53:49.574396: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m 2019-07-22 17:53:51.644516: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m 2019-07-22 17:53:51.646808: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5586e2a33be0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m 2019-07-22 17:53:51.646845: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m  32/176 [====>.........................] - ETA: \n",
      "\u001b[2m\u001b[36m(pid=27081)\u001b[0m 176/176 [==============================] - 0s 115us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-22 17:54:01,414\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''linear'', ''optimizer'': ''adam'', ''loss'': ''mse''}.h5'\n",
      "  date: 2019-07-22_17-54-01\n",
      "  done: false\n",
      "  experiment_id: 66077dd556fb4b198cc914a98f3a597a\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 27081\n",
      "  time_since_restore: 20.23278260231018\n",
      "  time_this_iter_s: 20.23278260231018\n",
      "  time_total_s: 20.23278260231018\n",
      "  timestamp: 1563798241\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.5/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING, [4 CPUs, 0 GPUs], [pid=27081], 20 s, 1 iter, 0 acc\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.5/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - train_model_0:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=27081], 20 s, 1 iter, 0 acc\n",
      "\n",
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_2019-07-22_17-49-46nwoa63x1/weights_tune_{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse'}.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f3338938f28>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-45.95922634383876, pvalue=2.920898371717077e-128)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "pred1 = model.predict(x_test)\n",
    "\n",
    "pred2 = m.final_model.predict_classes(x_test)\n",
    "pred2 = pred2.reshape(266,)\n",
    "# pred2 = pred2.astype('float64')\n",
    "# pred1 = pred1.astype('float64')\n",
    "stats.ttest_rel(pred2,pred1, nan_policy='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mlsquare import registry\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "mock_model, _ = registry[('sklearn', 'DecisionTreeClassifier')]['default']\n",
    "mock_model.y = np.array([[0,1], [0,1]])\n",
    "mock_model.X = np.array([[0,1], [0,1]])\n",
    "# y_train = to_categorical(y_train)\n",
    "primal = DecisionTreeClassifier()\n",
    "primal.fit(x_train, y_train)\n",
    "mock_model.primal = primal\n",
    "keras_model = mock_model.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Model type `<class 'sklearn.tree.tree.DecisionTreeClassifier'>` is not supported by mlsquare yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/mlsquare-core/mlsquare/src/mlsquare/core.py\u001b[0m in \u001b[0;36mdope\u001b[0;34m(primal_model, abstract_model, adapter, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mabstract_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_version\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'random'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fe22cbdb8c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmlsquare\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdope\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'random'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# # UserWarning('aa')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# import sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mlsquare-core/mlsquare/src/mlsquare/core.py\u001b[0m in \u001b[0;36mdope\u001b[0;34m(primal_model, abstract_model, adapter, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mabstract_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_version\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model type `%s` is not supported by mlsquare yet.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transpiling your model to it's Deep Neural Network equivalent...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Model type `<class 'sklearn.tree.tree.DecisionTreeClassifier'>` is not supported by mlsquare yet."
     ]
    }
   ],
   "source": [
    "from mlsquare import dope\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dope(DecisionTreeClassifier(), version='random')\n",
    "# # UserWarning('aa')\n",
    "# import sys\n",
    "# print('bkah ', file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlsquare import registry, dope\n",
    "model = LogisticRegression()\n",
    "abstract_model, adapter = registry[('sklearn', 'LogisticRegression')]['default']\n",
    "m = dope(model, abstract_model=abstract_model, adapt=adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dope' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8db60199bde1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ddd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dope' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "dope('ddd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on sklearn/numpy test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- t test\n",
    "   + Can ttest be used \n",
    "- chi square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-08-07 17:44:25,666\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-08-07_17-44-25_11428/logs.\n",
      "2019-08-07 17:44:25,773\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:35625 to respond...\n",
      "2019-08-07 17:44:25,893\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:63716 to respond...\n",
      "2019-08-07 17:44:25,900\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-08-07 17:44:25,918\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    }
   ],
   "source": [
    "import mlsquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('sklearn', 'LogisticRegression'), ('sklearn', 'LinearRegression'), ('sklearn', 'Ridge'), ('sklearn', 'Lasso'), ('sklearn', 'ElasticNet'), ('sklearn', 'LinearSVC'), ('sklearn', 'SVC'), ('sklearn', 'DecisionTreeClassifier')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-08 09:11:04,101\tERROR worker.py:1780 -- The node with client ID 11693efe1e3e3b3fd96d4413a026d8017cbb80cf has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=11470)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=11471)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=11473)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=11472)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n"
     ]
    }
   ],
   "source": [
    "mlsquare.registry.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.imly import dope\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression()\n",
    "m = dope(model)\n",
    "\n",
    "hasattr(m, 'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.imly import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, adapter = registry[('sklearn', 'LogisticRegression')]['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SklearnKerasClassifier'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test():\n",
    "    def __getitem__(self,x):\n",
    "        pass\n",
    "testtt= test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Container\n",
    "isinstance(testtt, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    }
   ],
   "source": [
    "from mlsquare import dope\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "m = dope(model)\n",
    "# m.save('testing_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r\"test_onnx.pkl\", \"rb\") as input_file:\n",
    "        e = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Sequential in module keras.engine.sequential object:\n",
      "\n",
      "class Sequential(keras.engine.training.Model)\n",
      " |  Linear stack of layers.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      layers: list of layers to add to the model.\n",
      " |  \n",
      " |  # Example\n",
      " |  \n",
      " |  ```python\n",
      " |  # Optionally, the first layer can receive an `input_shape` argument:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(500,)))\n",
      " |  \n",
      " |  # Afterwards, we do automatic shape inference:\n",
      " |  model.add(Dense(32))\n",
      " |  \n",
      " |  # This is identical to the following:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_dim=500))\n",
      " |  \n",
      " |  # And to the following:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, batch_input_shape=(None, 500)))\n",
      " |  \n",
      " |  # Note that you can also omit the `input_shape` argument:\n",
      " |  # In that case the model gets built the first time you call `fit` (or other\n",
      " |  # training and evaluation methods).\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.compile(optimizer=optimizer, loss=loss)\n",
      " |  \n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  \n",
      " |  # Note that when using this delayed-build pattern\n",
      " |  # (no input shape specified),\n",
      " |  # the model doesn't have any weights until the first call\n",
      " |  # to a training/evaluation method (since it isn't yet built):\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.weights  # returns []\n",
      " |  \n",
      " |  # Whereas if you specify the input shape, the model gets built continuously\n",
      " |  # as you are adding layers:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(500,)))\n",
      " |  model.add(Dense(32))\n",
      " |  model.weights  # returns list of length 4\n",
      " |  \n",
      " |  # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  # choose to manually build your model by calling\n",
      " |  # `build(batch_input_shape)`:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.build((None, 500))\n",
      " |  model.weights  # returns list of length 4\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      keras.engine.training.Model\n",
      " |      keras.engine.network.Network\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      # Raises\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  predict_classes(self, x, batch_size=32, verbose=0)\n",
      " |      Generate class predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns:\n",
      " |          A numpy array of class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, batch_size=32, verbose=0)\n",
      " |      Generates class probability predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy array of probability predictions.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A model instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  model\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.training.Model:\n",
      " |  \n",
      " |  compile(self, optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          optimizer: String (name of optimizer) or optimizer instance.\n",
      " |              See [optimizers](/optimizers).\n",
      " |          loss: String (name of objective function) or objective function.\n",
      " |              See [losses](/losses).\n",
      " |              If the model has multiple outputs, you can use a different loss\n",
      " |              on each output by passing a dictionary or a list of losses.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model\n",
      " |              during training and testing.\n",
      " |              Typically you will use `metrics=['accuracy']`.\n",
      " |              To specify different metrics for different outputs of a\n",
      " |              multi-output model, you could also pass a dictionary,\n",
      " |              such as `metrics={'output_a': 'accuracy'}`.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions\n",
      " |              of different model outputs.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the *weighted sum* of all individual losses,\n",
      " |              weighted by the `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping\n",
      " |              to the model's outputs. If a tensor, it is expected to map\n",
      " |              output names (strings) to scalar coefficients.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          target_tensors: By default, Keras will create placeholders for the\n",
      " |              model's target, which will be fed with the target data during\n",
      " |              training. If instead you would like to use your own\n",
      " |              target tensors (in turn, Keras will not expect external\n",
      " |              Numpy data for these targets at training time), you\n",
      " |              can specify them via the `target_tensors` argument. It can be\n",
      " |              a single tensor (for a single-output model), a list of tensors,\n",
      " |              or a dict mapping output names to target tensors.\n",
      " |          **kwargs: When using the Theano/CNTK backends, these arguments\n",
      " |              are passed into `K.function`.\n",
      " |              When using the TensorFlow backend,\n",
      " |              these arguments are passed into `tf.Session.run`.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of test data (if the model has a single input),\n",
      " |              or list of Numpy arrays (if the model has multiple inputs).\n",
      " |              If input layers in the model are named, you can also pass a\n",
      " |              dictionary mapping input names to Numpy arrays.\n",
      " |              `x` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Numpy array of target (label) data\n",
      " |              (if the model has a single output),\n",
      " |              or list of Numpy arrays (if the model has multiple outputs).\n",
      " |              If output layers in the model are named, you can also pass a\n",
      " |              dictionary mapping output names to Numpy arrays.\n",
      " |              `y` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per evaluation step.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |          verbose: 0 or 1. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the test samples, used for weighting the loss function.\n",
      " |              You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring the evaluation round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data\n",
      " |      as accepted by `test_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding tuples (inputs, targets)\n",
      " |              or (inputs, targets, sample_weights)\n",
      " |              or an instance of Sequence (keras.utils.Sequence)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          max_queue_size: maximum size for the generator queue\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: if True, use process based threading.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs)\n",
      " |      Trains the model for a given number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of training data (if the model has a single input),\n",
      " |              or list of Numpy arrays (if the model has multiple inputs).\n",
      " |              If input layers in the model are named, you can also pass a\n",
      " |              dictionary mapping input names to Numpy arrays.\n",
      " |              `x` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Numpy array of target (label) data\n",
      " |              (if the model has a single output),\n",
      " |              or list of Numpy arrays (if the model has multiple outputs).\n",
      " |              If output layers in the model are named, you can also pass a\n",
      " |              dictionary mapping output names to Numpy arrays.\n",
      " |              `y` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling.\n",
      " |          validation_data: tuple `(x_val, y_val)` or tuple\n",
      " |              `(x_val, y_val, val_sample_weights)` on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch').\n",
      " |              'batch' is a special option for dealing with the\n",
      " |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined.\n",
      " |          validation_steps: Only relevant if `steps_per_epoch`\n",
      " |              is specified. Total number of steps (batches of samples)\n",
      " |              to validate before stopping.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Trains the model on data generated batch-by-batch by a Python generator\n",
      " |      (or an instance of `Sequence`).\n",
      " |      \n",
      " |      The generator is run in parallel to the model, for efficiency.\n",
      " |      For instance, this allows you to do real-time data augmentation\n",
      " |      on images on CPU in parallel to training your model on GPU.\n",
      " |      \n",
      " |      The use of `keras.utils.Sequence` guarantees the ordering\n",
      " |      and guarantees the single use of every input per epoch when\n",
      " |      using `use_multiprocessing=True`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: A generator or an instance of `Sequence`\n",
      " |              (`keras.utils.Sequence`) object in order to avoid\n",
      " |              duplicate data when using multiprocessing.\n",
      " |              The output of the generator must be either\n",
      " |              - a tuple `(inputs, targets)`\n",
      " |              - a tuple `(inputs, targets, sample_weights)`.\n",
      " |              This tuple (a single output of the generator) makes a single\n",
      " |              batch. Therefore, all arrays in this tuple must have the same\n",
      " |              length (equal to the size of this batch). Different batches may\n",
      " |              have different sizes. For example, the last batch of the epoch\n",
      " |              is commonly smaller than the others, if the size of the dataset\n",
      " |              is not divisible by the batch size.\n",
      " |              The generator is expected to loop over its data\n",
      " |              indefinitely. An epoch finishes when `steps_per_epoch`\n",
      " |              batches have been seen by the model.\n",
      " |          steps_per_epoch: Integer.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before declaring one epoch\n",
      " |              finished and starting the next epoch. It should typically\n",
      " |              be equal to the number of samples of your dataset\n",
      " |              divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire data provided,\n",
      " |              as defined by `steps_per_epoch`.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_data: This can be either\n",
      " |              - a generator or a `Sequence` object for the validation data\n",
      " |              - tuple `(x_val, y_val)`\n",
      " |              - tuple `(x_val, y_val, val_sample_weights)`\n",
      " |              on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |          validation_steps: Only relevant if `validation_data`\n",
      " |              is a generator. Total number of steps (batches of samples)\n",
      " |              to yield from `validation_data` generator before stopping\n",
      " |              at the end of every epoch. It should typically\n",
      " |              be equal to the number of samples of your\n",
      " |              validation dataset divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(validation_data)` as a number of steps.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only). This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples\n",
      " |              from an under-represented class.\n",
      " |          max_queue_size: Integer. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation\n",
      " |              relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          shuffle: Boolean. Whether to shuffle the order of the batches at\n",
      " |              the beginning of each epoch. Only used with instances\n",
      " |              of `Sequence` (`keras.utils.Sequence`).\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |      def generate_arrays_from_file(path):\n",
      " |          while True:\n",
      " |              with open(path) as f:\n",
      " |                  for line in f:\n",
      " |                      # create numpy arrays of input data\n",
      " |                      # and labels, from each line in the file\n",
      " |                      x1, x2, y = process_line(line)\n",
      " |                      yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
      " |      \n",
      " |      model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      " |                          steps_per_epoch=10000, epochs=10)\n",
      " |      ```\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: The input data, as a Numpy array\n",
      " |              (or list of Numpy arrays if the model has multiple inputs).\n",
      " |          batch_size: Integer. If unspecified, it will default to 32.\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data as accepted by\n",
      " |      `predict_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding batches of input samples\n",
      " |              or an instance of Sequence (keras.utils.Sequence)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          max_queue_size: Maximum size for the generator queue.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: If `True`, use process based threading.\n",
      " |              Note that because\n",
      " |              this implementation relies on multiprocessing,\n",
      " |              you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed\n",
      " |              easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case the generator yields\n",
      " |              data in an invalid format.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Input samples, as a Numpy array.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Numpy array(s) of predictions.\n",
      " |  \n",
      " |  test_on_batch(self, x, y, sample_weight=None)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of test data,\n",
      " |              or list of Numpy arrays if the model has multiple inputs.\n",
      " |              If all inputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping input names to Numpy arrays.\n",
      " |          y: Numpy array of target data,\n",
      " |              or list of Numpy arrays if the model has multiple outputs.\n",
      " |              If all outputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping output names to Numpy arrays.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile().\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  train_on_batch(self, x, y, sample_weight=None, class_weight=None)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of training data,\n",
      " |              or list of Numpy arrays if the model has multiple inputs.\n",
      " |              If all inputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping input names to Numpy arrays.\n",
      " |          y: Numpy array of target data,\n",
      " |              or list of Numpy arrays if the model has multiple outputs.\n",
      " |              If all outputs in the model are named,\n",
      " |              you can also pass a dictionary\n",
      " |              mapping output names to Numpy arrays.\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile().\n",
      " |          class_weight: Optional dictionary mapping\n",
      " |              class indices (integers) to\n",
      " |              a weight (float) to apply to the model's loss for the samples\n",
      " |              from this class during training.\n",
      " |              This can be useful to tell the model to \"pay more attention\" to\n",
      " |              samples from an under-represented class.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.network.Network:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  call(self, inputs, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      A model is callable on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      \n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False)\n",
      " |      Loads all layer weights from a HDF5 save file.\n",
      " |      \n",
      " |      If `by_name` is False (default) weights are loaded\n",
      " |      based on the network's topology, meaning the architecture\n",
      " |      should be the same as when the weights were saved.\n",
      " |      Note that layers that don't have weights are not taken\n",
      " |      into account in the topological ordering, so adding or\n",
      " |      removing layers is fine as long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers\n",
      " |      only if they share the same name. This is useful\n",
      " |      for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the weights file to load.\n",
      " |          by_name: Boolean, whether to load weights by name\n",
      " |              or by topological order.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers\n",
      " |              where there is a mismatch in the number of weights,\n",
      " |              or a mismatch in the shape of the weight\n",
      " |              (only valid when `by_name`=True).\n",
      " |          reshape: Reshape weights to fit the layer when the correct number\n",
      " |              of weight arrays is present but their shape does not match.\n",
      " |      \n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  run_internal_graph(self, inputs, masks=None)\n",
      " |      Computes output tensors for new inputs.\n",
      " |      \n",
      " |      # Note:\n",
      " |          - Expects `inputs` to be a list (potentially with 1 element).\n",
      " |          - Can be run on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: List of tensors\n",
      " |          masks: List of masks (tensors or None).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Three lists: output_tensors, output_masks, output_shapes\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True)\n",
      " |      Saves the model to a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model`\n",
      " |      is a compiled model ready to be used (unless the saved model\n",
      " |      was never compiled in the first place).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True)\n",
      " |      Dumps all layer weights to a HDF5 file.\n",
      " |      \n",
      " |      The weight file has:\n",
      " |          - `layer_names` (attribute), a list of strings\n",
      " |              (ordered names of model layers).\n",
      " |          - For every layer, a `group` named `layer.name`\n",
      " |              - For every such layer group, a group attribute `weight_names`,\n",
      " |                  a list of strings\n",
      " |                  (ordered names of weights tensor of the layer).\n",
      " |              - For every weight in the layer, a dataset\n",
      " |                  storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the model.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: A list of Numpy arrays with shapes and types matching\n",
      " |              the output of `model.get_weights()`.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |              It defaults to `print` (prints to stdout).\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A YAML string.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.network.Network:\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the model's input specs.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  losses\n",
      " |      Retrieves the model's losses.\n",
      " |      \n",
      " |      Will only include losses that are either\n",
      " |      unconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include losses that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of loss tensors.\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |      Retrieves the model's updates.\n",
      " |      \n",
      " |      Will only include updates that are either\n",
      " |      unconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include updates that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  uses_learning_phase\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"testing_pickle.obj\",'r')\n",
    "object_file = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data1 = {'a': [1, 2.0, 3, 4+6j],\n",
    "         'b': ('string', u'Unicode string'),\n",
    "         'c': None}\n",
    "\n",
    "selfref_list = [1, 2, 3]\n",
    "selfref_list.append(selfref_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, [...]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfref_list[3][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('data.pkl', 'wb')\n",
    "\n",
    "# Pickle dictionary using protocol 0.\n",
    "pickle.dump(data1, output)\n",
    "\n",
    "# Pickle the list using the highest protocol available.\n",
    "pickle.dump(selfref_list, output, -1)\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1, 2.0, 3, (4+6j)], 'b': ('string', 'Unicode string'), 'c': None}\n"
     ]
    }
   ],
   "source": [
    "import pprint, pickle\n",
    "\n",
    "pkl_file = open('data.pkl', 'rb')\n",
    "\n",
    "data1 = pickle.load(pkl_file)\n",
    "pprint.pprint(data1)\n",
    "\n",
    "data2 = pickle.load(pkl_file)\n",
    "pprint.pprint(data2)\n",
    "\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-08-12 18:22:36,398\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-08-12_18-22-36_659/logs.\n",
      "2019-08-12 18:22:36,518\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:14380 to respond...\n",
      "2019-08-12 18:22:36,640\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:11421 to respond...\n",
      "2019-08-12 18:22:36,642\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-08-12 18:22:36,676\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    }
   ],
   "source": [
    "from mlsquare import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_model,_ = registry[('sklearn', 'LogisticRegression')]['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlsquare.architectures.sklearn.LogisticRegression at 0x7fef46f3f8d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'mlsquare.architectures.sklearn.LogisticRegression'>: it's not the same object as mlsquare.architectures.sklearn.LogisticRegression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5b85624ea136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'proxy_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'mlsquare.architectures.sklearn.LogisticRegression'>: it's not the same object as mlsquare.architectures.sklearn.LogisticRegression"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_details = open('proxy_data.pkl', 'wb')\n",
    " \n",
    "pickle.dump(proxy_model, file_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pickle' from '/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/pickle.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-13 11:33:17,542\tERROR worker.py:1780 -- The node with client ID cb0653dd5111d5c5f2793a66cb612bbb2a266b5d has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=708)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=710)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=711)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=709)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n"
     ]
    }
   ],
   "source": [
    "pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'mlsquare.architectures.sklearn.LogisticRegression'>: it's not the same object as mlsquare.architectures.sklearn.LogisticRegression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4bd8c885f2a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfile_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'proxy_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/test_imly/lib/python3.6/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol, byref, fmode, recurse)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mpik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# clear record of 'recursion-sensitive' pickled objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_imly/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_imly/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_imly/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, obj)\u001b[0m\n\u001b[1;32m    603\u001b[0m                     \"args[0] from __newobj__ args has the wrong class\")\n\u001b[1;32m    604\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNEWOBJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_imly/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_imly/lib/python3.6/site-packages/dill/_dill.py\u001b[0m in \u001b[0;36msave_type\u001b[0;34m(pickler, obj)\u001b[0m\n\u001b[1;32m   1336\u001b[0m        \u001b[0;31m#print (\"%s\\n%s\" % (type(obj), obj.__name__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m        \u001b[0;31m#print (\"%s\\n%s\" % (obj.__bases__, obj.__dict__))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m         \u001b[0mStockPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"# T4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_imly/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36msave_global\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m    925\u001b[0m                 raise PicklingError(\n\u001b[1;32m    926\u001b[0m                     \u001b[0;34m\"Can't pickle %r: it's not the same object as %s.%s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m                     (obj, module_name, name))\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'mlsquare.architectures.sklearn.LogisticRegression'>: it's not the same object as mlsquare.architectures.sklearn.LogisticRegression"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-12 16:38:49,922\tERROR worker.py:1780 -- The node with client ID 29f30a409e46e024b27fc22f7993d98d38d2c78f has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=29482)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=29485)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=29484)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=29483)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "file_details = open('proxy_data.pkl', 'wb')\n",
    " \n",
    "pickle.dump(proxy_model, file_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self):\n",
    "        # self.adapter = SklearnKerasClassifier\n",
    "        self.module_name = 'sklearn'  # Rename the variable\n",
    "        self.name = 'LogisticRegression'\n",
    "        self.version = 'default'\n",
    "        model_params = {'layer_1': {'units': 1, ## Make key name private - '_layer'\n",
    "                                    'l1': 0,\n",
    "                                    'l2': 0,\n",
    "                                    'activation': 'sigmoid'},\n",
    "                        'optimizer': 'adam',\n",
    "                        'loss': 'binary_crossentropy'\n",
    "                        }\n",
    "        self.set_params(params=model_params, set_by='model_init')\n",
    "        \n",
    "    def set_params(self, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_instance = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.LogisticRegression"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lr_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlsquare.architectures.sklearn.LogisticRegression"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(proxy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'mlsquare.architectures.sklearn.LogisticRegression'>: it's not the same object as mlsquare.architectures.sklearn.LogisticRegression",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9dab82c834bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'proxy_data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfile_details\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'mlsquare.architectures.sklearn.LogisticRegression'>: it's not the same object as mlsquare.architectures.sklearn.LogisticRegression"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "file_details = open('proxy_data.pkl', 'wb')\n",
    " \n",
    "pickle.dump(proxy_model, file_details)\n",
    "file_details.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_details = open('proxy_data.pkl', 'rb')\n",
    "\n",
    "loaded_data = pickle.load(file_details)\n",
    "\n",
    "file_details.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LogisticRegression in module __main__ object:\n",
      "\n",
      "class LogisticRegression(builtins.object)\n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  set_params(self, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __slotnames__ = []\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(loaded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = getattr(proxy_model, '__qualname__', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-13eccafe5393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "name = proxy_model.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "269.583px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
