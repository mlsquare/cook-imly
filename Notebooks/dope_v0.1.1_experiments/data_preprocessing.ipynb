{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Steps #####\n",
    "\n",
    "1. Detect and Load dataset\n",
    "2. Keras\n",
    "3. Scikit\n",
    "4. Kfold\n",
    "5. ROC curve\n",
    "6. Classification report\n",
    "7. Write back the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detecting and loading data #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('../data/client_secret.json', scope)\n",
    "\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "sh = gc.open('Dataset details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://s3.ap-south-1.amazonaws.com/mlsquare-datasets/iris.csv',\n",
       " 'params_dict': {'use_bias': 7,\n",
       "  'kernel_initializer': 8,\n",
       "  'bias_initializer': 9,\n",
       "  'kernel_regularizer': 10,\n",
       "  'bias_regularizer': 11,\n",
       "  'activity_regularizer': 12,\n",
       "  'kernel_constraint': 13,\n",
       "  'bias_constraint': 14,\n",
       "  'C': 15,\n",
       "  'class_weight': 16,\n",
       "  'dual': 17,\n",
       "  'fit_intercept': 18,\n",
       "  'intercept_scaling': 19,\n",
       "  'max_iter': 20,\n",
       "  'multi_class': 21,\n",
       "  'n_jobs': 22,\n",
       "  'penalty': 23,\n",
       "  'random_state': 24,\n",
       "  'solver': 25,\n",
       "  'tol': 26,\n",
       "  'verbose': 27,\n",
       "  'warm_start': 28},\n",
       " 'activation_function': 'Logistic regression',\n",
       " 'n_col': 4,\n",
       " 'p_col': 5,\n",
       " 'c_col': 6}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = \"UCI Iris\"\n",
    "import automation_script\n",
    "data_info = automation_script.get_url(dataset_name)\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info['params_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50 : 50'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data prep for iris dataset #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(data_info['url'], delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "n=data.shape[0]\n",
    "p=X.shape[1]\n",
    "\n",
    "unique,count = np.unique(Y,return_counts=True)\n",
    "class_distribution = str(count[0]) + \" : \" + str(count[1])\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'76.0 : 24.0'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data prep for Adult salary dataset #\n",
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "         'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "         'hours-per-week', 'native-country', 'target']\n",
    "data = pd.read_csv(data_url, delimiter=\",\", header=None, index_col=False,names=names)\n",
    "data = data[data[\"workclass\"] != \"?\"]\n",
    "data = data[data[\"occupation\"] != \"?\"]\n",
    "data = data[data[\"native-country\"] != \"?\"]\n",
    "\n",
    "# Convert categorical fields #\n",
    "categorical_col = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                   'relationship', 'race', 'sex', 'native-country', 'target']\n",
    "\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "feature_list = names[:14]\n",
    "# Test train split #\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['target']]\n",
    "\n",
    "# data.iloc[:,-1] = index\n",
    "# data = data.loc[data[4] != 2]\n",
    "# X = data.iloc[:,:-1]\n",
    "# Y = data.iloc[:,-1]\n",
    "n=data.shape[0]\n",
    "p=X.shape[1]\n",
    "\n",
    "unique,count = np.unique(Y,return_counts=True)\n",
    "class1=count[0]/data.shape[0]*100\n",
    "class2=count[1]/data.shape[0]*100\n",
    "class_distribution = str(round(class1)) + \" : \" + str(round(class2))\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# # Class1_distribution=Y[1].value_counts()[0] / Y.shape[0] * 100\n",
    "# # Class2_distribution=Y[1].value_counts()[1] / Y.shape[0] * 100\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Keras model #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 654us/step\n",
      "\n",
      "acc: 46.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0219178040822348, 0.4666666626930237]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Logistic regression using DNN ###\n",
    "config = {\n",
    "    'epoch': 200,\n",
    "    'batch_size': 100,\n",
    "    'model_info': {\n",
    "        'loss':'binary_crossentropy',\n",
    "        'optimizer':'adam',\n",
    "        'metrics':['accuracy']\n",
    "    }\n",
    "}\n",
    "\n",
    "score,keras_params = automation_script.get_keras_params(X,Y,data_info,config)\n",
    "print(score)\n",
    "print(keras_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model details to be added**\n",
    "1. Score/Accuracy\n",
    "2. bias_initializer\n",
    "3. kernel_regularizer\n",
    "4. bias_regularizer\n",
    "5. layer name\n",
    "6. use bias\n",
    "7. kernel initializer\n",
    "8. activity regularizer\n",
    "9. kernel constraint\n",
    "10. bias constraint\n",
    "\n",
    "*What do these values represent?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'dense_3',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None, 14),\n",
       " 'dtype': 'float32',\n",
       " 'units': 1,\n",
       " 'activation': 'sigmoid',\n",
       " 'use_bias': True,\n",
       " 'kernel_initializer': 'VarianceScaling',\n",
       " 'bias_initializer': 'Zeros',\n",
       " 'kernel_regularizer': None,\n",
       " 'bias_regularizer': None,\n",
       " 'activity_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'bias_constraint': None}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras_params = model.get_config()\n",
    "# keras_params = keras_params['layers'][0]['config']\n",
    "# keras_params['kernel_initializer'] = keras_params['kernel_initializer']['class_name']\n",
    "# keras_params['bias_initializer'] = keras_params['bias_initializer']['class_name']\n",
    "# keras_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scikit model #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0 {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Scikit learn #\n",
    "\n",
    "score, scikit_params = automation_script.get_scikit_params(X,Y)\n",
    "print(score, scikit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model details to collect #####\n",
    "1. All values returned by get_params method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit_params = logisticRegr.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing the values back to the sheet #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'ovr',\n",
       " 'n_jobs': 1,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1E5jcq2w42gN8bMIaeaRJpAdhgSVN-2XDJ_YTHe4qfwY',\n",
       " 'updatedRange': 'Sheet1!G4',\n",
       " 'updatedRows': 1,\n",
       " 'updatedColumns': 1,\n",
       " 'updatedCells': 1}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Steps #\n",
    "# 1. Read and figure out the relevant column and row\n",
    "# 2. Map the Keras/Scikit dicts with the columns and write to the corresponding cells\n",
    "# keras_params['layers']\n",
    "# scikit_params\n",
    "\n",
    "data = {\n",
    "    'params_dict': data_info['params_dict'],\n",
    "    'scikit_params': scikit_params,\n",
    "    'keras_params': keras_params,\n",
    "    'n_col': data_info['n_col'],\n",
    "    'p_col': data_info['p_col'],\n",
    "    'c_col': data_info['c_col'],\n",
    "    'row_nb': data_info['row_nb']\n",
    "}\n",
    "for param,col_nb in params_dict.items():\n",
    "    for s_param,value in scikit_params.items():\n",
    "        if param == s_param:\n",
    "            if value == None:\n",
    "                value = 'None'\n",
    "            worksheet.update_cell(row_nb+1, col_nb+1, value)\n",
    "            \n",
    "\n",
    "for param,col_nb in params_dict.items():\n",
    "    for k_param,value in keras_params.items():\n",
    "        if param == k_param:\n",
    "            if value == None:\n",
    "                value = 'None'\n",
    "            worksheet.update_cell(row_nb+1, col_nb+1, value)\n",
    "worksheet.update_cell(row_nb+1, n_col_nb, n)\n",
    "worksheet.update_cell(row_nb+1, p_col_nb, p)\n",
    "worksheet.update_cell(row_nb+1, c_col_nb, class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
