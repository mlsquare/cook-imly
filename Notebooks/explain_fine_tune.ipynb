{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.6, shuffle=True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will create and export the decision tree as a pdf\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left --     [ 1 -1  3  4 -1  6 -1  8 -1 10 -1 -1 13 14 -1 -1 -1]\n",
      "right --    [ 2 -1 12  5 -1  7 -1  9 -1 11 -1 -1 16 15 -1 -1 -1]\n",
      "features -- [ 3 -2  2  3 -2  1 -2  3 -2  0 -2 -2  0  0 -2 -2 -2]\n"
     ]
    }
   ],
   "source": [
    "print('left --    ',clf.tree_.children_left)\n",
    "print('right --   ',clf.tree_.children_right)\n",
    "print('features --',clf.tree_.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modified for decision feature prediction model\n",
    "\n",
    "left_nodes = clf.tree_.children_left[clf.tree_.children_left>0]\n",
    "right_nodes = clf.tree_.children_right[clf.tree_.children_right>0]\n",
    "node_indicator = clf.decision_path(X)\n",
    "path_list = []\n",
    "for i, j in enumerate(X):\n",
    "    path_list.append(node_indicator.indices[node_indicator.indptr[i]:node_indicator.indptr[i+1]])\n",
    "\n",
    "## Convert path to strings\n",
    "\n",
    "test_df = []\n",
    "# test_path = []\n",
    "# test_cut_feats = []\n",
    "path_column = []\n",
    "cuts_feat = []\n",
    "for i, j in enumerate(X):\n",
    "    path_as_string = []\n",
    "    for node in path_list[i]:\n",
    "        if node == 0:\n",
    "            path_as_string.append('S')\n",
    "            for val in X[i]:\n",
    "                test_df.append(val)\n",
    "            test_df.append(['S', 0])\n",
    "        elif node in left_nodes:\n",
    "            path_as_string.append('L')\n",
    "            for val in X[i]:\n",
    "                test_df.append(val)\n",
    "            if clf.tree_.feature[node] < 0:\n",
    "                test_df.append(['L', 0])\n",
    "            else:\n",
    "                test_df.append(['L', clf.tree_.feature[node]+1])\n",
    "        elif node in right_nodes:\n",
    "            path_as_string.append('R')\n",
    "            for val in X[i]:\n",
    "                test_df.append(val)\n",
    "            if clf.tree_.feature[node] < 0:\n",
    "                test_df.append(['R', 0])\n",
    "            else:\n",
    "                test_df.append(['R', clf.tree_.feature[node]+1])\n",
    "            \n",
    "    path_as_string.append('E')\n",
    "    for val in X[i]:\n",
    "        test_df.append(val)\n",
    "    test_df.append(['E', 0])\n",
    "    # path_as_string = ' '.join(path_as_string)\n",
    "    # path_column = np.append(path_column, path_as_string)\n",
    "    path_column.append(path_as_string)\n",
    "\n",
    "path_column = np.array(path_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = pd.DataFrame(np.array(test_df).reshape(-1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df[[5,6]] = pd.DataFrame(final_test_df[4].values.tolist(), index= final_test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>[S, 0]</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>[L, 0]</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>[E, 0]</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.14302</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>[S, 0]</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.14302</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>[L, 0]</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1        2        3       4  5  6\n",
       "0 -0.900681     1.019 -1.34023 -1.31544  [S, 0]  S  0\n",
       "1 -0.900681     1.019 -1.34023 -1.31544  [L, 0]  L  0\n",
       "2 -0.900681     1.019 -1.34023 -1.31544  [E, 0]  E  0\n",
       "3  -1.14302 -0.131979 -1.34023 -1.31544  [S, 0]  S  0\n",
       "4  -1.14302 -0.131979 -1.34023 -1.31544  [L, 0]  L  0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left_nodes = clf.tree_.children_left[clf.tree_.children_left>0]\n",
    "# right_nodes = clf.tree_.children_right[clf.tree_.children_right>0]\n",
    "# node_indicator = clf.decision_path(X)\n",
    "# path_list = []\n",
    "# for i, j in enumerate(X):\n",
    "#     path_list.append(node_indicator.indices[node_indicator.indptr[i]:node_indicator.indptr[i+1]])\n",
    "\n",
    "# ## Convert path to strings\n",
    "# path_column = np.array([])\n",
    "# for i, j in enumerate(X):\n",
    "#     path_as_string = []\n",
    "#     for node in path_list[i]:\n",
    "#         if node == 0:\n",
    "#             path_as_string.append('S')\n",
    "#         elif node in left_nodes:\n",
    "#             path_as_string.append('L')\n",
    "#         elif node in right_nodes:\n",
    "#             path_as_string.append('R')\n",
    "            \n",
    "#     path_as_string.append('E')\n",
    "#     path_as_string = ' '.join(path_as_string)\n",
    "#     path_column = np.append(path_column, path_as_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['S', 'L', 'R', 'E']\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "Xnew = np.hstack((X, path_column.reshape(-1,1)))\n",
    "path_sequence = Xnew[:,4]\n",
    "data = pd.DataFrame(Xnew)\n",
    "data[5]=y\n",
    "df = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# prepare dataset for training\n",
    "get_path_lengths = lambda t: len(t.split())\n",
    "paths_lengths = np.array([get_path_lengths(xi) for xi in path_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 4\n",
    "label_size = 3\n",
    "feature_size = 4\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = np.max(paths_lengths)\n",
    "sentences = []\n",
    "next_chars = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    # get the feature\n",
    "    curr_feat = np.array([df.iloc[i,0:4]])\n",
    "    curr_path = df.iloc[i,4].split()\n",
    "    curr_path_len = len(curr_path)\n",
    "    curr_label = y[i]\n",
    "    for j in range(1,curr_path_len):\n",
    "        features.append(curr_feat)\n",
    "        labels.append(curr_label)\n",
    "        sentences.append(curr_path[0:j])\n",
    "        next_chars.append(curr_path[j])\n",
    "print('Vectorization...')\n",
    "\n",
    "x_sent = np.zeros((len(sentences), maxlen, vocab_size), dtype=np.bool)\n",
    "x_feat = np.zeros((len(sentences), feature_size), dtype=np.float)\n",
    "y_chars = np.zeros((len(sentences), vocab_size), dtype=np.bool)\n",
    "y_feat = np.zeros((len(sentences), label_size), dtype=np.float)\n",
    "#from keras.utils import to_categorical\n",
    "#y_feat_tmp = to_categorical(df[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_sent[i, t, char_indices[char]] = 1\n",
    "    y_chars[i, char_indices[next_chars[i]]] = 1\n",
    "    x_feat[i,:] = features[i]\n",
    "    y_feat[i,labels[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 10\n",
    "print(y_chars[index],y_feat[index],x_sent[index],x_feat[index])\n",
    "print(y_chars.shape,y_feat.shape,x_sent.shape,x_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Concatenate, concatenate, Flatten\n",
    "\n",
    "h1_size = 5\n",
    "latent_dim = 5\n",
    "\n",
    "input_x_features = Input(shape=(feature_size,),name='ip_x')\n",
    "hidden_state_x = Dense(h1_size, activation='relu',name='hidden_x')(input_x_features)\n",
    "output_labels = Dense(3, activation='softmax',name='op_x')(hidden_state_x)\n",
    "\n",
    "input_sent_features = Input(shape=(maxlen,vocab_size),name='ip_sent')\n",
    "decoder = LSTM(latent_dim,return_state=False,return_sequences=False,name='lstm_sent')\n",
    "decoder_outputs = decoder(input_sent_features)\n",
    "\n",
    "merge_layer = concatenate([hidden_state_x,decoder_outputs],name='cat')\n",
    "output_chars = Dense(vocab_size, activation='softmax',name='op_sent')(merge_layer)\n",
    "model = Model([input_x_features,input_sent_features], [output_labels,output_chars])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_joint_model(initialize=True, rnn_cell= 'gru'):\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Input, LSTM, Dense, Concatenate, concatenate, Flatten, GRU\n",
    "    h1_size = 5\n",
    "    latent_dim = 5\n",
    "    \n",
    "    input_x_features = Input(shape=(feature_size,),name='ip_x')\n",
    "    hidden_state_x = Dense(h1_size, activation='relu',name='hidden_x')(input_x_features)\n",
    "    output_labels = Dense(3, activation='softmax',name='op_x')(hidden_state_x)\n",
    "    \n",
    "    input_sent_features = Input(shape=(maxlen,vocab_size),name='ip_sent')\n",
    "    if rnn_cell == 'gru':\n",
    "        RNN = GRU\n",
    "    else:\n",
    "        RNN = LSTM\n",
    "            \n",
    "    decoder = RNN(latent_dim,return_state=False,return_sequences=False,name='lstm_sent')\n",
    "    if initialize:\n",
    "        decoder_outputs = decoder(input_sent_features,initial_state=hidden_state_x)\n",
    "    else:\n",
    "        decoder_outputs = decoder(input_sent_features)\n",
    "    \n",
    "    merge_layer = concatenate([hidden_state_x,decoder_outputs],name='cat')\n",
    "    output_chars = Dense(vocab_size, activation='softmax',name='op_sent')(merge_layer)\n",
    "    model = Model([input_x_features,input_sent_features], [output_labels,output_chars])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = paths_joint_model()\n",
    "model.compile(optimizer='adam', loss={'op_x':'categorical_crossentropy','op_sent':'categorical_crossentropy'},metrics=['accuracy'])\n",
    "model.fit([x_feat,x_sent],[y_feat,y_chars],batch_size =20, epochs = 2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(x):\n",
    "    n = x.shape[0]\n",
    "    x_f = x.reshape(1,feature_size)\n",
    "    token = 'S'\n",
    "    cont = True\n",
    "    text = [token]\n",
    "    x_sent = np.zeros((1,maxlen,vocab_size),dtype=np.bool)\n",
    "    x_sent[0,0,char_indices[token]] = 1\n",
    "    label = []\n",
    "    index = 1\n",
    "    while cont & (index <maxlen):\n",
    "        pred = model.predict([x_f.reshape(1,feature_size),x_sent])\n",
    "        char_index = np.argmax(pred[1])\n",
    "        label.append(np.argmax(pred[0])) \n",
    "        x_sent[0,index,char_index] = 1\n",
    "        next_char = indices_char[char_index]\n",
    "        text.append(next_char)\n",
    "        index += 1    \n",
    "        if next_char == 'E':\n",
    "            cont = False\n",
    "    return [text,label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for i in range(10,20):\n",
    "    curr_feat = np.array([df.iloc[i,0:4]])\n",
    "    path,label= sample(curr_feat)\n",
    "    print('actual vs predicted: ', df.iloc[i,4] ,' vs ', ' '.join(path), 'labels: ', df.iloc[i,5],label[0])\n",
    "    count.append(df.iloc[i,5]==label[0])\n",
    "np.mean(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_model(initialize=True, rnn_cell= 'gru',latent_dim = 5):\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Input, LSTM, Dense, Concatenate, concatenate, Flatten, GRU\n",
    "    latent_dim = latent_dim\n",
    "    \n",
    "    hidden_state_x = Input(shape=(latent_dim,),name='hidden_x')\n",
    "    input_sent_features = Input(shape=(maxlen,vocab_size),name='ip_sent')\n",
    "    if rnn_cell == 'gru':\n",
    "        RNN = GRU\n",
    "    else:\n",
    "        RNN = LSTM\n",
    "            \n",
    "    decoder = RNN(latent_dim,return_state=False,return_sequences=False,name='gru_sent')\n",
    "    if initialize:\n",
    "        decoder_outputs = decoder(input_sent_features,initial_state=hidden_state_x)\n",
    "    else:\n",
    "        decoder_outputs = decoder(input_sent_features)\n",
    "    \n",
    "    merge_layer = concatenate([hidden_state_x,decoder_outputs],name='cat')\n",
    "    output_chars = Dense(vocab_size, activation='softmax',name='op_sent')(merge_layer)\n",
    "    model = Model([hidden_state_x,input_sent_features], output_chars)\n",
    "    return model\n",
    "\n",
    "def label_model(feature_size = 4, latent_dim = 5):\n",
    "    from keras.models import Model\n",
    "    from keras.layers import Input, LSTM, Dense, Concatenate, concatenate, Flatten, GRU\n",
    "    feature_size = feature_size\n",
    "    h1_size = latent_dim\n",
    "    input_x_features = Input(shape=(feature_size,),name='ip_x')\n",
    "    hidden_state_x1 = Dense(20, activation='tanh',name='hidden_x1')(input_x_features)\n",
    "    hidden_state_x2 = Dense(20, activation='tanh',name='hidden_x2')(hidden_state_x1)\n",
    "    hidden_state_x3 = Dense(h1_size, activation='tanh',name='hidden_x3')(hidden_state_x2)\n",
    "    output_labels = Dense(3, activation='softmax',name='op_x')(hidden_state_x3)    \n",
    "    model = Model(input_x_features,output_labels)\n",
    "    return model\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def get_hidden_x(x,model,layer_num=3):\n",
    "    def get_hidden_x_inner(model,layer_num=layer_num):\n",
    "        return K.function([model.layers[0].input], [model.layers[layer_num].output])\n",
    "    return get_hidden_x_inner(model,layer_num=layer_num)([x])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_m = paths_model()\n",
    "path_m.summary()\n",
    "label_m = label_model()\n",
    "label_m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_cat = to_categorical(y)\n",
    "\n",
    "label_m.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "label_m_history = label_m.fit(X,y_cat,batch_size =20, epochs = 2,verbose=0, shuffle=True)\n",
    "\n",
    "x_latent = get_hidden_x(x_feat,model=label_m)\n",
    "\n",
    "path_m.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "path_m.fit([x_latent,x_sent],y_chars,batch_size =20, epochs = 2,verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "latent_dim = 5\n",
    "\n",
    "def jaccard_score_inconsistent(x,y):\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "def get_j_coeff(a,b):\n",
    "    if len(a) != len(b):\n",
    "        return jaccard_score_inconsistent(a, b)\n",
    "    return jaccard_score(a, b, average='micro')\n",
    "        \n",
    "\n",
    "def sample_paths(x,path_model=path_m,label_model=label_m,latent_dim=latent_dim,feature_size=feature_size):\n",
    "    n = x.shape[0]\n",
    "    x_f = x.reshape(1,feature_size)\n",
    "    token = 'S'\n",
    "    cont = True\n",
    "    text = [token]\n",
    "    x_sent = np.zeros((1,maxlen,vocab_size),dtype=np.bool)\n",
    "    x_latent = get_hidden_x(x_f,model=label_model)\n",
    "    x_latent = x_latent.reshape(1,latent_dim)\n",
    "    x_sent[0,0,char_indices[token]] = 1\n",
    "    pred = label_model.predict(x_f)\n",
    "    label = [np.argmax(pred[0])]\n",
    "    index = 1\n",
    "    while cont & (index <maxlen):\n",
    "        pred = path_model.predict([x_latent,x_sent])\n",
    "        char_index = np.argmax(pred[0])\n",
    "        x_sent[0,index,char_index] = 1\n",
    "        next_char = indices_char[char_index]\n",
    "        text.append(next_char)\n",
    "        index += 1    \n",
    "        if next_char == 'E':\n",
    "            cont = False\n",
    "    return [text,label]\n",
    "\n",
    "def predict_decision_feature(x, path_step)\n",
    "\n",
    "count = []\n",
    "j_coeff = []\n",
    "l_dist = []\n",
    "for i in range(150):\n",
    "    curr_feat = np.array([df.iloc[i,0:4]])\n",
    "    path,label= sample_paths(curr_feat)\n",
    "#     print('actual vs predicted: ', df.iloc[i,4] ,' vs ', ' '.join(path), 'labels: ', df.iloc[i,5],label[0])\n",
    "    count.append(df.iloc[i,5]==label[0])\n",
    "    actual_path = df.iloc[i,4].split()\n",
    "    actual_path_tok = [char_indices[char] for char in actual_path]\n",
    "    pred_path_tok = [char_indices[char] for char in path]\n",
    "    j_coeff.append(get_j_coeff(actual_path_tok, pred_path_tok))\n",
    "    l_dist.append(distance.levenshtein(df.iloc[i,4].replace(' ', ''), ''.join(path)))\n",
    "print('\\nLabel accuracy - ',np.mean(count))\n",
    "print('Path metric (Jaccard) - ',np.mean(j_coeff))\n",
    "print('Path metric (Levensthein) - ',np.mean(l_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "label_m.evaluate(df.iloc[:,0:4], to_categorical(df.iloc[:,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(label_m_history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(label_m_history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizations required\n",
    "\n",
    "1) Path comparison - dt vs rnn output  -- Jaccard coeff/ levenstein distance (try both\n",
    "2) cutpoints while training  -- feature information\n",
    "   - Predict the precise cutpoint(regression model) \n",
    "   - 3 buckets(low, med, high)--range quantile splits1/3,2/3 -- Classification model\n",
    "   - 4 classification models - \n",
    "3) Packaging it as a usable API  \n",
    "4) latent_dim as hyperparam - ray/tune  \n",
    "5) Test/train split. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Concatenate, concatenate, Flatten, GRU\n",
    "\n",
    "feature_size = 4\n",
    "h1_size = 5\n",
    "input_x_features = Input(shape=(feature_size,),name='ip_x')\n",
    "hidden_state_x1 = Dense(20, activation='tanh',name='hidden_x1')(input_x_features)\n",
    "hidden_state_x2 = Dense(10, activation='tanh',name='hidden_x2')(hidden_state_x1)\n",
    "hidden_state_x3 = Dense(h1_size, activation='tanh',name='hidden_x3')(hidden_state_x2)\n",
    "output_labels = Dense(3, activation='softmax',name='op_x')(hidden_state_x3)    \n",
    "model = Model(input_x_features,output_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X,y_cat,batch_size =30, epochs = 200,verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X, y_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Jaccard coeff trials\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from scipy.spatial import distance\n",
    "distance.jaccard([1, 0, 0, 1], [0, 1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to predict decision feature\n",
    "\n",
    "np.array([[[1,0],[0,0,0,1],[0,1,0]],\n",
    "          [[1,0],[0,0,0,1],[0,1,0]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "## Trial model -- to predict decision features\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "input_1 = Input(shape=(5,))\n",
    "hidden_1 = Dense(8, activation='tanh')(input_1)\n",
    "output = Dense(5, activation='softmax')(hidden_1)\n",
    "\n",
    "test_model = Model(input_1, output)\n",
    "\n",
    "test_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 48        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 45        \n",
      "=================================================================\n",
      "Total params: 93\n",
      "Trainable params: 93\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "chars = ['S', 'L', 'R', 'E']\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "for i, j in enumerate(final_test_df.values):\n",
    "    final_test_df[5][i] = char_indices[final_test_df[5][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = final_test_df.drop(columns=4)\n",
    "\n",
    "trial_x = final_test_df.iloc[:,0:5]\n",
    "trial_y = final_test_df.iloc[:,5]\n",
    "\n",
    "# np.append(converted_chars, char_indices[final_test_df[5][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.14302</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.14302</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.14302</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.38535</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>-1.39706</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.38535</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>-1.39706</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.38535</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>-1.39706</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.50652</td>\n",
       "      <td>0.0982173</td>\n",
       "      <td>-1.28339</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.50652</td>\n",
       "      <td>0.0982173</td>\n",
       "      <td>-1.28339</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.50652</td>\n",
       "      <td>0.0982173</td>\n",
       "      <td>-1.28339</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.02185</td>\n",
       "      <td>1.2492</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.02185</td>\n",
       "      <td>1.2492</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1.02185</td>\n",
       "      <td>1.2492</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.31544</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.537178</td>\n",
       "      <td>1.93979</td>\n",
       "      <td>-1.16971</td>\n",
       "      <td>-1.05218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.537178</td>\n",
       "      <td>1.93979</td>\n",
       "      <td>-1.16971</td>\n",
       "      <td>-1.05218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.537178</td>\n",
       "      <td>1.93979</td>\n",
       "      <td>-1.16971</td>\n",
       "      <td>-1.05218</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-1.50652</td>\n",
       "      <td>0.788808</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.18381</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-1.50652</td>\n",
       "      <td>0.788808</td>\n",
       "      <td>-1.34023</td>\n",
       "      <td>-1.18381</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1        2        3  5  6\n",
       "0  -0.900681      1.019 -1.34023 -1.31544  0  0\n",
       "1  -0.900681      1.019 -1.34023 -1.31544  1  0\n",
       "2  -0.900681      1.019 -1.34023 -1.31544  3  0\n",
       "3   -1.14302  -0.131979 -1.34023 -1.31544  0  0\n",
       "4   -1.14302  -0.131979 -1.34023 -1.31544  1  0\n",
       "5   -1.14302  -0.131979 -1.34023 -1.31544  3  0\n",
       "6   -1.38535   0.328414 -1.39706 -1.31544  0  0\n",
       "7   -1.38535   0.328414 -1.39706 -1.31544  1  0\n",
       "8   -1.38535   0.328414 -1.39706 -1.31544  3  0\n",
       "9   -1.50652  0.0982173 -1.28339 -1.31544  0  0\n",
       "10  -1.50652  0.0982173 -1.28339 -1.31544  1  0\n",
       "11  -1.50652  0.0982173 -1.28339 -1.31544  3  0\n",
       "12  -1.02185     1.2492 -1.34023 -1.31544  0  0\n",
       "13  -1.02185     1.2492 -1.34023 -1.31544  1  0\n",
       "14  -1.02185     1.2492 -1.34023 -1.31544  3  0\n",
       "15 -0.537178    1.93979 -1.16971 -1.05218  0  0\n",
       "16 -0.537178    1.93979 -1.16971 -1.05218  1  0\n",
       "17 -0.537178    1.93979 -1.16971 -1.05218  3  0\n",
       "18  -1.50652   0.788808 -1.34023 -1.18381  0  0\n",
       "19  -1.50652   0.788808 -1.34023 -1.18381  1  0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-1.02185</td>\n",
       "      <td>-2.43395</td>\n",
       "      <td>-0.146641</td>\n",
       "      <td>-0.262387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>-1.02185</td>\n",
       "      <td>-2.43395</td>\n",
       "      <td>-0.146641</td>\n",
       "      <td>-0.262387</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>-1.02185</td>\n",
       "      <td>-2.43395</td>\n",
       "      <td>-0.146641</td>\n",
       "      <td>-0.262387</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-1.02185</td>\n",
       "      <td>-2.43395</td>\n",
       "      <td>-0.146641</td>\n",
       "      <td>-0.262387</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-1.02185</td>\n",
       "      <td>-2.43395</td>\n",
       "      <td>-0.146641</td>\n",
       "      <td>-0.262387</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0686618</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>0.395774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0686618</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>0.395774</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0686618</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>0.395774</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.0686618</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>0.395774</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.0686618</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.251221</td>\n",
       "      <td>0.395774</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3  5  6\n",
       "200   -1.02185  -2.43395 -0.146641 -0.262387  0  0\n",
       "201   -1.02185  -2.43395 -0.146641 -0.262387  2  3\n",
       "202   -1.02185  -2.43395 -0.146641 -0.262387  1  4\n",
       "203   -1.02185  -2.43395 -0.146641 -0.262387  1  0\n",
       "204   -1.02185  -2.43395 -0.146641 -0.262387  3  0\n",
       "205  0.0686618 -0.131979  0.251221  0.395774  0  0\n",
       "206  0.0686618 -0.131979  0.251221  0.395774  2  3\n",
       "207  0.0686618 -0.131979  0.251221  0.395774  1  4\n",
       "208  0.0686618 -0.131979  0.251221  0.395774  1  0\n",
       "209  0.0686618 -0.131979  0.251221  0.395774  3  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_df[200:210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "trial_y = to_categorical(trial_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(676, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "676/676 [==============================] - 2s 3ms/step - loss: 1.7179 - acc: 0.0740\n",
      "Epoch 2/2\n",
      "676/676 [==============================] - 0s 29us/step - loss: 1.6204 - acc: 0.1746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f767711ca20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.fit(trial_x, trial_y, batch_size =30, epochs = 2,verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
