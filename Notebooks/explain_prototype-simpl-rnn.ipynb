{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_nodes = clf.tree_.children_left[clf.tree_.children_left>0]\n",
    "right_nodes = clf.tree_.children_right[clf.tree_.children_right>0]\n",
    "node_indicator = clf.decision_path(X)\n",
    "path_list = []\n",
    "for i, j in enumerate(X):\n",
    "    path_list.append(node_indicator.indices[node_indicator.indptr[i]:node_indicator.indptr[i+1]])\n",
    "\n",
    "## Convert path to strings\n",
    "path_column = np.array([])\n",
    "for i, j in enumerate(X):\n",
    "    path_as_string = []\n",
    "    for node in path_list[i]:\n",
    "        if node == 0:\n",
    "            path_as_string.append('S')\n",
    "        elif node in left_nodes:\n",
    "            path_as_string.append('L')\n",
    "        elif node in right_nodes:\n",
    "            path_as_string.append('R')\n",
    "            \n",
    "    path_as_string.append('E')\n",
    "    path_as_string = ' '.join(path_as_string)\n",
    "    path_column = np.append(path_column, path_as_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['S', 'L', 'R', 'E']\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "Xnew = np.hstack((X, path_column.reshape(-1,1)))\n",
    "path_sequence = Xnew[:,4]\n",
    "data = pd.DataFrame(Xnew)\n",
    "data[5]=y\n",
    "df = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# prepare dataset for training\n",
    "get_path_lengths = lambda t: len(t.split())\n",
    "paths_lengths = np.array([get_path_lengths(xi) for xi in path_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 4\n",
    "label_size = 3\n",
    "feature_size = 4\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = np.max(paths_lengths)\n",
    "sentences = []\n",
    "next_chars = []\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    # get the feature\n",
    "    curr_feat = np.array([df.iloc[i,0:4]])\n",
    "    curr_path = df.iloc[i,4].split()\n",
    "    curr_path_len = len(curr_path)\n",
    "    curr_label = y[i]\n",
    "    for j in range(1,curr_path_len):\n",
    "        features.append(curr_feat)\n",
    "        labels.append(curr_label)\n",
    "        sentences.append(curr_path[0:j])\n",
    "        next_chars.append(curr_path[j])\n",
    "print('Vectorization...')\n",
    "\n",
    "x_sent = np.zeros((len(sentences), maxlen, vocab_size), dtype=np.bool)\n",
    "x_feat = np.zeros((len(sentences), feature_size), dtype=np.float)\n",
    "y_chars = np.zeros((len(sentences), vocab_size), dtype=np.bool)\n",
    "y_feat = np.zeros((len(sentences), label_size), dtype=np.float)\n",
    "#from keras.utils import to_categorical\n",
    "#y_feat_tmp = to_categorical(df[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_sent[i, t, char_indices[char]] = 1\n",
    "    y_chars[i, char_indices[next_chars[i]]] = 1\n",
    "    x_feat[i,:] = features[i]\n",
    "    y_feat[i,labels[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True False] [1. 0. 0.] [[ True False False False]\n",
      " [False False  True False]\n",
      " [False False  True False]\n",
      " [False  True False False]\n",
      " [False False False False]\n",
      " [False False False False]\n",
      " [False False False False]] [5.9 3.2 4.8 1.8]\n",
      "(560, 4) (560, 3) (560, 7, 4) (560, 4)\n"
     ]
    }
   ],
   "source": [
    "index = 10\n",
    "print(y_chars[index],y_feat[index],x_sent[index],x_feat[index])\n",
    "print(y_chars.shape,y_feat.shape,x_sent.shape,x_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/soma/venvs/daggit/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "ip_x (InputLayer)               (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ip_sent (InputLayer)            (None, 7, 4)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_x (Dense)                (None, 5)            25          ip_x[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_sent (LSTM)                (None, 5)            200         ip_sent[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cat (Concatenate)               (None, 10)           0           hidden_x[0][0]                   \n",
      "                                                                 lstm_sent[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "op_x (Dense)                    (None, 3)            18          hidden_x[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "op_sent (Dense)                 (None, 4)            44          cat[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 287\n",
      "Trainable params: 287\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Concatenate, concatenate, Flatten\n",
    "\n",
    "h1_size = 5\n",
    "latent_dim = 5\n",
    "\n",
    "input_x_features = Input(shape=(feature_size,),name='ip_x')\n",
    "hidden_state_x = Dense(h1_size, activation='relu',name='hidden_x')(input_x_features)\n",
    "output_labels = Dense(3, activation='linear',name='op_x')(hidden_state_x)\n",
    "\n",
    "input_sent_features = Input(shape=(maxlen,vocab_size),name='ip_sent')\n",
    "decoder = LSTM(latent_dim,return_state=False,return_sequences=False,name='lstm_sent')\n",
    "decoder_outputs = decoder(input_sent_features)\n",
    "\n",
    "merge_layer = concatenate([hidden_state_x,decoder_outputs],name='cat')\n",
    "output_chars = Dense(vocab_size, activation='softmax',name='op_sent')(merge_layer)\n",
    "model = Model([input_x_features,input_sent_features], [output_labels,output_chars])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "560/560 [==============================] - 2s 4ms/step - loss: 6.3213 - op_x_loss: 5.3535 - op_sent_loss: 0.9677 - op_x_acc: 0.3304 - op_sent_acc: 0.5625\n",
      "Epoch 2/10\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 6.2764 - op_x_loss: 5.3535 - op_sent_loss: 0.9229 - op_x_acc: 0.3339 - op_sent_acc: 0.5821\n",
      "Epoch 3/10\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 6.2321 - op_x_loss: 5.3535 - op_sent_loss: 0.8786 - op_x_acc: 0.3339 - op_sent_acc: 0.6036\n",
      "Epoch 4/10\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 6.1929 - op_x_loss: 5.3535 - op_sent_loss: 0.8394 - op_x_acc: 0.3339 - op_sent_acc: 0.5696\n",
      "Epoch 5/10\n",
      "560/560 [==============================] - 1s 2ms/step - loss: 6.1576 - op_x_loss: 5.3535 - op_sent_loss: 0.8041 - op_x_acc: 0.3339 - op_sent_acc: 0.5964\n",
      "Epoch 6/10\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 6.1260 - op_x_loss: 5.3535 - op_sent_loss: 0.7725 - op_x_acc: 0.3339 - op_sent_acc: 0.6250\n",
      "Epoch 7/10\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 6.1014 - op_x_loss: 5.3535 - op_sent_loss: 0.7479 - op_x_acc: 0.3339 - op_sent_acc: 0.6429A: 1s - loss: 5.5950 - op_x_loss: 4.8354 - op_sent_loss: 0.7596 - op_x_acc: 0.2667 - op_sen\n",
      "Epoch 8/10\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 6.0740 - op_x_loss: 5.3535 - op_sent_loss: 0.7205 - op_x_acc: 0.3339 - op_sent_acc: 0.6607\n",
      "Epoch 9/10\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 6.0491 - op_x_loss: 5.3535 - op_sent_loss: 0.6956 - op_x_acc: 0.3339 - op_sent_acc: 0.6804\n",
      "Epoch 10/10\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 6.0210 - op_x_loss: 5.3535 - op_sent_loss: 0.6675 - op_x_acc: 0.3339 - op_sent_acc: 0.7214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1367f36d8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit([x_feat,x_sent],[y_feat,y_chars],batch_size =10, epochs = 10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
