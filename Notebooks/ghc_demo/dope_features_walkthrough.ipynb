{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - Features of `mlsquare.dope`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `dope` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-11-07 16:17:10,699\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-11-07_16-17-10_32653/logs.\n",
      "2019-11-07 16:17:10,808\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:19189 to respond...\n",
      "2019-11-07 16:17:10,921\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:42688 to respond...\n",
      "2019-11-07 16:17:10,926\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-11-07 16:17:10,958\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    }
   ],
   "source": [
    "from mlsquare import dope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage - `dope` without additional parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your primal model(the model you intend to convert to a neural network)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# This single line of code enables your model to perform like a neural network\n",
    "m = dope(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "2019-11-07 16:17:15,759\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-11-07 16:17:15,760\tINFO tune.py:211 -- Starting a new experiment.\n",
      "2019-11-07 16:17:15,930\tWARNING util.py:62 -- The `start_trial` operation took 0.1632378101348877 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.3/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.3/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m 2019-11-07 16:17:18,445\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m 2019-11-07 16:17:26.914519: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m 2019-11-07 16:17:26.935064: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m 2019-11-07 16:17:26.935571: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5562b6843470 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m 2019-11-07 16:17:26.935589: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-07 16:17:27,436\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2019-11-07 16:17:27,592\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.1555318832397461 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''sigmoid'', ''optimizer'': ''adam'', ''loss'': ''binary_crossentropy''}.h5'\n",
      "  date: 2019-11-07_16-17-27\n",
      "  done: false\n",
      "  experiment_id: a63e26dd05234f31aabc59bb75105322\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.3499999980131785\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 32695\n",
      "  time_since_restore: 0.7397806644439697\n",
      "  time_this_iter_s: 0.7397806644439697\n",
      "  time_total_s: 0.7397806644439697\n",
      "  timestamp: 1573123647\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.5/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING, [4 CPUs, 0 GPUs], [pid=32695], 0 s, 1 iter, 0.35 acc\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m 32/60 [===============>..............] - ETA: \n",
      "\u001b[2m\u001b[36m(pid=32695)\u001b[0m 60/60 [==============================] - 0s 277us/step\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.5/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - train_model_0:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=32695], 0 s, 1 iter, 0.35 acc\n",
      "\n",
      "Creating model...\n",
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_2019-11-07_16-17-15h_flbyuh/weights_tune_{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'sigmoid', 'optimizer': 'adam', 'loss': 'binary_crossentropy'}.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f9e88f4b470>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 244us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5179819915029737, 0.311111111442248]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing versions of the proxy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    }
   ],
   "source": [
    "# Pass your neural network version choice as an argument to dope\n",
    "m = dope(model, version='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlsquare.adapters.sklearn.SklearnKerasClassifier object at 0x7f9dcff1e3c8>\n"
     ]
    }
   ],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing `adapter` and `proxy_model` externally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load adapter and proxy_model\n",
    "# Here, we are loading an adapter and a proxy_model from mlsquare for the sake of simplicity\n",
    "from mlsquare import registry\n",
    "\n",
    "proxy_model, adapter = registry[('sklearn', 'LinearRegression')]['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    }
   ],
   "source": [
    "m = dope(model, adapter=adapter, proxy_model=proxy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlsquare.adapters.sklearn.SklearnKerasRegressor object at 0x7f9dcff1eb38>\n",
      "<mlsquare.architectures.sklearn.LinearRegression object at 0x7f9e3d333588>\n",
      "<class 'mlsquare.adapters.sklearn.SklearnKerasRegressor'>\n"
     ]
    }
   ],
   "source": [
    "print(m)\n",
    "print(proxy_model)\n",
    "print(adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer - using `tune` for hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing model parameters via `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "2019-11-07 16:17:29,571\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-11-07 16:17:29,572\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.3/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.3/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m 2019-11-07 16:17:31,681\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m 2019-11-07 16:17:32.218702: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m 2019-11-07 16:17:32.222406: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m 2019-11-07 16:17:32.222755: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x561b65a4d470 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m 2019-11-07 16:17:32.222776: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-07 16:17:32,697\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m 32/60 [===============>..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=32698)\u001b[0m 60/60 [==============================] - 0s 270us/step\n",
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''sigmoid'', ''optimizer'': ''adam'', ''loss'': ''binary_crossentropy''}.h5'\n",
      "  date: 2019-11-07_16-17-32\n",
      "  done: false\n",
      "  experiment_id: c61b0976e5724160adc1a15e0055d521\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.5833333452542623\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 32698\n",
      "  time_since_restore: 0.8713645935058594\n",
      "  time_this_iter_s: 0.8713645935058594\n",
      "  time_total_s: 0.8713645935058594\n",
      "  timestamp: 1573123652\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.4/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - train_model_0:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=32698], 0 s, 1 iter, 0.583 acc\n",
      "\n",
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_2019-11-07_16-17-29_18lyadm/weights_tune_{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'sigmoid', 'optimizer': 'adam', 'loss': 'binary_crossentropy'}.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f9e3d15eef0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without additional search parameters\n",
    "m = dope(model)\n",
    "\n",
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Adam at 0x7f9dcc6b9438>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.final_model.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "2019-11-07 16:17:32,798\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-11-07 16:17:32,798\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.4/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.4/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'RUNNING': 1, 'PENDING': 1})\n",
      "PENDING trials:\n",
      " - train_model_1_optimizer=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_optimizer=adam:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m 2019-11-07 16:17:34,552\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m 2019-11-07 16:17:34.863843: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m 2019-11-07 16:17:34.866730: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m 2019-11-07 16:17:34.867115: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x557ae2f68470 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m 2019-11-07 16:17:34.867132: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-07 16:17:35,335\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0_optimizer=adam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_0_optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''sigmoid'', ''optimizer'': ''adam'', ''loss'': ''binary_crossentropy''}.h5'\n",
      "  date: 2019-11-07_16-17-35\n",
      "  done: false\n",
      "  experiment_id: 57607f55834c4a00b36e19e8fe076535\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.7166666626930237\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 32697\n",
      "  time_since_restore: 0.6321709156036377\n",
      "  time_this_iter_s: 0.6321709156036377\n",
      "  time_total_s: 0.6321709156036377\n",
      "  timestamp: 1573123655\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m 32/60 [===============>..............] - ETA: \n",
      "\u001b[2m\u001b[36m(pid=32697)\u001b[0m 60/60 [==============================] - 0s 289us/step\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m 2019-11-07 16:17:37,956\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m 2019-11-07 16:17:38.438104: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m 2019-11-07 16:17:38.441555: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m 2019-11-07 16:17:38.441948: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55ad259f3470 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m 2019-11-07 16:17:38.441964: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-07 16:17:38,943\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_1_optimizer=nadam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_1_optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''sigmoid'', ''optimizer'': ''nadam'', ''loss'': ''binary_crossentropy''}.h5'\n",
      "  date: 2019-11-07_16-17-38\n",
      "  done: false\n",
      "  experiment_id: 8ddf43a3b02d41a19410e6d7c954e4c0\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.7333333293596903\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 32696\n",
      "  time_since_restore: 0.8370919227600098\n",
      "  time_this_iter_s: 0.8370919227600098\n",
      "  time_total_s: 0.8370919227600098\n",
      "  timestamp: 1573123658\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.3/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 1, 'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_1_optimizer=nadam:\tRUNNING, [4 CPUs, 0 GPUs], [pid=32696], 0 s, 1 iter, 0.733 acc\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimizer=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=32697], 0 s, 1 iter, 0.717 acc\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.3/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 2})\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimizer=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=32697], 0 s, 1 iter, 0.717 acc\n",
      " - train_model_1_optimizer=nadam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=32696], 0 s, 1 iter, 0.733 acc\n",
      "\n",
      "Creating model...\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m 32/60 [===============>..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=32696)\u001b[0m 60/60 [==============================] - 0s 278us/step\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_1_optimizer=nadam_2019-11-07_16-17-35v15zmrqh/weights_tune_{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'sigmoid', 'optimizer': 'nadam', 'loss': 'binary_crossentropy'}.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f9dcc5f3240>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import tune\n",
    "m = dope(model)\n",
    "params = {'optimizer':{'grid_search':['adam', 'nadam']}}\n",
    "m.fit(X_train, y_train, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.Nadam at 0x7f9dcc60ee10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.final_model.optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registry - Accessing mlsquare's model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_name = 'sklearn'\n",
    "model_name = 'DecisionTreeClassifier'\n",
    "version = 'default'\n",
    "\n",
    "# When provided with the above three values registry returns the corresponding\n",
    "# adapter and proxy_model\n",
    "\n",
    "proxy_model, adapter = registry[(module_name, model_name)][version]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlsquare.architectures.sklearn.DecisionTreeClassifier object at 0x7f9e3d2bf358>\n",
      "<class 'mlsquare.adapters.sklearn.SklearnKerasClassifier'>\n"
     ]
    }
   ],
   "source": [
    "print(proxy_model)\n",
    "print(adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sklearn', 'LogisticRegression'),\n",
       " ('sklearn', 'LinearRegression'),\n",
       " ('sklearn', 'Ridge'),\n",
       " ('sklearn', 'Lasso'),\n",
       " ('sklearn', 'ElasticNet'),\n",
       " ('sklearn', 'LinearSVC'),\n",
       " ('sklearn', 'SVC'),\n",
       " ('sklearn', 'DecisionTreeClassifier')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(registry.data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `save` and `explain` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 7.\n"
     ]
    }
   ],
   "source": [
    "m.save(filename=\"test_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coming soon...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-07 17:14:55,865\tERROR worker.py:1780 -- The node with client ID cfdaefc73b8ade127afd024197915e32d9eff28c has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    }
   ],
   "source": [
    "m.explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.117px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
