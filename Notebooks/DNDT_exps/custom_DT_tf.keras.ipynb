{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom DNDT keras layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **A typical custom dot product layer--example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim= output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name= 'kernel', shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform', trainable=True)\n",
    "        self.built= True#super(MyLayer, self).build(input_shape)\n",
    "    \n",
    "    def call(self,x):\n",
    "        return K.dot(x, self.kernel)# shape (1,3)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)#(None, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1= Input(shape=(2,))\n",
    "latent= MyLayer(3)(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "my_layer_6 (MyLayer)         (None, 3)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod= Model(inputs=l1, outputs=latent)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.00611025,  0.02683054,  0.02120567],\n",
       "        [ 0.03125073, -0.02671376, -0.04855492]], dtype=float32)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgt= mod.layers[1].get_weights()\n",
    "wgt #weighhts init by custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0148045 , 0.03222001, 0.01997696]], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1= x[:1]\n",
    "mod.predict(t1)#prediction at end of custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes:  (1, 2) (2, 3)\n"
     ]
    }
   ],
   "source": [
    "print('shapes: ',t1.shape, wgt[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cross checking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.0148045 , 0.03222001, 0.01997696]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.dot(t1, wgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Keras implementation of Custom DT layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from functools import reduce\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Layer\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check where is num_Class arg passed into initialization into mlsquare.DT?\n",
    "class DT(Layer):\n",
    "    def __init__(self, cuts_per_feat, t=0.1, num_class=3, **kwargs):\n",
    "        self.temperature= t #kwargs.get('t')\n",
    "        self.num_cut= cuts_per_feat\n",
    "        self.num_leaf = np.prod(np.array(cuts_per_feat)+1)\n",
    "        self.num_class= num_class #kwargs.get('num_class')\n",
    "        super(DT, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.leaf_score= self.add_weight(shape=(self.num_leaf, self.num_class), initializer='random_uniform',\n",
    "                             trainable=True)\n",
    "        self.cut_points_list = [self.add_weight(shape=(cut_val,), initializer='random_uniform', trainable=True) \n",
    "                                for cut_val in self.num_cut]\n",
    "        super(DT, self).build(input_shape) \n",
    "        \n",
    "    def kron_prod(self, a, b):\n",
    "        res = np.einsum('ij,ik->ijk', a, b)\n",
    "        res = np.reshape(res, (-1, np.prod(res.shape[1:])))\n",
    "        return res\n",
    "    \n",
    "    def binn(self, x, cut_points, temperature=0.1):\n",
    "        # x is a N-by-1 matrix (column vector)\n",
    "        # cut_points is a D-dim vector (D is the number of cut-points)\n",
    "        # this function produces a N-by-(D+1) matrix, each row has only one element being one and the rest are all zeros\n",
    "        D = cut_points.shape[0]\n",
    "        W = np.reshape(np.linspace(1.0, D + 1.0, D + 1), (1,-1))\n",
    "        cut_points = np.sort(np.array([cut_points]))  # make sure cut_points is monotonically increasing\n",
    "        b = np.cumsum(np.concatenate([np.array([0]), -cut_points], 0), dtype='float32')\n",
    "        #b = np.cumsum(np.concatenate([K.variable(value= [[0]]), -cut_points], 0))#, dtype='float32')\n",
    "        h = tf.matmul(x, W) + b\n",
    "        res =keras.activations.softmax(h / temperature) \n",
    "        #np.exp(h / temperature) / tf.reduce_sum(tf.exp(logits), axis)\n",
    "        return res\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        leaf = reduce(self.kron_prod, map(lambda z: self.binn(inputs[:, z[0]:z[0] + 1], z[1],\n",
    "                    self.temperature), enumerate(self.cut_points_list)))\n",
    "        \n",
    "        return np.matmul(leaf, self.leaf_score)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.num_class)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#l1 =Input(shape=(2,))\n",
    "#latent= DT([1,1], num_class=3, t=0.1)(l1)\n",
    "\n",
    "#pred = Dense(3, activation='sigmoid')(latent)\n",
    "\n",
    "#model_dt_2 = Model(inputs=l1, outputs= pred)\n",
    "#model_dt_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Above layer has some incosistency in clubbing with a Dense layer that follows.\n",
    "* Results from above Needs to be evaluated with TF 2.0, alongside results from author's demo.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So the following training is done with a model defined using tf.keras & keras conventions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris= load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= iris.data\n",
    "y=iris.target\n",
    "\n",
    "x= x[:,2:4]#taking Petal width, Petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X & y shapes: (150, 2) (150, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "\n",
    "y = to_categorical(y)\n",
    "print('X & y shapes:', x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt= optimizers.Adam()\n",
    "loss= losses.categorical_crossentropy \n",
    "model_dt_2.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/16\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 1.1158 - accuracy: 0.3333\n",
      "Epoch 2/16\n",
      "150/150 [==============================] - 0s 107us/step - loss: 1.1135 - accuracy: 0.3333\n",
      "Epoch 3/16\n",
      "150/150 [==============================] - 0s 120us/step - loss: 1.1117 - accuracy: 0.3333\n",
      "Epoch 4/16\n",
      "150/150 [==============================] - 0s 83us/step - loss: 1.1100 - accuracy: 0.3333\n",
      "Epoch 5/16\n",
      "150/150 [==============================] - 0s 130us/step - loss: 1.1083 - accuracy: 0.3333\n",
      "Epoch 6/16\n",
      "150/150 [==============================] - 0s 108us/step - loss: 1.1069 - accuracy: 0.3333\n",
      "Epoch 7/16\n",
      "150/150 [==============================] - 0s 126us/step - loss: 1.1054 - accuracy: 0.3333\n",
      "Epoch 8/16\n",
      "150/150 [==============================] - 0s 109us/step - loss: 1.1043 - accuracy: 0.3333\n",
      "Epoch 9/16\n",
      "150/150 [==============================] - 0s 113us/step - loss: 1.1033 - accuracy: 0.3333\n",
      "Epoch 10/16\n",
      "150/150 [==============================] - 0s 91us/step - loss: 1.1021 - accuracy: 0.3333\n",
      "Epoch 11/16\n",
      "150/150 [==============================] - 0s 124us/step - loss: 1.1011 - accuracy: 0.3333\n",
      "Epoch 12/16\n",
      "150/150 [==============================] - 0s 108us/step - loss: 1.1000 - accuracy: 0.3333\n",
      "Epoch 13/16\n",
      "150/150 [==============================] - 0s 128us/step - loss: 1.0991 - accuracy: 0.3333\n",
      "Epoch 14/16\n",
      "150/150 [==============================] - 0s 89us/step - loss: 1.0981 - accuracy: 0.3333\n",
      "Epoch 15/16\n",
      "150/150 [==============================] - 0s 155us/step - loss: 1.0973 - accuracy: 0.3333\n",
      "Epoch 16/16\n",
      "150/150 [==============================] - 0s 128us/step - loss: 1.0964 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe3e5f10cf8>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt_2.fit(x,y,batch_size=8, epochs=16, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `tensorflow.keras` implementation of Custom DT layer: with TF 2.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from functools import reduce\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DT(layers.Layer):\n",
    "    \"\"\"\n",
    "    --config:    \n",
    "        input args:\n",
    "        num_class: no. of classes/ no of units /output dims.\n",
    "        num_cut: no. of cuts for each feature\n",
    "        temperature: t\n",
    "        \n",
    "        returns:\n",
    "        tf.Keras DT layer\n",
    "    \"\"\"    \n",
    "    def __init__(self, cuts_per_feat, num_class=3, t=0.1, **kwargs):\n",
    "        super(DT, self).__init__(**kwargs)\n",
    "        self.num_class= num_class #determines output dims\n",
    "        self.num_cut= cuts_per_feat\n",
    "        self.temperature= t\n",
    "        self.num_leaf = tf.math.reduce_prod(tf.constant(cuts_per_feat)+1)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        assert input_shape[1]==len(self.num_cut), 'Num. of defined cut points and input feature count is unequal; Define cut points for each input feature'\n",
    "        #Add some assertion input_shape[1]==len(num_cut)\n",
    "        \n",
    "        self.leaf_score= self.add_weight(shape=(self.num_leaf, self.num_class), initializer='random_uniform',\n",
    "                             trainable=True)\n",
    "        self.cut_points_list = [self.add_weight(shape=(cut_val,), initializer='random_uniform', trainable=True) \n",
    "                                for cut_val in self.num_cut]\n",
    "        \n",
    "        self.built= True\n",
    "        #[tf.Variable(tf.random.uniform([i])) for i in self.num_cut]\n",
    "        \n",
    "    def kron_prod(self, a, b):\n",
    "        res = tf.einsum('ij,ik->ijk', a, b)\n",
    "        res = tf.reshape(res, [-1, tf.math.reduce_prod(res.shape[1:])])\n",
    "        return res    \n",
    "    \n",
    "    def binn(self, x, cut_points, temperature):        \n",
    "        # x is a N-by-1 matrix (column vector)\n",
    "        # cut_points is a D-dim vector (D is the number of cut-points)\n",
    "        # this function produces a N-by-(D+1) matrix, each row has only one element being one and the rest are all zeros\n",
    "        D = cut_points.get_shape().as_list()[0]\n",
    "        W = tf.reshape(tf.linspace(1.0, D + 1.0, D + 1), [1, -1])#corresponds to list of no. of cut_points\n",
    "        #Or use tf.Variable(tf.reshape(tf.linspace(1.0, D + 1.0, D + 1), [1, -1]), trainable=False)\n",
    "        \n",
    "        cut_points = tf.sort(cut_points)  # makes sure cut_points is monotonically increasing\n",
    "        b = tf.cumsum(tf.concat([tf.constant(0.0, shape=[1]), -cut_points], 0))#outputs list os cutpoints as [0,-b1,-b1]\n",
    "        \n",
    "        h = tf.matmul(x, W) + b\n",
    "        res = tf.nn.softmax(h / temperature)\n",
    "        return res\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        leaf = reduce(self.kron_prod, \n",
    "            map(lambda z: self.binn(inputs[:, z[0]:z[0] + 1], z[1], self.temperature), \n",
    "                enumerate(self.cut_points_list)))\n",
    "        return tf.matmul(leaf, self.leaf_score)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.num_class)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dt_5 (DT)                    (None, 3)                 14        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 26\n",
      "Trainable params: 26\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "l1 =Input(shape=(2))\n",
    "latent= DT([1,1], num_class=3, t=0.1)(l1)\n",
    "pred = Dense(3, activation='sigmoid')(latent)\n",
    "\n",
    "model_dt_3 = Model(inputs=l1, outputs= pred)\n",
    "model_dt_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X & y shapes: (150, 2) (150, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris= load_iris()\n",
    "\n",
    "x= iris.data\n",
    "y=iris.target\n",
    "\n",
    "x= x[:,2:4]#taking Petal width, Petal width\n",
    "y = to_categorical(y)\n",
    "print('X & y shapes:', x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/16\n",
      "150/150 [==============================] - 2s 10ms/sample - loss: 1.0987 - accuracy: 0.3333\n",
      "Epoch 2/16\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 1.0980 - accuracy: 0.6133\n",
      "Epoch 3/16\n",
      "150/150 [==============================] - 0s 169us/sample - loss: 1.0970 - accuracy: 0.5600\n",
      "Epoch 4/16\n",
      "150/150 [==============================] - 0s 220us/sample - loss: 1.0958 - accuracy: 0.5600\n",
      "Epoch 5/16\n",
      "150/150 [==============================] - 0s 216us/sample - loss: 1.0933 - accuracy: 0.5800\n",
      "Epoch 6/16\n",
      "150/150 [==============================] - 0s 201us/sample - loss: 1.0900 - accuracy: 0.6067\n",
      "Epoch 7/16\n",
      "150/150 [==============================] - 0s 207us/sample - loss: 1.0854 - accuracy: 0.6067\n",
      "Epoch 8/16\n",
      "150/150 [==============================] - 0s 186us/sample - loss: 1.0784 - accuracy: 0.6067\n",
      "Epoch 9/16\n",
      "150/150 [==============================] - 0s 165us/sample - loss: 1.0692 - accuracy: 0.6067\n",
      "Epoch 10/16\n",
      "150/150 [==============================] - 0s 172us/sample - loss: 1.0568 - accuracy: 0.6133\n",
      "Epoch 11/16\n",
      "150/150 [==============================] - 0s 188us/sample - loss: 1.0417 - accuracy: 0.6533\n",
      "Epoch 12/16\n",
      "150/150 [==============================] - 0s 138us/sample - loss: 1.0234 - accuracy: 0.6533\n",
      "Epoch 13/16\n",
      "150/150 [==============================] - 0s 182us/sample - loss: 1.0023 - accuracy: 0.6533\n",
      "Epoch 14/16\n",
      "150/150 [==============================] - 0s 134us/sample - loss: 0.9795 - accuracy: 0.6533\n",
      "Epoch 15/16\n",
      "150/150 [==============================] - 0s 149us/sample - loss: 0.9542 - accuracy: 0.6600\n",
      "Epoch 16/16\n",
      "150/150 [==============================] - 0s 198us/sample - loss: 0.9286 - accuracy: 0.6600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1906a4b438>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt= optimizers.Adam()\n",
    "loss= losses.categorical_crossentropy \n",
    "model_dt_3.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "model_dt_3.fit(x,y,batch_size=8, epochs=16, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Trying Titatnic dataset(3 input features) with above layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data2 = pd.read_csv('titanic//train.csv')\n",
    "data2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le= LabelEncoder()\n",
    "data2['Sex'] = le.fit_transform(data2['Sex'])\n",
    "data2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2_cols= list(data2.columns)\n",
    "data2_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X & y shapes: (891, 3) (891, 2)\n"
     ]
    }
   ],
   "source": [
    "x = data2[['Pclass','Sex','SibSp']].values\n",
    "y = data2[['Survived']].values\n",
    "\n",
    "y = to_categorical(y)\n",
    "print('X & y shapes:', x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dt_11 (DT)                   (None, 2)                 19        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l1 =Input(shape=(3))\n",
    "latent= DT([1,1,1], num_class=2, t=0.1)(l1)\n",
    "pred = Dense(2, activation='sigmoid')(latent)\n",
    "\n",
    "model_dt_4 = Model(inputs=l1, outputs= pred)\n",
    "model_dt_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples\n",
      "Epoch 1/8\n",
      "891/891 [==============================] - 1s 935us/sample - loss: 0.6846 - accuracy: 0.6162\n",
      "Epoch 2/8\n",
      "891/891 [==============================] - 0s 117us/sample - loss: 0.6604 - accuracy: 0.6543\n",
      "Epoch 3/8\n",
      "891/891 [==============================] - 0s 129us/sample - loss: 0.6245 - accuracy: 0.7868\n",
      "Epoch 4/8\n",
      "891/891 [==============================] - 0s 126us/sample - loss: 0.5874 - accuracy: 0.7868\n",
      "Epoch 5/8\n",
      "891/891 [==============================] - 0s 117us/sample - loss: 0.5572 - accuracy: 0.7868\n",
      "Epoch 6/8\n",
      "891/891 [==============================] - 0s 116us/sample - loss: 0.5368 - accuracy: 0.7868\n",
      "Epoch 7/8\n",
      "891/891 [==============================] - 0s 134us/sample - loss: 0.5246 - accuracy: 0.7868\n",
      "Epoch 8/8\n",
      "891/891 [==============================] - 0s 174us/sample - loss: 0.5178 - accuracy: 0.7868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f18d7e89dd8>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt= optimizers.Adam()\n",
    "loss= losses.categorical_crossentropy \n",
    "model_dt_4.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "model_dt_4.fit(x,y,batch_size=8, epochs=8, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* varying `cuts_per_features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dt_13 (DT)                   (None, 2)                 79        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 85\n",
      "Trainable params: 85\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l1 =Input(shape=(3))\n",
    "latent= DT([2,2,3], num_class=2, t=0.1)(l1)\n",
    "pred = Dense(2, activation='sigmoid')(latent)\n",
    "\n",
    "model_dt_4 = Model(inputs=l1, outputs= pred)\n",
    "model_dt_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples\n",
      "Epoch 1/8\n",
      "891/891 [==============================] - 1s 968us/sample - loss: 0.6864 - accuracy: 0.6105\n",
      "Epoch 2/8\n",
      "891/891 [==============================] - 0s 122us/sample - loss: 0.6606 - accuracy: 0.7003\n",
      "Epoch 3/8\n",
      "891/891 [==============================] - 0s 152us/sample - loss: 0.6178 - accuracy: 0.7868\n",
      "Epoch 4/8\n",
      "891/891 [==============================] - 0s 167us/sample - loss: 0.5728 - accuracy: 0.7868\n",
      "Epoch 5/8\n",
      "891/891 [==============================] - 0s 162us/sample - loss: 0.5438 - accuracy: 0.7868\n",
      "Epoch 6/8\n",
      "891/891 [==============================] - 0s 126us/sample - loss: 0.5272 - accuracy: 0.7868\n",
      "Epoch 7/8\n",
      "891/891 [==============================] - 0s 118us/sample - loss: 0.5187 - accuracy: 0.7868\n",
      "Epoch 8/8\n",
      "891/891 [==============================] - 0s 127us/sample - loss: 0.5147 - accuracy: 0.7868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f18d4764588>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt= optimizers.Adam()\n",
    "loss= losses.categorical_crossentropy \n",
    "model_dt_4.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "model_dt_4.fit(x,y,batch_size=8, epochs=8, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
