{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Decision Trees: tensorflow code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DNDT Paper: https://arxiv.org/pdf/1806.06988.pdf\n",
    "* code: https://github.com/wOOL/DNDT/blob/master/tensorflow/neural_network_decision_tree.py#L10\n",
    "* Ref Notebook: https://github.com/wOOL/DNDT/blob/master/tensorflow/demo.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Key parameters defined for `nn_decision_tree(. . .)`:**\n",
    "    * `x`: Placeholder for 2 input feature values (Petal length, Petal width) in x\n",
    "    * `cut_points_list`: Variable holding randomly inititialized n `cut point values`, a trainable param.\n",
    "    * `leaf_score`: Variable holding trainable weights/values mapping last layer bins to output target class layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.feature[:, 2:4]  # use \"Petal length\" and \"Petal width\" only\n",
    "y = iris.label\n",
    "d = x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cut = [1, 1]  # \"Petal length\" and \"Petal width\"\n",
    "num_leaf = np.prod(np.array(num_cut) + 1)# 4\n",
    "num_class = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_points_list = [tf.Variable(tf.random.uniform([i])) for i in num_cut]\n",
    "leaf_score = tf.Variable(tf.random.uniform([num_leaf, num_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.38126063], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.08172297], dtype=float32)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_points_list#with TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
       "array([[0.6178036 , 0.23387122, 0.1611011 ],\n",
       "       [0.3350451 , 0.36053157, 0.40758777],\n",
       "       [0.83489025, 0.19071114, 0.0848999 ],\n",
       "       [0.04420972, 0.41416192, 0.6197046 ]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_score#from TF 2.0 eager execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Starting with `nn_decision_tree( . . .)`**\n",
    "\n",
    "* **In line 1:**\n",
    "\n",
    "`leaf = reduce(tf_kron_prod, map(lambda z: tf_bin(x[:, z[0]:z[0] + 1], z[1], temperature), enumerate(cut_points_list)))`.\n",
    "\n",
    "* `lambda` function passes `cut_points_list` values  one by one, alongside a corresponding column of feature vector x, say `x[:,0]` representing `Petal length` into `tf_bin(. . .)` functon; i.e., first passing  `cut_points_list[0]`with `x[:,0:1]`; And then `cut_points_list[1]`and `x[:,1:2]`.\n",
    "                  \n",
    "* The obtained sequence of softmax outputs of two `input features` & `two cut_points` through `tf_bin( )` is then passed into `tf_kron_prod(. . .)`\n",
    "* `result = map(lambda z: tf_bin(x[:, z[0]:z[0] + 1], z[1], 0.1), enumerate(cut_points_list))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  #1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.\n",
    "def nn_decision_tree(x, cut_points_list, leaf_score, temperature=0.1):\n",
    "    # cut_points_list contains the cut_points for each dimension of feature\n",
    "    leaf = reduce(tf_kron_prod,\n",
    "                  map(lambda z: tf_bin(x[:, z[0]:z[0] + 1], z[1], temperature), enumerate(cut_points_list)))\n",
    "    return tf.matmul(leaf, leaf_score)\n",
    "\n",
    "\n",
    "#y_pred = nn_decision_tree(x_ph, cut_points_list, leaf_score, temperature=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So `z` is arg passed into lambda from iterable `enumerate(cut_points_list)`**.\n",
    "* And `z[0]` & `z[1]` correspond to first & second `cut_points` respectively.\n",
    "* And `z[0][0]` = index & `z[0][1]` = underlying cut_point tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_point_list:\n",
      " [(0, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.38126063], dtype=float32)>), (1, <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.08172297], dtype=float32)>)] \n",
      "\n",
      "cut_point 1:\n",
      " <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.38126063], dtype=float32)> \n",
      "cut_point 2:\n",
      " <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.08172297], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "z= enumerate(cut_points_list)\n",
    "cut_list= list(z)\n",
    "print('cut_point_list:\\n',cut_list, '\\n\\ncut_point 1:\\n', cut_list[0][1], '\\ncut_point 2:\\n', cut_list[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x[:,0:1]#correspondes to x[:, z[0]:z[0] + 1], z[1] above\n",
    "#x[:,1:2]#correspondes to x[:, z[1]:z[1] + 1], z[1] above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now the above params are passed into following `tf_bin( )` function, one at a time resulting in softmax outputs**\n",
    "* the `map(lambda z: tf_bin(x[:, z[0]:z[0] + 1], z[1], temperature), enumerate(cut_points_list))` passes -- `feature 1(Petal length)` i.e., `x[:,0:1]` as `x[:, z[0]:z[0] + 1]` and corresponding `cut_list[0][1]` as `z[1]` into **`tf_bin( )`** first then `2nd feature (Petal width)` & 2nd cut_point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  #2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\n",
    "def tf_bin(x, cut_points, temperature=0.1):\n",
    "    # x is a N-by-1 matrix (column vector), corresponding to 1 feature at a time\n",
    "    # cut_points is a D-dim vector (D is the number of cut-points)\n",
    "    # this function produces a N-by-(D+1) matrix, each row has only one element being one and the rest are all zeros\n",
    "    D = cut_points.get_shape().as_list()[0]\n",
    "    W = tf.reshape(tf.linspace(1.0, D + 1.0, D + 1), [1, -1])\n",
    "    cut_points = tf.sort(cut_points)  # make sure cut_points is monotonically increasing\n",
    "    b = tf.cumsum(tf.concat([tf.constant(0.0, shape=[1]), -cut_points], 0))\n",
    "    h = tf.matmul(x, W) + b\n",
    "    res = tf.nn.softmax(h / temperature)\n",
    "    return res\n",
    "\n",
    "#tf_bin(x[:, z[0]:z[0] + 1], z[1], 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`tf_bin( )` results for `feature 1(Petal length)` i.e., `x_ph[:,0:1]` and `1st cut_point` or `z[0]`, i.e.,`cut_list[0][1]` from above.**\n",
    "    * Since the `tf_bin( )` is invoked two times, one for each `x` feature 1 & 2, also for each item from cut_point_list. Therefore computing softmax at each one's end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_list[0][1].get_shape().as_list()#value of D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=63, shape=(1, 2), dtype=float32, numpy=array([[1., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D=1\n",
    "W= tf.reshape(tf.linspace(1.0, D + 1.0, D + 1), [1, -1])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=75, shape=(1,), dtype=float32, numpy=array([0.38126063], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_pts= tf.sort(cut_list[0][1])\n",
    "cut_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following lines up sorted `cut_point` values as `[0,-b1,-b2-, . ., -bn]` as mentioned in paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.38126063], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([tf.constant(0.0, shape=[1]), -cut_pts], 0)\n",
    "tf.concat([tf.constant(0.0, shape=[1]), -cut_pts], 0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* And following results in cumulative sum `b` for 1nd cut_point as `[0,-b1,-b1-b2, -b1-b2-b3. . .-b1-b2-b3-bn]` as mentioned in paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.38126063], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= tf.cumsum(tf.concat([tf.constant(0.0, shape=[1]), -cut_pts], 0))\n",
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=114, shape=(5, 2), dtype=float32, numpy=\n",
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.constant(x[:5], dtype=tf.float32)\n",
    "inputs#converting inputs to 'float32' tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: tf.Tensor(\n",
      "[[1.4       2.4187393]\n",
      " [1.4       2.4187393]\n",
      " [1.3       2.2187393]\n",
      " [1.5       2.6187394]\n",
      " [1.4       2.4187393]], shape=(5, 2), dtype=float32) \n",
      "\n",
      "softmax results for feature 1:\n",
      " tf.Tensor(\n",
      "[[3.7640464e-05 9.9996233e-01]\n",
      " [3.7640464e-05 9.9996233e-01]\n",
      " [1.0231069e-04 9.9989772e-01]\n",
      " [1.3847483e-05 9.9998617e-01]\n",
      " [3.7640464e-05 9.9996233e-01]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temperature=0.1\n",
    "h = tf.matmul(inputs[:,0:1], W) + b\n",
    "res = tf.nn.softmax(h / temperature)\n",
    "print('h:', h,'\\n\\nsoftmax results for feature 1:\\n', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`tf_bin( )` result for `feature 2(Petal width)` i.e., `x[:,1:2]` and `2nd cut_point` or `z[1]`, i.e.,`cut_list[1][1]` from above.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.38126063], dtype=float32)>),\n",
       " (1,\n",
       "  <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.08172297], dtype=float32)>)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=152, shape=(1,), dtype=float32, numpy=array([0.08172297], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_pts2= tf.sort(cut_list[1][1])#2nd cutpoint\n",
    "cut_pts2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* And following results in cumulative sum `b` for 2nd cut_point as `[0,-b1,-b1-b2, -b1-b2-b3. . .-b1-b2-b3-bn]` as mentioned in paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.08172297], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2= tf.cumsum(tf.concat([tf.constant(0.0, shape=[1]), -cut_pts2], 0))\n",
    "b2.numpy()#b2 is list of cut_points, as in [0,-b1,-b1-b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h: tf.Tensor(\n",
      "[[0.2        0.31827703]\n",
      " [0.2        0.31827703]\n",
      " [0.2        0.31827703]\n",
      " [0.2        0.31827703]\n",
      " [0.2        0.31827703]], shape=(5, 2), dtype=float32) \n",
      "\n",
      "softmax results for feature 2:\n",
      " tf.Tensor(\n",
      "[[0.23455445 0.76544553]\n",
      " [0.23455445 0.76544553]\n",
      " [0.23455445 0.76544553]\n",
      " [0.23455445 0.76544553]\n",
      " [0.23455445 0.76544553]], shape=(5, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temperature=0.1\n",
    "h2 = tf.matmul(inputs[:,1:2], W) + b2#for feature 2 in input x_ph\n",
    "res2 = tf.nn.softmax(h2 / temperature)\n",
    "print('h:', h2,'\\n\\nsoftmax results for feature 2:\\n', res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now the above softmax values obtained in sequence are passed into following `tf_kron_prod(. . .)` function, both at a once**\n",
    "* the `reduce(tf_kron_prod, map(lambda z: tf_bin(x[:, z[0]:z[0] + 1], z[1], temperature), enumerate(cut_points_list)))` passes -- computed softmax outputs `res` for `feature 1(Petal length)` i.e., `x[:,0:1]`, cut_point 1 as `cut_list[0][1]`; And `res2` for `feature_2 (Petal width)`, cut_point 2 as `cut_list[1][1]` into **`tf_kron_prod(. . .)`**.\n",
    "* So the following are the binned values of all 5 input datapoints at the end of `kron_layer` in paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=247, shape=(5, 4), dtype=float32, numpy=\n",
       "array([[8.8287388e-06, 2.8811724e-05, 2.3454562e-01, 7.6541668e-01],\n",
       "       [8.8287388e-06, 2.8811724e-05, 2.3454562e-01, 7.6541668e-01],\n",
       "       [2.3997427e-05, 7.8313256e-05, 2.3453046e-01, 7.6536721e-01],\n",
       "       [3.2479888e-06, 1.0599494e-05, 2.3455121e-01, 7.6543492e-01],\n",
       "       [8.8287388e-06, 2.8811724e-05, 2.3454562e-01, 7.6541668e-01]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "leaf = reduce(tf_kron_prod, [res, res2])\n",
    "leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  #3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.\n",
    "def tf_kron_prod(a, b):\n",
    "    res = tf.einsum('ij,ik->ijk', a, b)\n",
    "    res = tf.reshape(res, [-1, tf.reduce_prod(res.shape[1:])])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of two softamx outputs res & res2: (5, 2) (5, 2)\n"
     ]
    }
   ],
   "source": [
    "print('shape of two softamx outputs res & res2:', res.shape, res2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To manually do what `reduce(tf_kron_prod, [res, res2])` is doing: Breaking down `tf_kron_prroduct( )`: \n",
    "    * **Inputs:**\n",
    "    * `res`: softmax output from `tf_bin( )` for `x[:,0:1]` and `cut_pts` value 1 in `cut_points_list`\n",
    "    * `res2`: softmax output from `tf_bin( )` for `x[:,1:2]` and `cut_pts2` value 2 in `cut_points_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=252, shape=(5, 2, 2), dtype=float32, numpy=\n",
       "array([[[8.8287388e-06, 2.8811724e-05],\n",
       "        [2.3454562e-01, 7.6541668e-01]],\n",
       "\n",
       "       [[8.8287388e-06, 2.8811724e-05],\n",
       "        [2.3454562e-01, 7.6541668e-01]],\n",
       "\n",
       "       [[2.3997427e-05, 7.8313256e-05],\n",
       "        [2.3453046e-01, 7.6536721e-01]],\n",
       "\n",
       "       [[3.2479888e-06, 1.0599494e-05],\n",
       "        [2.3455121e-01, 7.6543492e-01]],\n",
       "\n",
       "       [[8.8287388e-06, 2.8811724e-05],\n",
       "        [2.3454562e-01, 7.6541668e-01]]], dtype=float32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kron_res= tf.einsum('ij,ik->ijk', res, res2)\n",
    "kron_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In above `tf.einsum`, kron product is performed; wherein each softmax value of a feature is multiplied with each other softmax value for other feature.\n",
    "* Therefore in above--there are two softmax outputs for each feature,\n",
    "each softmax value for feature 1 is multiplied with each of the softmax values of feature 2. i.e. `kron_res[0][0]` correspondes to product between `res[0][0], res2[0][0]` and `res[0][0], res2[0][1]`; Similarly `kron_res[0][1]` corresponds to product between `res[0][1], res2[0][0]` and `res[0][0], res2[0][1]`.\n",
    "\n",
    "As in\n",
    "**kron_res[0][0][0]= res[0][0]* res2[0][0];** likewise\n",
    "**kron_res[0][0][1]= res[0][0]* res2[0][1]** above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kron_product is then reshaped into (None, 4), corresponding to total number of leaves in layer before predicition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_prod(kron_res.shape[1:]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=283, shape=(5, 4), dtype=float32, numpy=\n",
       "array([[8.8287388e-06, 2.8811724e-05, 2.3454562e-01, 7.6541668e-01],\n",
       "       [8.8287388e-06, 2.8811724e-05, 2.3454562e-01, 7.6541668e-01],\n",
       "       [2.3997427e-05, 7.8313256e-05, 2.3453046e-01, 7.6536721e-01],\n",
       "       [3.2479888e-06, 1.0599494e-05, 2.3455121e-01, 7.6543492e-01],\n",
       "       [8.8287388e-06, 2.8811724e-05, 2.3454562e-01, 7.6541668e-01]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kron_res= tf.reshape(kron_res, [-1, tf.reduce_prod(kron_res.shape[1:])])\n",
    "kron_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* following computes the target label as a result of vector product between output at DT leaves and Weight matrix which maps DT leaves & class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=286, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.2296738 , 0.36174935, 0.4942583 ],\n",
       "       [0.2296738 , 0.36174935, 0.4942583 ],\n",
       "       [0.22968492, 0.36174738, 0.494249  ],\n",
       "       [0.22966973, 0.3617501 , 0.49426177],\n",
       "       [0.2296738 , 0.36174935, 0.4942583 ]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In nn_decision_tree( ) line2\n",
    "y_pred = tf.matmul(leaf, leaf_score)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* results from main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=373, shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.2296738 , 0.36174935, 0.4942583 ],\n",
       "       [0.2296738 , 0.36174935, 0.4942583 ],\n",
       "       [0.22968492, 0.36174738, 0.494249  ],\n",
       "       [0.22966973, 0.3617501 , 0.49426177],\n",
       "       [0.2296738 , 0.36174935, 0.4942583 ]], dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nn_decision_tree(inputs, cut_points_list, leaf_score, temperature=0.1)\n",
    "#loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(logits=y_pred, onehot_labels=y_ph))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Obtaining bins ouputs values for a specific a input feature**\n",
    "\n",
    "[Run the following]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from functools import reduce\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X & y shapes: (150, 2) (150, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris= load_iris()\n",
    "\n",
    "x= iris.data\n",
    "y=iris.target\n",
    "\n",
    "x= x[:,2:4]#taking Petal width, Petal width\n",
    "y = to_categorical(y)\n",
    "print('X & y shapes:', x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5497626], dtype=float32)>),\n",
       " (1,\n",
       "  <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.24273801], dtype=float32)>)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binn(x, cut_points, temperature):        \n",
    "    # x is a N-by-1 matrix (column vector)\n",
    "    # cut_points is a D-dim vector (D is the number of cut-points)\n",
    "    # this function produces a N-by-(D+1) matrix, each row has only one element being one and the rest are all zeros\n",
    "    D = cut_points.get_shape().as_list()[0]\n",
    "    W = tf.reshape(tf.linspace(1.0, D + 1.0, D + 1), [1, -1])#corresponds to list of no. of cut_points\n",
    "    #Or use tf.Variable(tf.reshape(tf.linspace(1.0, D + 1.0, D + 1), [1, -1]), trainable=False)\n",
    "        \n",
    "    cut_points = tf.sort(cut_points)  # makes sure cut_points is monotonically increasing\n",
    "    b = tf.cumsum(tf.concat([tf.constant(0.0, shape=[1]), -cut_points], 0))#outputs list os cutpoints as [0,-b1,-b1]\n",
    "        \n",
    "    h = tf.matmul(x, W) + b\n",
    "    res = tf.nn.softmax(h / temperature)\n",
    "    return res\n",
    "\n",
    "#x[:2]\n",
    "temperature=0.1\n",
    "cut_points_list = [tf.Variable(tf.random.uniform([i])) for i in [1,1]]\n",
    "c_pt= list(enumerate(cut_points_list))\n",
    "c_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.5497626], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_pt[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=422, shape=(2,), dtype=float32, numpy=array([ 0.       , -0.5497626], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_points = tf.sort(c_pt[0][1])  # makes sure cut_points is monotonically increasing\n",
    "b = tf.cumsum(tf.concat([tf.constant(0.0, shape=[1]), -cut_points], 0))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=428, shape=(1, 2), dtype=float32, numpy=array([[1., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D= c_pt[0][1].get_shape().as_list()[0]#D= 1 here\n",
    "W = tf.reshape(tf.linspace(1.0, D + 1.0, D + 1), [1, -1])\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=429, shape=(5, 2), dtype=float32, numpy=\n",
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2]], dtype=float32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "#np.dtype(x[0][0])#x[:2,0:1]) ##To check the dtype of input\n",
    "inputs = tf.constant(x[:5], dtype=tf.float32)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=435, shape=(5, 2), dtype=float32, numpy=\n",
       "array([[1.4      , 2.2502375],\n",
       "       [1.4      , 2.2502375],\n",
       "       [1.3      , 2.0502372],\n",
       "       [1.5      , 2.4502373],\n",
       "       [1.4      , 2.2502375]], dtype=float32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = tf.matmul(inputs[:,0:1], W) + b\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Softmax outputs taking into account cut_points per feature and input feature column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a1 : corresponds to softmax outputs for input feature 1 & cut_point 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=505, shape=(5, 2), dtype=float32, numpy=\n",
       "array([[2.0294457e-04, 9.9979705e-01],\n",
       "       [2.0294457e-04, 9.9979705e-01],\n",
       "       [5.5146980e-04, 9.9944848e-01],\n",
       "       [7.4668860e-05, 9.9992537e-01],\n",
       "       [2.0294457e-04, 9.9979705e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1= binn(inputs[:,0:1], c_pt[0][1], temperature)\n",
    "a1#softmax outputs (batch_size, num_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a2 : corresponds to softmax outputs for input feature 2 & cut_point 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=544, shape=(5, 2), dtype=float32, numpy=\n",
       "array([[0.6052479 , 0.39475214],\n",
       "       [0.6052479 , 0.39475214],\n",
       "       [0.6052479 , 0.39475214],\n",
       "       [0.6052479 , 0.39475214],\n",
       "       [0.6052479 , 0.39475214]], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2= binn(inputs[:, 1:2], c_pt[1][1], temperature)\n",
    "a2#softmax outputs (batch_size, num_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtaining kron outputs for specific inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax values for 1st input at the end of binning layer:\n",
      " [[2.0294457e-04 9.9979705e-01]] [[0.6052479  0.39475214]]\n"
     ]
    }
   ],
   "source": [
    "def kron_prod(a, b):\n",
    "    res = tf.einsum('ij,ik->ijk', a, b)\n",
    "    res = tf.reshape(res, [-1, tf.math.reduce_prod(res.shape[1:])])\n",
    "    return res\n",
    "\n",
    "a11= a1[:1].numpy()\n",
    "a21= a2[:1].numpy()\n",
    "print('softmax values for 1st input at the end of binning layer:\\n', a11, a21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Computes, aligns the dot product of softmax val. of each feature with every other feature's softmax vals. along rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=578, shape=(1, 2, 2), dtype=float32, numpy=\n",
       "array([[[1.2283179e-04, 8.0112804e-05],\n",
       "        [6.0512507e-01, 3.9467204e-01]]], dtype=float32)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.einsum('ij,ik->ijk', a1[:1],a2[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2283179e-04, 8.0112804e-05, 6.0512507e-01, 3.9467204e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kron_prod(a1[:1],a2[:1]).numpy()# Same as reduce(kron_prod, [a1[:1],a2[:1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Kron product : manual product each softmax output of a feature with  each other output of other feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st element in kron_prod: 0.00012283179 \n",
      "last element in kron_prod: 0.39467204\n",
      "Which is same as tf.einsum\n"
     ]
    }
   ],
   "source": [
    "print('1st element in kron_prod:',a11[0][0]*a21[0][0],'\\nlast element in kron_prod:',a11[0][1]*a21[0][1])\n",
    "print('Which is same as tf.einsum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If there were 3 input features & the cuts_per_feature were be [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=685, shape=(1, 8), dtype=float32, numpy=\n",
       "array([[2.4928044e-08, 1.2280686e-04, 1.6258459e-08, 8.0096543e-05,\n",
       "        1.2280684e-04, 6.0500228e-01, 8.0096550e-05, 3.9459193e-01]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(kron_prod, [a1[:1],a2[:1],a1[:1]])#Same as kron_prod(kron_prod(a1,a2), a1)\n",
    "##that is first elemenet is computed as:\n",
    "#kron_prod(a1[:1],a2[:1]).numpy()[0][0] * a11[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
