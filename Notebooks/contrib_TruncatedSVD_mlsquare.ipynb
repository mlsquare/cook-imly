{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributing Sklearn's decompositon SVD to mlsquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fork mlsquare repository to your account and clone.**\n",
    "\n",
    "**Or just Clone https://github.com/mlsquare/mlsquare.git**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Navigate to `src/mlsquare/architectures` folder, Where the code for mapping `TruncatedSVD()` to `tf.linalg.svd()` resides.\n",
    "* The code for mapping primal model(SVD) to corresponding TF equivalent is saved in `sklearn.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kev/Desktop/mlsquare/src'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Register the proxy SVD model in `mlsquare/architecture/sklearn.py` as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-11-20 14:02:24,075\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-11-20_14-02-24_5650/logs.\n",
      "2019-11-20 14:02:24,202\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:24890 to respond...\n",
      "2019-11-20 14:02:24,323\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:34796 to respond...\n",
      "2019-11-20 14:02:24,326\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-11-20 14:02:24,347\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    }
   ],
   "source": [
    "#from ..base import registry, BaseModel\n",
    "from mlsquare.base import registry, BaseModel\n",
    "from mlsquare.adapters.sklearn import SklearnKerasDecompose\n",
    "from mlsquare.architectures.sklearn import GeneralizedLinearModel\n",
    "\n",
    "#from mlsquare.adapters.sklearn import #SurpriselibModels\n",
    "\n",
    "@registry.register\n",
    "class SVD(GeneralizedLinearModel):\n",
    "    def __init__(self):\n",
    "        self.adapter = SklearnKerasDecompose\n",
    "        self.module_name = 'sklearn'\n",
    "        self.name = 'TruncatedSVD'\n",
    "        self.version = 'default'\n",
    "        model_params = {'full_matrices': False,\n",
    "                       'compute_uv': True,\n",
    "                      'name':None}\n",
    "\n",
    "              #          }\n",
    "\n",
    "        self.set_params(params=model_params, set_by='model_init')\n",
    "    def create_model(self, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define an adapter `SklearnKerasDecompose` for mapping `sklearn.decomposition.TruncatedSVD`  to `tensorflow.linalg.svd` in `mlsquare/adapters/sklearn.py` to work with sklearn methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.utils.functions import _parse_params\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class SklearnKerasDecompose():\n",
    "    def __init__(self, proxy_model, primal_model, **kwargs):\n",
    "        self.primal_model = primal_model\n",
    "        self.params = None ## Temporary!\n",
    "        self.proxy_model = proxy_model\n",
    "        \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.fit_transform(X)\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None,**kwargs):\n",
    "        kwargs.setdefault('full_matrices', False)\n",
    "        kwargs.setdefault('params', self.params)\n",
    "        kwargs.setdefault('space', False)\n",
    "        kwargs.setdefault('compute_uv', True)\n",
    "        kwargs.setdefault('name', None)\n",
    "        self.params = kwargs['params']\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        primal_model = self.primal_model\n",
    "        self.proxy_model.num_components= primal_model.n_components\n",
    "        \n",
    "        sess= tf.Session()#for TF  1.13\n",
    "        s,u,v= sess.run(tf.linalg.svd(X))#for TF  1.13\n",
    "        #s: singular values\n",
    "        #u: normalised projection distances\n",
    "        #v: decomposition/projection orthogonal axes\n",
    "        \n",
    "        self.proxy_model.components_= v[:self.proxy_model.num_components,:]#analogous to TruncatedSVD().components_ Or primal_model.components_ Or Vh component from randomised SVD\n",
    "        #Sigma = s[:self.proxy_model.num_components]\n",
    "        X_transformed = u[:,:self.proxy_model.num_components] * s[:self.proxy_model.num_components]\n",
    "        self.singular_values_ = s[:self.proxy_model.num_components]# Store the n_components singular values            \n",
    "        return X_transformed\n",
    "    \n",
    "    def explained_variance_(self):\n",
    "        print('Method not implemented yet!')\n",
    "        \n",
    "    def explained_variance_ratio_(self):\n",
    "        print('Method not implemented yet!')    \n",
    "    \n",
    "    def explain(self, **kwargs):\n",
    "        # @param: SHAP or interpret\n",
    "        print('Coming soon...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* registered methods so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sklearn',\n",
       "  'xyz'): {'default': [<mlsquare.architectures.sklearn.SVD_1 at 0x7fc68d0309b0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasDecompose_1]},\n",
       " ('sklearn',\n",
       "  'TruncatedSVD'): {'default': [<__main__.SVD at 0x7fc69ba24be0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasDecompose]},\n",
       " ('sklearn',\n",
       "  'LogisticRegression'): {'default': [<mlsquare.architectures.sklearn.LogisticRegression at 0x7fc6ec451fd0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'LinearRegression'): {'default': [<mlsquare.architectures.sklearn.LinearRegression at 0x7fc6ec45e1d0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Ridge'): {'default': [<mlsquare.architectures.sklearn.Ridge at 0x7fc6ec45e390>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Lasso'): {'default': [<mlsquare.architectures.sklearn.Lasso at 0x7fc6ec45e550>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'ElasticNet'): {'default': [<mlsquare.architectures.sklearn.ElasticNet at 0x7fc6ec45e710>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'LinearSVC'): {'default': [<mlsquare.architectures.sklearn.LinearSVC at 0x7fc6ec45e8d0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'SVC'): {'default': [<mlsquare.architectures.sklearn.SVC at 0x7fc6ec45ec18>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'DecisionTreeClassifier'): {'default': [<mlsquare.architectures.sklearn.DecisionTreeClassifier at 0x7fc6ec45ef60>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlsquare.base import registry\n",
    "registry.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Once the new model is registered & corresponding adapter is defined in mlsquare framework.**)\n",
    "#### User Interaction with `dope` with sklearn SVD preference & intent to utilise underlying TF SVD \n",
    "\n",
    "    \n",
    "\n",
    "    1. a) User instantiates a primal model `sklearn.decomposition.TruncatedSVD` with args --`n_components` as number of required singular components.\n",
    "    b) User loads the data & proceed with necessary data preparation steps \n",
    "    \n",
    "    \n",
    "    2. Now, import `dope` from mlsquare & `dope` the primal model by passing primal model to dope function. The `dope` function equips above primal model with standard sklearn methods--`fit, fit_transform, save, explain.`\n",
    "    \n",
    "    3.  Carry on with usual sklearn SVD methods; Try out sklearn \n",
    "    methods -- `.fit( )` & `.fit_transform( )` with the doped model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a Instantiate primal module\n",
    "* n_components: 10 (number of reduced dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "primal = TruncatedSVD(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'randomized',\n",
       " 'n_components': 10,\n",
       " 'n_iter': 5,\n",
       " 'random_state': None,\n",
       " 'tol': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primal.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b Following are data preparation steps required to instantiate a svd model\n",
    "* Also evaluating the regression results at various stages with varying dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "reg= linear_model.LinearRegression()\n",
    "\n",
    "boston =load_boston()\n",
    "df_x= pd.DataFrame(boston.data, columns= boston.feature_names)\n",
    "lbe= LabelEncoder()\n",
    "df_x = df_x.apply(lambda x: lbe.fit_transform(x))#df_x[col]))\n",
    "df_y= df_y= pd.DataFrame(boston.target)\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df_x, df_y, test_size=0.2)\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>320</td>\n",
       "      <td>172</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>356</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>279</td>\n",
       "      <td>225</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>356</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>400</td>\n",
       "      <td>159</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>271</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>383</td>\n",
       "      <td>112</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>311</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>395</td>\n",
       "      <td>139</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>356</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRIM  ZN  INDUS  CHAS  NOX   RM  AGE  DIS  RAD  TAX  PTRATIO    B  LSTAT\n",
       "0     0   3     19     0   51  320  172  297    0   34        9  356     53\n",
       "1    23   0     56     0   36  279  225  333    1   11       23  356    161\n",
       "2    22   0     56     0   36  400  159  333    1   11       23  271     28\n",
       "3    32   0     16     0   33  383  112  361    2    5       31  311      6\n",
       "4   110   0     16     0   33  395  139  361    2    5       31  356     64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating results with full dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7718433212036813\n"
     ]
    }
   ],
   "source": [
    "reg= linear_model.LinearRegression()\n",
    "reg.fit(xtrain, ytrain)\n",
    "print(reg.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating results with reduced dimensionality through primal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn_svd truncated dims: (506, 10)\n",
      "0.7610344819179395\n"
     ]
    }
   ],
   "source": [
    "skl_truncated_x = primal.fit(df_x).transform(df_x)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(skl_truncated_x, df_y, test_size=0.2)\n",
    "print('sklearn_svd truncated dims:', skl_truncated_x.shape)\n",
    "reg= linear_model.LinearRegression()\n",
    "reg.fit(xtrain, ytrain)\n",
    "print(reg.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. dope the model to obtain keras svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    }
   ],
   "source": [
    "from mlsquare import dope\n",
    "\n",
    "model = dope(primal)# adapter(proxy_model=proxy_model, primal_model=primal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy model object from registry:\n",
      " <__main__.SVD object at 0x7fc69ba24be0>\n"
     ]
    }
   ],
   "source": [
    "print('proxy model object from registry:\\n', model.proxy_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Try out sklearn methods-- `.fit( )` & `.fit_transform( )` to obtained reduced dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input arr a:\n",
      " [[-0.37185829  0.92336504  1.5171664   1.18310932]\n",
      " [ 0.33509612 -0.25202299  2.27541814 -0.01449869]\n",
      " [-1.53221078 -0.50267072 -1.10473735  0.46878196]\n",
      " [-0.90897815  0.47738812 -1.0676476  -2.14099275]\n",
      " [-1.00401905  0.38661532  0.55889188 -0.32992535]] \n",
      "\n",
      "shape of a: (5, 4) \n",
      "\n",
      "dtype of a: float64\n"
     ]
    }
   ],
   "source": [
    "a= np.random.randn(5,4)\n",
    "print('input arr a:\\n',a,'\\n\\nshape of a:', a.shape, '\\n\\ndtype of a:', a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.765971  ,  0.07249544, -1.10125291,  0.59645285],\n",
       "       [ 1.97173184, -1.00333899, -0.06425587, -0.67453579],\n",
       "       [-1.16614764,  1.03002233, -1.16152227, -0.52016207],\n",
       "       [-2.12782336, -1.44799052, -0.36044253,  0.15373504],\n",
       "       [ 0.04632845, -0.639334  , -1.07900081, -0.05999566]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_truncated_x= model.fit_transform(a)\n",
    "tf_truncated_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_truncated_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Similarly with sklearn's `boston_dataset` from `1.b` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2= np.array(df_x.values, dtype= np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 471.04962214,  330.53051303,    8.67494127, ...,  -10.20964288,\n",
       "         -11.40944565,   26.75673524],\n",
       "       [ 545.473621  ,  266.09903932,   78.12796733, ...,   19.84120668,\n",
       "          -4.45406447,   -5.85600368],\n",
       "       [ 477.92571461,  357.67984616,  -89.8250494 , ...,   28.90475808,\n",
       "          -3.75504454,   -3.6268214 ],\n",
       "       ...,\n",
       "       [ 533.89491136,  184.50034054, -103.19963966, ...,   29.29001292,\n",
       "          13.7427487 ,   -3.59156992],\n",
       "       [ 545.86519119,  132.99450123, -118.31830091, ...,   28.33873663,\n",
       "          12.90476995,   -3.26489671],\n",
       "       [ 463.39533327,  126.36114053,   96.81230318, ...,   29.68789887,\n",
       "           7.78444792,    4.41248029]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dope_truncated_x= model.fit_transform(inp2)\n",
    "dope_truncated_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dope_truncated_x.shape\n",
    "#dimensionality reduced to n_components using tf.linalg.svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating results with reduced dimensionality through doped model & ascertaining approximately faithful results through underlying TF method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doped_svd truncated dims: (506, 10)\n",
      "0.6110820718545925\n"
     ]
    }
   ],
   "source": [
    "#truncated_x= model.fit(df_x).fit_transform(df_x)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(dope_truncated_x, df_y, test_size=0.2)\n",
    "\n",
    "print('doped_svd truncated dims:', dope_truncated_x.shape)\n",
    "\n",
    "reg= linear_model.LinearRegression()\n",
    "reg.fit(xtrain, ytrain)\n",
    "print(reg.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(skl_truncated_x, dope_truncated_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
