{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.imly import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sklearn',\n",
       "  'LogisticRegression'): {'default': [<mlsquare.imly.architectures.sklearn.LogisticRegression at 0x7f681d9d72e8>,\n",
       "   mlsquare.imly.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'LinearRegression'): {'default': [<mlsquare.imly.architectures.sklearn.LinearRegression at 0x7f681d9d7748>,\n",
       "   mlsquare.imly.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Ridge'): {'default': [<mlsquare.imly.architectures.sklearn.Ridge at 0x7f681d9f67f0>,\n",
       "   mlsquare.imly.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Lasso'): {'default': [<mlsquare.imly.architectures.sklearn.Lasso at 0x7f681d6c12e8>,\n",
       "   mlsquare.imly.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'ElasticNet'): {'default': [<mlsquare.imly.architectures.sklearn.ElasticNet at 0x7f681d6c1400>,\n",
       "   mlsquare.imly.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'LinearSVC'): {'default': [<mlsquare.imly.architectures.sklearn.LinearSVC at 0x7f681d6c14e0>,\n",
       "   mlsquare.imly.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'SVC'): {'default': [<mlsquare.imly.architectures.sklearn.SVC at 0x7f681d6c16a0>,\n",
       "   mlsquare.imly.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'CART'): {'default': [<mlsquare.imly.architectures.sklearn.DecisionTreeClassifier at 0x7f681d6c19e8>,\n",
       "   mlsquare.imly.adapters.sklearn.SklearnKerasClassifier]}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing new arch on Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-07-11 16:21:14,830\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-11_16-21-14_3919/logs.\n",
      "2019-07-11 16:21:14,939\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:51658 to respond...\n",
      "2019-07-11 16:21:15,050\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:28296 to respond...\n",
      "2019-07-11 16:21:15,051\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-07-11 16:21:15,073\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer adam\n",
      "loss binary_crossentropy\n"
     ]
    }
   ],
   "source": [
    "from mlsquare.imly import dope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.linear_model.logistic\n",
      "from functions -- sklearn\n",
      "Transpiling your model to it's Deep Neural Network equivalent...\n",
      "from dope --  sklearn LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "m = dope(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"../data/iris.csv\"\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.imly.utils.functions import _parse_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "params = {\n",
    "    'optimization': tune.grid_search(['adam', 'nadam'])\n",
    "}\n",
    "\n",
    "# _parse_params(params, return_as='flat')\n",
    "# params['optimization'].items()\n",
    "# tune.grid_search([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2019-07-12 14:37:18,152\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-07-12 14:37:18,153\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimization {'grid_search': ['adam', 'nadam']}\n",
      "{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'sigmoid', 'optimizer': 'adam', 'loss': 'binary_crossentropy', 'optimization': {'grid_search': ['adam', 'nadam']}}\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.1/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.1/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'RUNNING': 1, 'PENDING': 1})\n",
      "PENDING trials:\n",
      " - train_model_1_optimization=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_optimization=adam:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m 2019-07-12 14:37:21,771\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m config from tune --  {'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'sigmoid', 'optimizer': 'adam', 'loss': 'binary_crossentropy', 'optimization': 'adam'}\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m 2019-07-12 14:37:21.998427: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m 2019-07-12 14:37:22.019662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m 2019-07-12 14:37:22.020104: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c807f28ce0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m 2019-07-12 14:37:22.020126: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 14:37:22,567\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.16294527053833008 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-12 14:37:22,570\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0_optimization=adam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_0_optimization=adam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''sigmoid'', ''optimizer'': ''adam'', ''loss'': ''binary_crossentropy'',\n",
      "    ''optimization'': ''adam''}.h5'\n",
      "  date: 2019-07-12_14-37-22\n",
      "  done: false\n",
      "  experiment_id: 25c5e78314db4679a81f2d3e9f5e4752\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.55\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 22608\n",
      "  time_since_restore: 0.5893383026123047\n",
      "  time_this_iter_s: 0.5893383026123047\n",
      "  time_total_s: 0.5893383026123047\n",
      "  timestamp: 1562922442\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m 32/40 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=22608)\u001b[0m 40/40 [==============================] - 0s 455us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 14:37:22,791\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.21942639350891113 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-12 14:37:23,295\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.47644495964050293 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 1, 'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_1_optimization=nadam:\tRUNNING\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimization=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=22608], 0 s, 1 iter, 0.55 acc\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m 2019-07-12 14:37:26,117\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m config from tune --  {'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'sigmoid', 'optimizer': 'adam', 'loss': 'binary_crossentropy', 'optimization': 'nadam'}\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m 2019-07-12 14:37:26.337350: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m 2019-07-12 14:37:26.359568: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m 2019-07-12 14:37:26.360094: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5628c512dce0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m 2019-07-12 14:37:26.360114: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 14:37:26,749\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_1_optimization=nadam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_1_optimization=nadam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''sigmoid'', ''optimizer'': ''adam'', ''loss'': ''binary_crossentropy'',\n",
      "    ''optimization'': ''nadam''}.h5'\n",
      "  date: 2019-07-12_14-37-26\n",
      "  done: false\n",
      "  experiment_id: 3329f36b26fe42dfb3b6fd84d5bfe973\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.45\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 22609\n",
      "  time_since_restore: 0.5220222473144531\n",
      "  time_this_iter_s: 0.5220222473144531\n",
      "  time_total_s: 0.5220222473144531\n",
      "  timestamp: 1562922446\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m 32/40 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=22609)\u001b[0m 40/40 [==============================] - 0s 426us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 14:37:27,251\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.500340461730957 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 2})\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimization=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=22608], 0 s, 1 iter, 0.55 acc\n",
      " - train_model_1_optimization=nadam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=22609], 0 s, 1 iter, 0.45 acc\n",
      "\n",
      "Creating model...\n",
      "{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'sigmoid', 'optimizer': 'adam', 'loss': 'binary_crossentropy', 'optimization': 'adam'}\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_optimization=adam_2019-07-12_14-37-1825kan4qd/weights_tune_{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'sigmoid', 'optimizer': 'adam', 'loss': 'binary_crossentropy', 'optimization': 'adam'}.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fede01f0be0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 259us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1402924060821533, 0.4666666626930237]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('sklearn', 'LogisticRegression'), ('sklearn', 'LinearRegression'), ('sklearn', 'Ridge'), ('sklearn', 'Lasso'), ('sklearn', 'ElasticNet'), ('sklearn', 'LinearSVC'), ('sklearn', 'SVC')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlsquare.imly import registry\n",
    "registry.data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing new arch on Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-07-11 17:02:54,077\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-11_17-02-54_7124/logs.\n",
      "2019-07-11 17:02:54,189\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:43494 to respond...\n",
      "2019-07-11 17:02:54,303\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:21330 to respond...\n",
      "2019-07-11 17:02:54,304\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-07-11 17:02:54,333\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer adam\n",
      "loss binary_crossentropy\n",
      "optimizer adam\n",
      "loss mse\n",
      "sklearn.linear_model.base\n",
      "from functions -- sklearn\n",
      "Transpiling your model to it's Deep Neural Network equivalent...\n",
      "from dope --  sklearn LinearRegression\n"
     ]
    }
   ],
   "source": [
    "from mlsquare.imly import dope\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "model = LinearRegression()\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "Y = diabetes.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "m = dope(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:03:06,498\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-07-11 17:03:06,498\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimization {'grid_search': ['adam', 'nadam']}\n",
      "{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': {'grid_search': ['adam', 'nadam']}}\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.7/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.7/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'RUNNING': 1, 'PENDING': 1})\n",
      "PENDING trials:\n",
      " - train_model_1_optimization=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_optimization=adam:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m 2019-07-11 17:03:08,549\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m config from tune --  {'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'adam'}\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m 2019-07-11 17:03:19.030581: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m 2019-07-11 17:03:19.053630: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m 2019-07-11 17:03:19.053927: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55b56d58cce0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m 2019-07-11 17:03:19.053942: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "Result for train_model_0_optimization=adam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''linear'', ''optimizer'': ''adam'', ''loss'': ''mse'',\n",
      "    ''optimization'': ''adam''}.h5'\n",
      "  date: 2019-07-11_17-03-19\n",
      "  done: false\n",
      "  experiment_id: 98a061d0c5284bcab02bb88e3de14777\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 7180\n",
      "  time_since_restore: 0.9170739650726318\n",
      "  time_this_iter_s: 0.9170739650726318\n",
      "  time_total_s: 0.9170739650726318\n",
      "  timestamp: 1562844799\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m  32/176 [====>.........................] - ETA: \n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m 176/176 [==============================] - 0s 91us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:03:20,053\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.2982962131500244 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-11 17:03:20,056\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0_optimization=adam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.8/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'RUNNING': 1, 'PENDING': 1})\n",
      "PENDING trials:\n",
      " - train_model_1_optimization=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_optimization=adam:\tRUNNING, [4 CPUs, 0 GPUs], [pid=7180], 0 s, 1 iter, 0 acc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:03:20,566\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.5078999996185303 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-11 17:03:21,294\tWARNING util.py:62 -- The `start_trial` operation took 0.7259354591369629 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m 2019-07-11 17:03:23,993\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m config from tune --  {'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'nadam'}\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m 2019-07-11 17:03:30.370615: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m 2019-07-11 17:03:30.394167: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m 2019-07-11 17:03:30.394480: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5560f3d96ce0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m 2019-07-11 17:03:30.394497: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:03:31,281\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_1_optimization=nadam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_1_optimization=nadam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''linear'', ''optimizer'': ''adam'', ''loss'': ''mse'',\n",
      "    ''optimization'': ''nadam''}.h5'\n",
      "  date: 2019-07-11_17-03-31\n",
      "  done: false\n",
      "  experiment_id: 2d5e8d1d72b142ff94d8c2f5eb9b2eb2\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 7181\n",
      "  time_since_restore: 1.030895709991455\n",
      "  time_this_iter_s: 1.030895709991455\n",
      "  time_total_s: 1.030895709991455\n",
      "  timestamp: 1562844811\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m  32/176 [====>.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=7181)\u001b[0m 176/176 [==============================] - 0s 96us/step\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.8/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 1, 'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_1_optimization=nadam:\tRUNNING, [4 CPUs, 0 GPUs], [pid=7181], 1 s, 1 iter, 0 acc\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimization=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=7180], 0 s, 1 iter, 0 acc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:03:31,788\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.5061254501342773 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.6/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 2})\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimization=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=7180], 0 s, 1 iter, 0 acc\n",
      " - train_model_1_optimization=nadam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=7181], 1 s, 1 iter, 0 acc\n",
      "\n",
      "Creating model...\n",
      "{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'adam'}\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_optimization=adam_2019-07-11_17-03-06l0gv1q5v/weights_tune_{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'adam'}.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fc5916f4fd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'optimization': {'grid_search': ['adam', 'nadam']}\n",
    "}\n",
    "\n",
    "m.fit(x_train, y_train, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 0s 17us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[28168.135602678572, 0.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = { 'units': 1,\n",
    "                'input_dim': 10,\n",
    "                'activation': 'sigmoid',\n",
    "                'optimizer': 'adam',\n",
    "                'loss': 'binary_crossentropy'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params.update({'input_dim': x_train.shape[1], 'optimizer': 'nadam'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 1,\n",
       " 'input_dim': 10,\n",
       " 'activation': 'sigmoid',\n",
       " 'optimizer': 'nadam',\n",
       " 'loss': 'binary_crossentropy'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New arch on Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-07-12 15:51:37,913\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-12_15-51-37_25812/logs.\n",
      "2019-07-12 15:51:38,027\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:13905 to respond...\n",
      "2019-07-12 15:51:38,143\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:24860 to respond...\n",
      "2019-07-12 15:51:38,146\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-07-12 15:51:38,172\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer adam\n",
      "loss binary_crossentropy\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss categorical_hinge\n",
      "optimizer adam\n",
      "loss categorical_hinge\n",
      "optimizer adam\n",
      "loss categorical_crossentropy\n",
      "sklearn.linear_model.ridge\n",
      "from functions -- sklearn\n",
      "Transpiling your model to it's Deep Neural Network equivalent...\n",
      "from dope --  sklearn Ridge\n"
     ]
    }
   ],
   "source": [
    "from mlsquare.imly import dope\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "model = Ridge()\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "Y = diabetes.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "m = dope(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimization {'grid_search': ['adam', 'nadam']}\n",
      "{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0.1, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': {'grid_search': ['adam', 'nadam']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 15:51:49,153\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-07-12 15:51:49,153\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.3/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.3/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'RUNNING': 1, 'PENDING': 1})\n",
      "PENDING trials:\n",
      " - train_model_1_optimization=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_optimization=adam:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m loss categorical_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m 2019-07-12 15:51:54,146\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m 2019-07-12 15:51:54.342553: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m 2019-07-12 15:51:54.363405: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m 2019-07-12 15:51:54.363829: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56014f821210 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m 2019-07-12 15:51:54.363844: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 15:51:55,281\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0_optimization=adam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m  32/176 [====>.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=25898)\u001b[0m 176/176 [==============================] - 0s 149us/step\n",
      "Result for train_model_0_optimization=adam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0.1, ''layer_1.activation'': ''linear'', ''optimizer'': ''adam'', ''loss'': ''mse'',\n",
      "    ''optimization'': ''adam''}.h5'\n",
      "  date: 2019-07-12_15-51-55\n",
      "  done: false\n",
      "  experiment_id: a0b718c392514095a8ad128b3d7f5e84\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 25898\n",
      "  time_since_restore: 1.0451347827911377\n",
      "  time_this_iter_s: 1.0451347827911377\n",
      "  time_total_s: 1.0451347827911377\n",
      "  timestamp: 1562926915\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.4/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'RUNNING': 1, 'PENDING': 1})\n",
      "PENDING trials:\n",
      " - train_model_1_optimization=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_optimization=adam:\tRUNNING, [4 CPUs, 0 GPUs], [pid=25898], 1 s, 1 iter, 0 acc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 15:51:55,790\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.5075442790985107 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-12 15:51:56,118\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.3078923225402832 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m loss categorical_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m 2019-07-12 15:51:59,336\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m 2019-07-12 15:51:59.670879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m 2019-07-12 15:51:59.695421: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m 2019-07-12 15:51:59.696321: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x564291fce220 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m 2019-07-12 15:51:59.696339: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 15:52:00,687\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.1529543399810791 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-12 15:52:00,690\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_1_optimization=nadam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_1_optimization=nadam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0, ''layer_1.l2'':\n",
      "    0.1, ''layer_1.activation'': ''linear'', ''optimizer'': ''adam'', ''loss'': ''mse'',\n",
      "    ''optimization'': ''nadam''}.h5'\n",
      "  date: 2019-07-12_15-52-00\n",
      "  done: false\n",
      "  experiment_id: 32f467c4d33f45f389e403fd37198993\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 25897\n",
      "  time_since_restore: 1.1565191745758057\n",
      "  time_this_iter_s: 1.1565191745758057\n",
      "  time_total_s: 1.1565191745758057\n",
      "  timestamp: 1562926920\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m  32/176 [====>.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=25897)\u001b[0m 176/176 [==============================] - 0s 130us/step\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.4/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 1, 'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_1_optimization=nadam:\tRUNNING, [4 CPUs, 0 GPUs], [pid=25897], 1 s, 1 iter, 0 acc\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimization=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=25898], 1 s, 1 iter, 0 acc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 15:52:00,796\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.10332798957824707 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.4/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 2})\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimization=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=25898], 1 s, 1 iter, 0 acc\n",
      " - train_model_1_optimization=nadam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=25897], 1 s, 1 iter, 0 acc\n",
      "\n",
      "Creating model...\n",
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_optimization=adam_2019-07-12_15-51-49a9h47lif/weights_tune_{'layer_1.units': 1, 'layer_1.l1': 0, 'layer_1.l2': 0.1, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'adam'}.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fc4f4148f98>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'optimization': {'grid_search': ['adam', 'nadam']}\n",
    "}\n",
    "\n",
    "m.fit(x_train, y_train, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 0s 134us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[28003.96012981673, 0.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 18:37:01,973\tERROR worker.py:1780 -- The node with client ID 946eac0c7615d8ca9f9b69e0bc48c3f9a3262472 has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=25888)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=25889)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n"
     ]
    }
   ],
   "source": [
    "m.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New arch on Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "2019-07-11 17:16:27,859\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-11_17-16-27_8392/logs.\n",
      "2019-07-11 17:16:27,969\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:30864 to respond...\n",
      "2019-07-11 17:16:28,087\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:21883 to respond...\n",
      "2019-07-11 17:16:28,090\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-07-11 17:16:28,122\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer adam\n",
      "loss binary_crossentropy\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "sklearn.linear_model.coordinate_descent\n",
      "from functions -- sklearn\n",
      "Transpiling your model to it's Deep Neural Network equivalent...\n",
      "from dope --  sklearn Lasso\n"
     ]
    }
   ],
   "source": [
    "from mlsquare.imly import dope\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "model = Lasso()\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "Y = diabetes.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "m = dope(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "optimization {'grid_search': ['adam', 'nadam']}\n",
      "{'layer_1.units': 1, 'layer_1.l1': 0.1, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': {'grid_search': ['adam', 'nadam']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:16:37,803\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-07-11 17:16:37,803\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.8/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.8/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'RUNNING': 1, 'PENDING': 1})\n",
      "PENDING trials:\n",
      " - train_model_1_optimization=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_optimization=adam:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m 2019-07-11 17:16:39,787\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m config from tune --  {'layer_1.units': 1, 'layer_1.l1': 0.1, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'adam'}\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m 2019-07-11 17:16:42.527804: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m 2019-07-11 17:16:42.553576: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m 2019-07-11 17:16:42.553888: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5648c4841220 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m 2019-07-11 17:16:42.553904: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:16:43,295\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0_optimization=adam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_0_optimization=adam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0.1, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''linear'', ''optimizer'': ''adam'', ''loss'': ''mse'',\n",
      "    ''optimization'': ''adam''}.h5'\n",
      "  date: 2019-07-11_17-16-43\n",
      "  done: false\n",
      "  experiment_id: c5d7033b3229434588eb505797d0935e\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 8442\n",
      "  time_since_restore: 0.9532709121704102\n",
      "  time_this_iter_s: 0.9532709121704102\n",
      "  time_total_s: 0.9532709121704102\n",
      "  timestamp: 1562845603\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'RUNNING': 1, 'PENDING': 1})\n",
      "PENDING trials:\n",
      " - train_model_1_optimization=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_optimization=adam:\tRUNNING, [4 CPUs, 0 GPUs], [pid=8442], 0 s, 1 iter, 0 acc\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m  32/176 [====>.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=8442)\u001b[0m 176/176 [==============================] - 0s 102us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:16:43,823\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.4927048683166504 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m 2019-07-11 17:16:45,336\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m config from tune --  {'layer_1.units': 1, 'layer_1.l1': 0.1, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'nadam'}\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m 2019-07-11 17:16:52.947624: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m 2019-07-11 17:16:52.969632: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m 2019-07-11 17:16:52.969969: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55bf482dece0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m 2019-07-11 17:16:52.969985: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:16:53,714\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_1_optimization=nadam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m  32/176 [====>.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=8440)\u001b[0m 176/176 [==============================] - 0s 91us/step\n",
      "Result for train_model_1_optimization=nadam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0.1, ''layer_1.l2'':\n",
      "    0, ''layer_1.activation'': ''linear'', ''optimizer'': ''adam'', ''loss'': ''mse'',\n",
      "    ''optimization'': ''nadam''}.h5'\n",
      "  date: 2019-07-11_17-16-53\n",
      "  done: false\n",
      "  experiment_id: 4b8511bb456e4a29bb98d546b56c5563\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 8440\n",
      "  time_since_restore: 0.9616527557373047\n",
      "  time_this_iter_s: 0.9616527557373047\n",
      "  time_total_s: 0.9616527557373047\n",
      "  timestamp: 1562845613\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 1, 'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_1_optimization=nadam:\tRUNNING, [4 CPUs, 0 GPUs], [pid=8440], 0 s, 1 iter, 0 acc\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimization=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=8442], 0 s, 1 iter, 0 acc\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 2})\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimization=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=8442], 0 s, 1 iter, 0 acc\n",
      " - train_model_1_optimization=nadam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=8440], 0 s, 1 iter, 0 acc\n",
      "\n",
      "Creating model...\n",
      "{'layer_1.units': 1, 'layer_1.l1': 0.1, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'adam'}\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_optimization=adam_2019-07-11_17-16-37afthwv5j/weights_tune_{'layer_1.units': 1, 'layer_1.l1': 0.1, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'adam'}.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fcff730e470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'optimization': {'grid_search': ['adam', 'nadam']}\n",
    "}\n",
    "\n",
    "m.fit(x_train, y_train, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 0s 67us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[28146.029898966164, 0.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New arch ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-07-11 17:22:15,695\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-11_17-22-15_9122/logs.\n",
      "2019-07-11 17:22:15,823\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:49299 to respond...\n",
      "2019-07-11 17:22:15,945\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:37932 to respond...\n",
      "2019-07-11 17:22:15,947\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-07-11 17:22:15,991\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer adam\n",
      "loss binary_crossentropy\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "sklearn.linear_model.coordinate_descent\n",
      "from functions -- sklearn\n",
      "Transpiling your model to it's Deep Neural Network equivalent...\n",
      "from dope --  sklearn ElasticNet\n"
     ]
    }
   ],
   "source": [
    "from mlsquare.imly import dope\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "model = ElasticNet()\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "Y = diabetes.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "m = dope(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:22:17,456\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-07-11 17:22:17,457\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimization {'grid_search': ['adam', 'nadam']}\n",
      "{'layer_1.units': 1, 'layer_1.l1': 0.1, 'layer_1.l2': 0.1, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': {'grid_search': ['adam', 'nadam']}}\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.2/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.2/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'RUNNING': 1, 'PENDING': 1})\n",
      "PENDING trials:\n",
      " - train_model_1_optimization=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_optimization=adam:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m 2019-07-11 17:22:20,598\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m config from tune --  {'layer_1.units': 1, 'layer_1.l1': 0.1, 'layer_1.l2': 0.1, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'adam'}\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m 2019-07-11 17:22:24.190612: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m 2019-07-11 17:22:25.673906: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m 2019-07-11 17:22:25.674900: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x559cc59ad1d0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m 2019-07-11 17:22:25.674923: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:22:27,891\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0_optimization=adam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m  32/176 [====>.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=9176)\u001b[0m 176/176 [==============================] - 0s 88us/step\n",
      "Result for train_model_0_optimization=adam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0.1, ''layer_1.l2'':\n",
      "    0.1, ''layer_1.activation'': ''linear'', ''optimizer'': ''adam'', ''loss'': ''mse'',\n",
      "    ''optimization'': ''adam''}.h5'\n",
      "  date: 2019-07-11_17-22-27\n",
      "  done: false\n",
      "  experiment_id: bd9ef94335904c6493d34a3ad06d8811\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 9176\n",
      "  time_since_restore: 4.410916328430176\n",
      "  time_this_iter_s: 4.410916328430176\n",
      "  time_total_s: 4.410916328430176\n",
      "  timestamp: 1562845947\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.5/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'RUNNING': 1, 'PENDING': 1})\n",
      "PENDING trials:\n",
      " - train_model_1_optimization=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_optimization=adam:\tRUNNING, [4 CPUs, 0 GPUs], [pid=9176], 4 s, 1 iter, 0 acc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:22:28,397\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.5049664974212646 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-11 17:22:28,603\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.19721245765686035 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m 2019-07-11 17:22:31,573\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m config from tune --  {'layer_1.units': 1, 'layer_1.l1': 0.1, 'layer_1.l2': 0.1, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'nadam'}\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m 2019-07-11 17:22:37.377058: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m 2019-07-11 17:22:37.397675: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m 2019-07-11 17:22:37.398260: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x563539ed8ce0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m 2019-07-11 17:22:37.398276: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:22:38,272\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_1_optimization=nadam. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_1_optimization=nadam:\n",
      "  checkpoint: 'weights_tune_{''layer_1.units'': 1, ''layer_1.l1'': 0.1, ''layer_1.l2'':\n",
      "    0.1, ''layer_1.activation'': ''linear'', ''optimizer'': ''adam'', ''loss'': ''mse'',\n",
      "    ''optimization'': ''nadam''}.h5'\n",
      "  date: 2019-07-11_17-22-38\n",
      "  done: false\n",
      "  experiment_id: 9a8f4345118d4c809207f44c55a965ac\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 9173\n",
      "  time_since_restore: 1.0243546962738037\n",
      "  time_this_iter_s: 1.0243546962738037\n",
      "  time_total_s: 1.0243546962738037\n",
      "  timestamp: 1562845958\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m  32/176 [====>.........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "\u001b[2m\u001b[36m(pid=9173)\u001b[0m 176/176 [==============================] - 0s 110us/step\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.5/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 1, 'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_1_optimization=nadam:\tRUNNING, [4 CPUs, 0 GPUs], [pid=9173], 1 s, 1 iter, 0 acc\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimization=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=9176], 4 s, 1 iter, 0 acc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:22:39,204\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.9312164783477783 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.3/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 2 ({'TERMINATED': 2})\n",
      "TERMINATED trials:\n",
      " - train_model_0_optimization=adam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=9176], 4 s, 1 iter, 0 acc\n",
      " - train_model_1_optimization=nadam:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=9173], 1 s, 1 iter, 0 acc\n",
      "\n",
      "Creating model...\n",
      "{'layer_1.units': 1, 'layer_1.l1': 0.1, 'layer_1.l2': 0.1, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'adam'}\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_optimization=adam_2019-07-11_17-22-17zq4qxexo/weights_tune_{'layer_1.units': 1, 'layer_1.l1': 0.1, 'layer_1.l2': 0.1, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'mse', 'optimization': 'adam'}.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fa810739fd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'optimization': {'grid_search': ['adam', 'nadam']}\n",
    "}\n",
    "\n",
    "m.fit(x_train, y_train, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 0s 70us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[28201.543673637218, 0.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-11 17:59:46,121\tERROR worker.py:1780 -- The node with client ID 90e1bb565b5d9ed965bd046d7e51d5cf7f1d09ae has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m E0711 18:00:04.714831  9242 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m E0711 18:00:04.714839  9236 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=9175)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=9174)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n"
     ]
    }
   ],
   "source": [
    "m.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New arch on Linear SVC\n",
    "Pending -  \n",
    "1) Setting units dynamically  \n",
    "2) enc at score level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-07-12 14:35:57,710\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-12_14-35-57_22566/logs.\n",
      "2019-07-12 14:35:57,832\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:55354 to respond...\n",
      "2019-07-12 14:35:57,947\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:28633 to respond...\n",
      "2019-07-12 14:35:57,950\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-07-12 14:35:57,980\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer adam\n",
      "loss binary_crossentropy\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss categorical_hinge\n",
      "optimizer adam\n",
      "loss categorical_hinge\n",
      "sklearn.svm.classes\n",
      "from functions -- sklearn\n",
      "Transpiling your model to it's Deep Neural Network equivalent...\n",
      "from dope --  sklearn LinearSVC\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from mlsquare.imly import dope\n",
    "\n",
    "m = dope(LinearSVC())\n",
    "# m = dope(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"../data/iris.csv\"\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 14:36:07,729\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-07-12 14:36:07,730\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m 2019-07-12 14:36:11,863\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m config from tune --  {'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'categorical_hinge'}\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m Deprecated in favor of operator or tf.math.divide.\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m 2019-07-12 14:36:12.103230: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m 2019-07-12 14:36:12.131612: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m 2019-07-12 14:36:12.132778: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55e8c8519ce0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m 2019-07-12 14:36:12.132792: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''layer_1.l1'': 0, ''layer_1.l2'': 0, ''layer_1.activation'':\n",
      "    ''linear'', ''optimizer'': ''adam'', ''loss'': ''categorical_hinge''}.h5'\n",
      "  date: 2019-07-12_14-36-12\n",
      "  done: false\n",
      "  experiment_id: 08e53c025ccf47cab29a4ca996132c51\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.45\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 22610\n",
      "  time_since_restore: 0.4769737720489502\n",
      "  time_this_iter_s: 0.4769737720489502\n",
      "  time_total_s: 0.4769737720489502\n",
      "  timestamp: 1562922372\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m 32/40 [=======================>......] - ETA: \n",
      "\u001b[2m\u001b[36m(pid=22610)\u001b[0m 40/40 [==============================] - 0s 410us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 14:36:12,663\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.251662015914917 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-12 14:36:12,667\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2019-07-12 14:36:13,797\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 1.1289193630218506 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - train_model_0:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=22610], 0 s, 1 iter, 0.45 acc\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - train_model_0:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=22610], 0 s, 1 iter, 0.45 acc\n",
      "\n",
      "Creating model...\n",
      "{'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'categorical_hinge'}\n",
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_2019-07-12_14-36-07q491jrra/weights_tune_{'layer_1.l1': 0, 'layer_1.l2': 0, 'layer_1.activation': 'linear', 'optimizer': 'adam', 'loss': 'categorical_hinge'}.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fede020df98>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 181us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5847259283065795, 0.5333333373069763]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(x_test, y_test)\n",
    "# y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = LinearSVC()\n",
    "test_model.fit(x_train, y_train)\n",
    "test_pred = test_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 1])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "_y = np.array(y_train)\n",
    "enc.fit(_y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conv = enc.transform(test_pred.reshape(-1,1))\n",
    "# test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_conv.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train).reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_SVC = test_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_SVC.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New arch on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-07-12 13:06:10,096\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-07-12_13-06-10_21494/logs.\n",
      "2019-07-12 13:06:10,204\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:25676 to respond...\n",
      "2019-07-12 13:06:10,314\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:32020 to respond...\n",
      "2019-07-12 13:06:10,316\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-07-12 13:06:10,340\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer adam\n",
      "loss binary_crossentropy\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss mse\n",
      "optimizer adam\n",
      "loss categorical_hinge\n",
      "optimizer adam\n",
      "loss categorical_hinge\n",
      "sklearn.svm.classes\n",
      "from functions -- sklearn\n",
      "Transpiling your model to it's Deep Neural Network equivalent...\n",
      "from dope --  sklearn SVC\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from mlsquare.imly import dope\n",
    "\n",
    "# m = dope(LinearSVC())\n",
    "m = dope(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"../data/iris.csv\"\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.6, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "2019-07-12 13:06:17,543\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-07-12 13:06:17,543\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m 2019-07-12 13:06:21,160\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m loss binary_crossentropy\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m loss mse\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m optimizer adam\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m loss categorical_hinge\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m config from tune --  {'layer_1.kernel_dim': 10, 'layer_1.activation': 'linear', 'layer_2.activation': 'softmax', 'optimizer': 'adam', 'loss': 'categorical_hinge'}\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m Deprecated in favor of operator or tf.math.divide.\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m 2019-07-12 13:06:21.363566: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m 2019-07-12 13:06:21.386447: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m 2019-07-12 13:06:21.387531: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56198e55dce0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m 2019-07-12 13:06:21.387564: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''layer_1.kernel_dim'': 10, ''layer_1.activation'': ''linear'',\n",
      "    ''layer_2.activation'': ''softmax'', ''optimizer'': ''adam'', ''loss'': ''categorical_hinge''}.h5'\n",
      "  date: 2019-07-12_13-06-21\n",
      "  done: false\n",
      "  experiment_id: 5db3c5fce8f34ecba290df44cb26367f\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.55\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 21539\n",
      "  time_since_restore: 0.5656368732452393\n",
      "  time_this_iter_s: 0.5656368732452393\n",
      "  time_total_s: 0.5656368732452393\n",
      "  timestamp: 1562916981\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m 32/40 [=======================>......] - ETA: \n",
      "\u001b[2m\u001b[36m(pid=21539)\u001b[0m 40/40 [==============================] - 0s 377us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 13:06:22,158\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.3950352668762207 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-12 13:06:22,162\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.1/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'TERMINATED': 1})\n",
      "TERMINATED trials:\n",
      " - train_model_0:\tTERMINATED, [4 CPUs, 0 GPUs], [pid=21539], 0 s, 1 iter, 0.55 acc\n",
      "\n",
      "Creating model...\n",
      "{'layer_1.kernel_dim': 10, 'layer_1.activation': 'linear', 'layer_2.activation': 'softmax', 'optimizer': 'adam', 'loss': 'categorical_hinge'}\n",
      "WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_2019-07-12_13-06-17dlyd5oay/weights_tune_{'layer_1.kernel_dim': 10, 'layer_1.activation': 'linear', 'layer_2.activation': 'softmax', 'optimizer': 'adam', 'loss': 'categorical_hinge'}.h5\n",
      "You are trying to load a weight file containing 2 layers into a model with 0 layers.\n",
      "Loading failed. Trying next model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f101efd5e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9433125178019206, 0.9333333293596904]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-12 14:34:08,230\tERROR worker.py:1780 -- The node with client ID 6393907f1f20977f03cdef547800fcdf3a532090 has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m E0712 14:34:11.718411 21602 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m E0712 14:34:11.721477 21604 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m E0712 14:34:11.718731 21608 raylet_client.cc:345] IOError: [RayletClient] Connection closed unexpectedly. [RayletClient] Failed to push profile events.\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=21536)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=21537)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=21538)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "_x, _y = np.array(x_test), np.array(y_test)\n",
    "m.score(_x, _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New arch on DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "x = pd.DataFrame(iris.data[:, :], columns = iris.feature_names[:])\n",
    "y = pd.DataFrame(iris.target, columns =[\"Species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-24 17:32:35,173\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-07-24 17:32:35,173\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 7.6/8.2 GB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-24 17:33:00,603\tWARNING util.py:62 -- The `start_trial` operation took 25.42269206047058 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-24 17:33:00,890\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 0.28678202629089355 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 7.6/8.2 GB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m 2019-07-24 17:34:14,431\tERROR worker.py:1412 -- Calling ray.init() again after it has already been called.\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m epochs ---  250\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m For more information, please see:\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m   * https://github.com/tensorflow/addons\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m If you depend on functionality not listed there, please file an issue.\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m WARNING:tensorflow:From /home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m Use tf.cast instead.\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m 2019-07-24 17:36:38.476647: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m 2019-07-24 17:36:41.323667: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2304000000 Hz\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m 2019-07-24 17:36:41.691874: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x7f61f4a531e0 executing computations on platform Host. Devices:\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m 2019-07-24 17:36:41.694512: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m  32/112 [=======>......................] - ETA: \n",
      "\u001b[2m\u001b[36m(pid=21379)\u001b[0m 112/112 [==============================] - 0s 576us/step\n",
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''layer_3.activation'': ''sigmoid'', ''optimizer'': ''adam'',\n",
      "    ''loss'': ''categorical_crossentropy''}.h5'\n",
      "  date: 2019-07-24_17-36-51\n",
      "  done: false\n",
      "  experiment_id: 17c1177f0e1c4e8797841f1e9431f057\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.6964285714285714\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 21379\n",
      "  time_since_restore: 132.11888647079468\n",
      "  time_this_iter_s: 132.11888647079468\n",
      "  time_total_s: 132.11888647079468\n",
      "  timestamp: 1563970011\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-24 17:36:53,335\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 1.8783962726593018 seconds to complete, which may be a performance bottleneck.\n",
      "2019-07-24 17:36:53,338\tERROR trial_runner.py:460 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 409, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 314, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 2316, in get\n",
      "    raise value\n",
      "ray.exceptions.RayTaskError: \u001b[36mray_WrappedFunc:train()\u001b[39m (pid=21379, host=shakkeel-TUF-GAMING-FX504GD-FX80GD)\n",
      "  File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/memory_monitor.py\", line 77, in raise_if_low_memory\n",
      "    self.error_threshold))\n",
      "ray.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node shakkeel-TUF-GAMING-FX504GD-FX80GD is used (7.86 / 8.21 GB). The top 5 memory consumers are:\n",
      "\n",
      "PID\tMEM\tCOMMAND\n",
      "5154\t0.55GB\t/usr/lib/firefox/firefox -contentproc -childID 21 -isForBrowser -prefsLen 7290 -prefMapSize 184967 -\n",
      "4084\t0.53GB\t/usr/lib/firefox/firefox -new-window\n",
      "4396\t0.41GB\t/usr/lib/firefox/firefox -contentproc -childID 6 -isForBrowser -prefsLen 6837 -prefMapSize 184967 -p\n",
      "5681\t0.36GB\t/usr/lib/firefox/firefox -contentproc -childID 26 -isForBrowser -prefsLen 7357 -prefMapSize 184967 -\n",
      "5025\t0.35GB\t/usr/lib/firefox/firefox -contentproc -childID 19 -isForBrowser -prefsLen 7244 -prefMapSize 184967 -\n",
      "\n",
      "In addition, ~0.94 GB of shared memory is currently being used by the Ray object store. You can set the object store size with the `object_store_memory` parameter when starting Ray, and the max Redis size with `redis_max_memory`.\n",
      "\n",
      "2019-07-24 17:36:53,340\tINFO ray_trial_executor.py:178 -- Destroying actor for trial train_model_0. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 7.9/8.2 GB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING, [4 CPUs, 0 GPUs], [pid=21379], 132 s, 1 iter, 0.696 acc\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-24 17:36:54,819\tWARNING util.py:62 -- The `experiment_checkpoint` operation took 1.4785771369934082 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 7.8/8.2 GB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "Number of trials: 1 ({'ERROR': 1})\n",
      "ERROR trials:\n",
      " - train_model_0:\tERROR, 1 failures: /home/shakkeel/ray_results/experiment_name/train_model_0_2019-07-24_17-32-35ilk9_4bg/error_2019-07-24_17-36-53.txt, [4 CPUs, 0 GPUs], [pid=21379], 132 s, 1 iter, 0.696 acc\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_model_0])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d26113ee8bf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# m.fit(x_train, y_train, cuts_per_feature=2, verbose=1,params=params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuts_per_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/mlsquare-core/mlsquare/src/mlsquare/adapters/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m## Search for best model using Tune ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         self.final_model = get_best_model(X, y, abstract_model = self.abstract_model, \n\u001b[0;32m---> 57\u001b[0;31m                                             primal_data=primal_data, epochs=kwargs['epochs'], batch_size=kwargs['batch_size'])\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_model\u001b[0m  \u001b[0;31m# Not necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mlsquare-core/mlsquare/src/mlsquare/optmizers/tune.py\u001b[0m in \u001b[0;36mget_best_model\u001b[0;34m(X, y, abstract_model, primal_data, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m                                     \u001b[0;31m# config=kwargs['params'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mean_accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mreuse_actors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse_actors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mtrial_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             raise_on_failed_trial=raise_on_failed_trial)\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_function, checkpoint_freq, checkpoint_at_end, export_formats, max_failures, restore, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_model_0])"
     ]
    }
   ],
   "source": [
    "from mlsquare import dope\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from keras.utils import to_categorical\n",
    "from ray import tune\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "m = dope(model)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "params = {\n",
    "    \"epochs\": tune.grid_search([100, 200]),\n",
    "    \"optimizer\": tune.grid_search([\"adam\", \"nadam\"])\n",
    "}\n",
    "\n",
    "# m.fit(x_train, y_train, cuts_per_feature=2, verbose=1,params=params)\n",
    "m.fit(x_train, y_train, cuts_per_feature=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7755351694006669, 0.5789473715581392]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = to_categorical(y_test)\n",
    "\n",
    "m.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "decision_tree_2 (DecisionTre (None, 81)                8         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 246       \n",
      "=================================================================\n",
      "Total params: 254\n",
      "Trainable params: 254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.imly import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sklearn',\n",
       "  'LogisticRegression'): {'default': [<mlsquare.imly.architectures.sklearn.LogisticRegression at 0x7f5e012739b0>,\n",
       "   mlsquare.imly.wrappers.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'LinearRegression'): {'default': [<mlsquare.imly.architectures.sklearn.LinearRegression at 0x7f5e01273b70>,\n",
       "   mlsquare.imly.wrappers.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Ridge'): {'default': [<mlsquare.imly.architectures.sklearn.Ridge at 0x7f5e01273d30>,\n",
       "   mlsquare.imly.wrappers.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Lasso'): {'default': [<mlsquare.imly.architectures.sklearn.Lasso at 0x7f5e01273ef0>,\n",
       "   mlsquare.imly.wrappers.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'ElasticNet'): {'default': [<mlsquare.imly.architectures.sklearn.ElasticNet at 0x7f5e0127e0f0>,\n",
       "   mlsquare.imly.wrappers.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'LinearSVC'): {'default': [<mlsquare.imly.architectures.sklearn.LinearSVC at 0x7f5e0127e2b0>,\n",
       "   mlsquare.imly.wrappers.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'SVC'): {'default': [<mlsquare.imly.architectures.sklearn.SVC at 0x7f5e0127e5f8>,\n",
       "   mlsquare.imly.wrappers.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'DecisionTreeClassifier'): {'default': [<mlsquare.imly.architectures.sklearn.DecisionTreeClassifier at 0x7f5e0127e940>,\n",
       "   mlsquare.imly.wrappers.sklearn.SklearnKerasClassifier]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-07-09 20:17:29,038\tERROR worker.py:1780 -- The node with client ID 5eb68493146f8c2ee1aff797f7aae8326f6aff55 has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 111, in <module>\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1034, in main_loop\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m     task = self._get_next_task_from_local_scheduler()\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/worker.py\", line 1017, in _get_next_task_from_local_scheduler\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m     task = self.raylet_client.get_task()\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m   File \"python/ray/_raylet.pyx\", line 244, in ray._raylet.RayletClient.get_task\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=26079)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=26077)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=26142)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m Exception: [RayletClient] Raylet connection closed.\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/workers/default_worker.py\", line 118, in <module>\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m     driver_id=None)\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m   File \"/home/shakkeel/anaconda3/envs/test_imly/lib/python3.6/site-packages/ray/utils.py\", line 68, in push_error_to_driver\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m     time.time())\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m   File \"python/ray/_raylet.pyx\", line 297, in ray._raylet.RayletClient.push_error\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m   File \"python/ray/_raylet.pyx\", line 59, in ray._raylet.check_status\n",
      "\u001b[2m\u001b[36m(pid=26076)\u001b[0m Exception: [RayletClient] Connection closed unexpectedly.\n"
     ]
    }
   ],
   "source": [
    "registry.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = {'layer_1.units': 2,\n",
    "              'layer_1.activation': ['linear', 'sigmoid'],\n",
    "              'layer_2.activation': 'sigmoid',\n",
    "              'layer_2.units': 2,\n",
    "              'optimization': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_1.units\n",
      "layer_1.activation\n",
      "layer_2.activation\n",
      "layer_2.units\n"
     ]
    }
   ],
   "source": [
    "## Convert to tree\n",
    "\n",
    "parsed_params = {}\n",
    "\n",
    "for key, value in test_params.items():\n",
    "    if key.split('_')[0] == 'layer':\n",
    "        print(key)\n",
    "        try:\n",
    "            parsed_params[key.split('.')[0]].update({key.split('.')[1]:value})\n",
    "        except:\n",
    "            parsed_params.update({key.split('.')[0]:{key.split('.')[1]:value}})\n",
    "    else:\n",
    "        parsed_params.update({key:value})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_params = {layer_name:{param_name:value}} # Use dict comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_params['layer_1'].update({'units': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1': {'units': 2, 'activation': ['linear', 'sigmoid']},\n",
       " 'layer_2': {'activation': 'sigmoid', 'units': 2},\n",
       " 'optimization': 'adam'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_1\n",
      "layer_2\n"
     ]
    }
   ],
   "source": [
    "## Flatten from tree\n",
    "\n",
    "tree_params = {}\n",
    "\n",
    "for key, value in parsed_params.items():\n",
    "    if key.split('_')[0] == 'layer':\n",
    "        print(key)\n",
    "        for k, v in parsed_params[key].items():\n",
    "            tree_params.update({'.'.join([key, k]): v})\n",
    "    else:\n",
    "        tree_params.update({key:value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1.units': 2,\n",
       " 'layer_1.activation': ['linear', 'sigmoid'],\n",
       " 'layer_2.activation': 'sigmoid',\n",
       " 'layer_2.units': 2,\n",
       " 'optimization': 'adam'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-84-e99b317d7831>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-84-e99b317d7831>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    comp_parsed_params = {key: value for key, value in test_params.items() if key.split('_')[0] == 'layer' print(key)}\u001b[0m\n\u001b[0m                                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Using dict comprehension\n",
    "comp_parsed_params = {}\n",
    "\n",
    "for key, value in test_params.items():\n",
    "    if key.split('_')[0] == 'layer':\n",
    "        print(key)\n",
    "        try:\n",
    "            parsed_params[key.split('.')[0]].update({key.split('.')[1]:value})\n",
    "        except:\n",
    "            parsed_params.update({key.split('.')[0]:{key.split('.')[1]:value}})\n",
    "    else:\n",
    "        parsed_params.update({key:value})\n",
    "        \n",
    "comp_parsed_params = {key: value for key, value in test_params.items() if key.split('_')[0] == 'layer' print(key)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1.units': 2,\n",
       " 'layer_1.activation': ['linear', 'sigmoid'],\n",
       " 'layer_2.activation': 'sigmoid',\n",
       " 'layer_2.units': 2,\n",
       " 'optimization': 'adam'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_parsed_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_1.units': 2,\n",
       " 'layer_1.activation': ['linear', 'sigmoid'],\n",
       " 'layer_2.activation': 'sigmoid',\n",
       " 'layer_2.units': 2,\n",
       " 'optimization': 'adam'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.imly.commons.functions import _parse_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = _parse_params(test_params, return_as='nested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-bee5e8feac65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_parse_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_as\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/mlsquare-core/mlsquare/src/mlsquare/imly/commons/functions.py\u001b[0m in \u001b[0;36m_parse_params\u001b[0;34m(params, return_as)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'layer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0medited_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "_parse_params(test_params, return_as='flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.__class__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.117px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
