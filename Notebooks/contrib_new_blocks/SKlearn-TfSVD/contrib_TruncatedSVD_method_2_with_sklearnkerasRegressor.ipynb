{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributing Sklearn's decompositon SVD to mlsquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fork mlsquare repository to your account and clone.**\n",
    "\n",
    "**Or just Clone https://github.com/mlsquare/mlsquare.git**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Navigate to `src/mlsquare/architectures` folder, Where the code for mapping `TruncatedSVD()` to `tf.linalg.svd()` resides.\n",
    "* The code for mapping primal model(SVD) to corresponding TF equivalent is saved in `sklearn.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook contains following edits in succession to method 1:**\n",
    "* Arranging matrix tranformation operations in architecture.\n",
    "* Utilising existing `SklearnKerasRegressor` methods\n",
    "* Restraining trigger of `SklearnKerasRegressor`'s standard methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kev/Desktop/mlsquare_experiments/src'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Register the proxy SVD model in `mlsquare/architecture/sklearn.py` as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from ..base import registry, BaseModel\n",
    "from mlsquare.base import registry, BaseModel\n",
    "from mlsquare.adapters.sklearn import SklearnKerasRegressor\n",
    "from mlsquare.architectures.sklearn import GeneralizedLinearModel\n",
    "\n",
    "from abc import abstractmethod\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "\n",
    "class DimensionalityReductionModel:\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y= None):\n",
    "        \"\"\"Needs Implementation in sub classes\"\"\"\n",
    "        \n",
    "    @abstractmethod\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Needs Implementation in sub classes\"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "@registry.register\n",
    "class SVD(DimensionalityReductionModel, GeneralizedLinearModel):\n",
    "    def __init__(self):\n",
    "        self.adapter = SklearnKerasRegressor\n",
    "        #self.adapter = SklearnKerasRegressor(DimensionalityReductionModel)\n",
    "        self.module_name = 'sklearn' \n",
    "        self.name = 'TruncatedSVD'\n",
    "        self.version = 'default'\n",
    "        model_params = {'full_matrices': False,\n",
    "                       'compute_uv': True,\n",
    "                      'name':None}\n",
    "\n",
    "        self.set_params(params=model_params, set_by='model_init')\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.fit_transform(X)\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None,**kwargs):\n",
    "        kwargs.setdefault('full_matrices', False)\n",
    "        kwargs.setdefault('compute_uv', True)\n",
    "        kwargs.setdefault('name', None)\n",
    "        \n",
    "        X = np.array(X, dtype= np.float32 if str(X.values.dtype)=='float32' else np.float64) if isinstance(X, pandas.core.frame.DataFrame) else np.array(X, dtype= np.float32 if str(X.dtype)=='float32' else np.float64)#changing to recommended dtype, accomodating dataframe & numpy array\n",
    "\n",
    "        #X = np.array(X)\n",
    "        #y = np.array(y)\n",
    "        \n",
    "        n_components= self.primal.n_components#using primal attributes passed from adapter\n",
    "        n_features = X.shape[1]\n",
    "        if n_components>= n_features:\n",
    "                raise ValueError(\"n_components must be < n_features;\"\n",
    "                                 \" got %d >= %d\" % (n_components, n_features))\n",
    "                \n",
    "        sess= tf.Session()#for TF  1.13\n",
    "        s,u,v= sess.run(tf.linalg.svd(X, full_matrices=kwargs['full_matrices'], compute_uv=kwargs['compute_uv']))#for TF  1.13\n",
    "        \n",
    "        self.components_= v[:n_components,:]\n",
    "        X_transformed = u[:,:n_components] * s[:n_components]\n",
    "        \n",
    "        self.explained_variance_= np.var(X_transformed, axis=0)\n",
    "        \n",
    "        self.singular_values_ = s[:n_components]\n",
    "        return X_transformed\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X@self.components_.T\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        return np.dot(X, self.components_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using existing adapter `SklearnKerasRegressor` with minor modifications for mapping `sklearn.decomposition.TruncatedSVD`  to `tensorflow.linalg.svd` in `mlsquare/adapters/sklearn.py`  and work with sklearn methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.utils.functions import _parse_params\n",
    "import numpy as np\n",
    "from ..architectures import sklearn\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class SklearnKerasRegressor():\n",
    "    def __init__(self, proxy_model, primal_model, **kwargs):\n",
    "        self.primal_model = primal_model\n",
    "        self.proxy_model = proxy_model\n",
    "        self.params = None\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.proxy_model.X = X\n",
    "        self.proxy_model.y = y\n",
    "        self.proxy_model.primal = self.primal_model\n",
    "        kwargs.setdefault('verbose', 0)\n",
    "        kwargs.setdefault('epochs', 250)\n",
    "        kwargs.setdefault('batch_size', 30)\n",
    "        kwargs.setdefault('params', self.params)\n",
    "        self.params = kwargs['params']\n",
    "\n",
    "        if self.params != None: ## Validate implementation with different types of tune input\n",
    "            if not isinstance(self.params, dict):\n",
    "                raise TypeError(\"Params should be of type 'dict'\")\n",
    "            self.params = _parse_params(self.params, return_as='flat')\n",
    "            self.proxy_model.update_params(self.params)\n",
    "\n",
    "        #if self.proxy_model.__class__.__name in ['SVD', 'PCA']:\n",
    "        if isinstance(self.proxy_model, (sklearn.DimensionalityReductionModel)):\n",
    "            return self.proxy_model.fit(X)\n",
    "        \n",
    "        primal_model = self.primal_model\n",
    "        primal_model.fit(X, y)\n",
    "        y_pred = primal_model.predict(X)\n",
    "        primal_data = {\n",
    "            'y_pred': y_pred,\n",
    "            'model_name': primal_model.__class__.__name__\n",
    "        }\n",
    "\n",
    "        self.final_model = get_best_model(X, y, proxy_model=self.proxy_model, primal_data=primal_data,\n",
    "                                          epochs=kwargs['epochs'], batch_size=kwargs['batch_size'],\n",
    "                                          verbose=kwargs['verbose'])\n",
    "        return self.final_model  # Not necessary.\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if not isinstance(self.proxy_model, (sklearn.DimensionalityReductionModel)):\n",
    "            raise AttributeError(\"'SklearnKerasRegressor' object has no attribute 'transform'\")\n",
    "        return self.proxy_model.transform(X)\n",
    "    \n",
    "    def fit_transform(self, X,y=None):\n",
    "        if not isinstance(self.proxy_model, (sklearn.DimensionalityReductionModel)):\n",
    "            raise AttributeError(\"'SklearnKerasRegressor' object has no attribute 'fit_transform'\")\n",
    "        return self.proxy_model.fit_transform(X)\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        if not isinstance(self.proxy_model, (sklearn.DimensionalityReductionModel)):\n",
    "            raise AttributeError(\"'SklearnKerasRegressor' object has no attribute 'inverse_transform'\")\n",
    "        return self.proxy_model.inverse_transform(X)\n",
    "    \n",
    "    \n",
    "    def score(self, X, y, **kwargs):\n",
    "        if isinstance(self.proxy_model, (sklearn.DimensionalityReductionModel)):\n",
    "            raise AttributeError(\"'SklearnKerasRegressor' object has no attribute 'score'\")\n",
    "\n",
    "        score = self.final_model.evaluate(X, y, **kwargs)\n",
    "        return score\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Pending:\n",
    "        1) Write a 'filter_sk_params' function(check keras_regressor wrapper) if necessary.\n",
    "        2) Data checks and data conversions\n",
    "        '''\n",
    "        if isinstance(self.proxy_model, (sklearn.DimensionalityReductionModel)):\n",
    "            raise AttributeError(\"'SklearnKerasRegressor' object has no attribute 'predict'\")\n",
    "            \n",
    "        pred = self.final_model.predict(X)\n",
    "        return pred\n",
    "\n",
    "    def save(self, filename=None):\n",
    "        if filename == None:\n",
    "            raise ValueError(\n",
    "                'Name Error: to save the model you need to specify the filename')\n",
    "\n",
    "        if isinstance(self.proxy_model, (sklearn.DimensionalityReductionModel)):\n",
    "            raise AttributeError(\"'SklearnKerasRegressor' object has no attribute 'save'\")\n",
    "        pickle.dump(self.final_model, open(filename + '.pkl', 'wb'))\n",
    "\n",
    "        self.final_model.save(filename + '.h5')\n",
    "\n",
    "        onnx_model = onnxmltools.convert_keras(self.final_model)\n",
    "        onnxmltools.utils.save_model(onnx_model, filename + '.onnx')\n",
    "\n",
    "    def explain(self, **kwargs):\n",
    "        # @param: SHAP or interpret\n",
    "        print('Coming soon...')\n",
    "        return self.final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* registered methods so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-12-02 21:27:02,054\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-12-02_21-27-02_14769/logs.\n",
      "2019-12-02 21:27:02,196\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:23611 to respond...\n",
      "2019-12-02 21:27:02,319\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:61413 to respond...\n",
      "2019-12-02 21:27:02,324\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-12-02 21:27:02,362\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('sklearn',\n",
       "  'TruncatedSVD'): {'default': [<mlsquare.architectures.sklearn.SVD at 0x7f35cd1ca1d0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'LogisticRegression'): {'default': [<mlsquare.architectures.sklearn.LogisticRegression at 0x7f35cc455a20>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'LinearRegression'): {'default': [<mlsquare.architectures.sklearn.LinearRegression at 0x7f35cc455be0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Ridge'): {'default': [<mlsquare.architectures.sklearn.Ridge at 0x7f35cc455da0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Lasso'): {'default': [<mlsquare.architectures.sklearn.Lasso at 0x7f35cc455f60>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'ElasticNet'): {'default': [<mlsquare.architectures.sklearn.ElasticNet at 0x7f35cc464160>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'LinearSVC'): {'default': [<mlsquare.architectures.sklearn.LinearSVC at 0x7f35cc464320>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'SVC'): {'default': [<mlsquare.architectures.sklearn.SVC at 0x7f35cc464668>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'DecisionTreeClassifier'): {'default': [<mlsquare.architectures.sklearn.DecisionTreeClassifier at 0x7f35cc4649b0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlsquare.base import registry\n",
    "registry.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Once the new model is registered & corresponding adapter is defined in mlsquare framework.**)\n",
    "#### User Interaction with `dope` with sklearn SVD preference & intent to utilise underlying TF SVD \n",
    "\n",
    "    \n",
    "\n",
    "    1. a) User instantiates a primal model `sklearn.decomposition.TruncatedSVD` with args --`n_components` as number of required singular components.\n",
    "    b) User loads the data & proceed with necessary data preparation steps \n",
    "    \n",
    "    \n",
    "    2. Now, import `dope` from mlsquare & `dope` the primal model by passing primal model to dope function. The `dope` function equips above primal model with standard sklearn methods--`fit, fit_transform, save, explain.`\n",
    "    \n",
    "    3.  Carry on with usual sklearn SVD methods; Try out sklearn \n",
    "    methods -- `.fit( )`, `.fit_transform( )`, `.transform( )` with the doped model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a Instantiate primal module\n",
    "* n_components: 10 (number of reduced dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "primal = TruncatedSVD(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'randomized',\n",
       " 'n_components': 10,\n",
       " 'n_iter': 5,\n",
       " 'random_state': None,\n",
       " 'tol': 0.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primal.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b Following are data preparation steps required to instantiate a svd model\n",
    "* Also evaluating the regression results at various stages with varying dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "reg= linear_model.LinearRegression()\n",
    "\n",
    "boston =load_boston()\n",
    "df_x= pd.DataFrame(boston.data, columns= boston.feature_names)\n",
    "lbe= LabelEncoder()\n",
    "df_x = df_x.apply(lambda x: lbe.fit_transform(x))#df_x[col]))\n",
    "df_y= df_y= pd.DataFrame(boston.target)\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df_x, df_y, test_size=0.2)\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>320</td>\n",
       "      <td>172</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>356</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>279</td>\n",
       "      <td>225</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>356</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>400</td>\n",
       "      <td>159</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>271</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRIM  ZN  INDUS  CHAS  NOX   RM  AGE  DIS  RAD  TAX  PTRATIO    B  LSTAT\n",
       "0     0   3     19     0   51  320  172  297    0   34        9  356     53\n",
       "1    23   0     56     0   36  279  225  333    1   11       23  356    161\n",
       "2    22   0     56     0   36  400  159  333    1   11       23  271     28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating results with full dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7562361743176013\n"
     ]
    }
   ],
   "source": [
    "reg= linear_model.LinearRegression()\n",
    "reg.fit(xtrain, ytrain)\n",
    "print(reg.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating results with reduced dimensionality through primal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn_svd truncated dims: (506, 10)\n",
      "0.729796445256366\n"
     ]
    }
   ],
   "source": [
    "skl_truncated_x = primal.fit(df_x).transform(df_x)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(skl_truncated_x, df_y, test_size=0.2)\n",
    "print('sklearn_svd truncated dims:', skl_truncated_x.shape)\n",
    "reg= linear_model.LinearRegression()\n",
    "reg.fit(xtrain, ytrain)\n",
    "print(reg.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. dope the model to obtain keras svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    }
   ],
   "source": [
    "from mlsquare import dope\n",
    "\n",
    "model = dope(primal)# adapter(proxy_model=proxy_model, primal_model=primal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy model object from registry:\n",
      " <mlsquare.architectures.sklearn.SVD object at 0x7f35cd1ca1d0> \n",
      "\n",
      "correspnding adapter:\n",
      " <mlsquare.adapters.sklearn.SklearnKerasRegressor object at 0x7f358cb73c18>\n"
     ]
    }
   ],
   "source": [
    "print('proxy model object from registry:\\n', model.proxy_model, '\\n\\ncorrespnding adapter:\\n', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "??model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Try out sklearn methods-- `.fit( )` & `.fit_transform( )` to obtain reduced dimensionality, with sklearn's `boston_dataset` from `1.b` above.\n",
    "* Fitting the doped model with -- Dataframe input Or Numpy array inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp= np.array(df_x.values, dtype= np.float64)\n",
    "\n",
    "#dope_truncated_x=model.fit_transform(df_x) #takes in dataframe input\n",
    "dope_truncated_x= model.fit_transform(inp)\n",
    "\n",
    "dope_truncated_x.shape\n",
    "#dimensionality reduced to n_components using tf.linalg.svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating results with reduced dimensionality through doped model & ascertaining approximately faithful results through underlying TF method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doped_svd truncated dims: (506, 10)\n",
      "0.7294817890786716\n"
     ]
    }
   ],
   "source": [
    "#truncated_x= model.fit(df_x).fit_transform(df_x)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(dope_truncated_x, df_y, test_size=0.2)\n",
    "\n",
    "print('doped_svd truncated dims:', dope_truncated_x.shape)\n",
    "\n",
    "reg= linear_model.LinearRegression()\n",
    "reg.fit(xtrain, ytrain)\n",
    "print(reg.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trying how sklearn SVD deals with anamoly methods--`.score()`, `.predict()` and implement similar error flagging for undefined apis for proxy_model.\n",
    "    * Chances are a user presuming TrucnatedSVD as a usual model will try out above methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* follwing contains error for sklearn_svd's undefined  api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TruncatedSVD' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ad4838fa8017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprimal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#primal is an sklearn object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TruncatedSVD' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "primal.predict(df_x)\n",
    "#primal is an sklearn object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* proxy svd model flags following error on calling undefined methods, Usually. ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SklearnKerasRegressor' object has no attribute 'final_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1028fe8f35e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/mlsquare_experiments/src/mlsquare/adapters/sklearn.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SklearnKerasRegressor' object has no attribute 'final_model'"
     ]
    }
   ],
   "source": [
    "model.score(inp)# Same for model.predict(inp)\n",
    "#model is a adapter object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un-implemented methods flag an `AttributeError`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* proxy svd model flags following error on calling undefined methods, Now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SklearnKerasRegressor' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d984e0696b44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#Same for model.score(inp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#model is a adapter object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mlsquare_experiments/src/mlsquare/adapters/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    368\u001b[0m         '''\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDimensionalityReductionModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'SklearnKerasRegressor' object has no attribute 'predict'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SklearnKerasRegressor' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "model.predict(inp)#Same for model.score(inp)\n",
    "#model is a adapter object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "* Or it could be that once the wrapper method(`.fit( )`) yields an architecture object(`model.fit(x)`), the resulting arch object should only be used to access underlying attributes--(`sigma components, Vh values`) and not for perpetual transformation say--(`.fit( ).transform( )`).?\n",
    "* Or Each sklearn's native method should be used across individual adapter instances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problems**\n",
    "* Also `trans_input.components_` differs from `primal.components_` by some tolerance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* following is accessing/operating architecture SVD methods directly from archi instance not on adapter instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 471.04962214,  330.53051303,    8.67494127, ...,  -10.20964288,\n",
       "         -11.40944565,   26.75673524],\n",
       "       [ 545.473621  ,  266.09903932,   78.12796733, ...,   19.84120668,\n",
       "          -4.45406447,   -5.85600368],\n",
       "       [ 477.92571461,  357.67984616,  -89.8250494 , ...,   28.90475808,\n",
       "          -3.75504454,   -3.6268214 ],\n",
       "       ...,\n",
       "       [ 533.89491136,  184.50034054, -103.19963966, ...,   29.29001292,\n",
       "          13.7427487 ,   -3.59156992],\n",
       "       [ 545.86519119,  132.99450123, -118.31830091, ...,   28.33873663,\n",
       "          12.90476995,   -3.26489671],\n",
       "       [ 463.39533327,  126.36114053,   96.81230318, ...,   29.68789887,\n",
       "           7.78444792,    4.41248029]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_input = model.fit(inp)\n",
    "trans_input.fit_transform(inp)#Here trans_input is an architecture instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* why not equivalent to `primal.fit(inp).transform(inp)` / `model.fit_transform(inp)` Or `trans_input.fit_transform(inp)` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -75.56887878,  -57.8884622 ,  260.59461822, ...,  102.97383264,\n",
       "         352.53301963,  -70.64307926],\n",
       "       [ -72.29982996,  -50.40249459,  325.00120352, ...,  102.73029093,\n",
       "         352.15956815,  -52.63267368],\n",
       "       [ -58.21365467,  -49.94548524,  292.98765322, ...,  146.19322653,\n",
       "         266.72016715, -101.97958854],\n",
       "       ...,\n",
       "       [ -55.38801771,    5.15461941,  244.974442  , ...,  164.35738679,\n",
       "         358.31152541,  119.03717653],\n",
       "       [ -22.34637091,    1.54294869,  262.12034469, ...,  182.74887134,\n",
       "         290.10490754,   99.91750279],\n",
       "       [ -65.32687223,   -1.70295098,  235.34476637, ...,   85.01131929,\n",
       "         356.28068861,   47.04061476]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inp).transform(inp)#same as trans_input.transform(inp2) ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 471.04962214,  330.53051303,    8.67494127, ...,  -10.20964288,\n",
       "         -11.40944565,   26.75673524],\n",
       "       [ 545.473621  ,  266.09903932,   78.12796733, ...,   19.84120668,\n",
       "          -4.45406447,   -5.85600368],\n",
       "       [ 477.92571461,  357.67984616,  -89.8250494 , ...,   28.90475808,\n",
       "          -3.75504454,   -3.6268214 ],\n",
       "       ...,\n",
       "       [ 533.89491136,  184.50034054, -103.19963966, ...,   29.29001292,\n",
       "          13.7427487 ,   -3.59156992],\n",
       "       [ 545.86519119,  132.99450123, -118.31830091, ...,   28.33873663,\n",
       "          12.90476995,   -3.26489671],\n",
       "       [ 463.39533327,  126.36114053,   96.81230318, ...,   29.68789887,\n",
       "           7.78444792,    4.41248029]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_input_x= model.fit_transform(inp)\n",
    "trans_input_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
