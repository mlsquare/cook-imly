{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributing Sklearn's decompositon SVD to mlsquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fork mlsquare repository to your account and clone.**\n",
    "\n",
    "**Or just Clone https://github.com/mlsquare/mlsquare.git**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Navigate to `src/mlsquare/architectures` folder, Where the code for mapping `TruncatedSVD()` to `tf.linalg.svd()` resides.\n",
    "* The code for mapping primal model(SVD) to corresponding TF equivalent is saved in `sklearn.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kev/Desktop/mlsquare_experiments/src'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Register the proxy SVD model in `mlsquare/architecture/sklearn.py` as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-11-28 17:44:53,353\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-11-28_17-44-53_6525/logs.\n",
      "2019-11-28 17:44:53,493\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:21174 to respond...\n",
      "2019-11-28 17:44:53,603\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:27128 to respond...\n",
      "2019-11-28 17:44:53,605\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-11-28 17:44:53,619\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    }
   ],
   "source": [
    "#from ..base import registry, BaseModel\n",
    "from mlsquare.base import registry, BaseModel\n",
    "from mlsquare.adapters.sklearn import SklearnKerasDecompose\n",
    "from mlsquare.architectures.sklearn import GeneralizedLinearModel\n",
    "\n",
    "#from mlsquare.adapters.sklearn import #SurpriselibModels\n",
    "\n",
    "@registry.register\n",
    "class SVD(GeneralizedLinearModel):\n",
    "    def __init__(self):\n",
    "        self.adapter = SklearnKerasDecompose\n",
    "        self.module_name = 'sklearn'\n",
    "        self.name = 'TruncatedSVD'\n",
    "        self.version = 'default'\n",
    "        model_params = {'full_matrices': False,\n",
    "                       'compute_uv': True,\n",
    "                      'name':None}\n",
    "\n",
    "              #          }\n",
    "\n",
    "        self.set_params(params=model_params, set_by='model_init')\n",
    "    def create_model(self, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define an adapter `SklearnKerasDecompose` for mapping `sklearn.decomposition.TruncatedSVD`  to `tensorflow.linalg.svd` in `mlsquare/adapters/sklearn.py` to work with sklearn methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.utils.functions import _parse_params\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class SklearnKerasDecompose():\n",
    "    def __init__(self, proxy_model, primal_model, **kwargs):\n",
    "        self.primal_model = primal_model\n",
    "        self.params = None ## Temporary!\n",
    "        self.proxy_model = proxy_model\n",
    "        self.n_components= primal_model.n_components#moved here so user like in sklearncan can access n_components, even before .fit_transform. \n",
    "        \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.fit_transform(X)\n",
    "        return self\n",
    "    \n",
    "    def fit_transform(self, X, y=None,**kwargs):\n",
    "        kwargs.setdefault('full_matrices', False)\n",
    "        kwargs.setdefault('params', self.params)\n",
    "        kwargs.setdefault('space', False)\n",
    "        kwargs.setdefault('compute_uv', True)\n",
    "        kwargs.setdefault('name', None)\n",
    "        self.params = kwargs['params']\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        #primal_model = self.primal_model\n",
    "        #self.proxy_model.n_components= primal_model.n_components        \n",
    "        #self.n_components= primal_model.n_components # Now its callable as model.num_components just like a sklearn svd object\n",
    "        \n",
    "        #?--should the `.num_components`, '.components_', '.singular_values_' be defined as attributes of proxy_model class or adapter class --?\n",
    "        \n",
    "        k = self.n_components\n",
    "        n_features = X.shape[1]\n",
    "        if k>= n_features:\n",
    "                raise ValueError(\"n_components must be < n_features;\"\n",
    "                                 \" got %d >= %d\" % (k, n_features))\n",
    "            \n",
    "        sess= tf.Session()#for TF  1.13\n",
    "        s,u,v= sess.run(tf.linalg.svd(X, full_matrices=kwargs['full_matrices'], compute_uv=kwargs['compute_uv']))#for TF  1.13\n",
    "        #s: singular values\n",
    "        #u: normalised projection distances\n",
    "        #v: decomposition/projection orthogonal axes\n",
    "        \n",
    "        self.components_= v[:self.n_components,:]\n",
    "        #self.proxy_model.components_= v[:self.proxy_model.n_components,:]#analogous to TruncatedSVD().components_ Or primal_model.components_ Or Vh component from randomised SVD\n",
    "        \n",
    "        #Sigma = s[:self.proxy_model.num_components]\n",
    "        X_transformed = u[:,:self.n_components] * s[:self.n_components]\n",
    "        #X_transformed = u[:,:self.proxy_model.n_components] * s[:self.proxy_model.n_components]\n",
    "        \n",
    "        self.singular_values_ = s[:self.n_components]\n",
    "        #self.proxy_model.singular_values_ = s[:self.proxy_model.n_components]# Store the n_components singular values\n",
    "        \n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* registered methods so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sklearn',\n",
       "  'xyz'): {'default': [<mlsquare.architectures.sklearn.SVD_1 at 0x7fe8de47e9e8>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasDecompose_1]},\n",
       " ('sklearn',\n",
       "  'TruncatedSVD'): {'default': [<__main__.SVD at 0x7fe8ece73630>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasDecompose]},\n",
       " ('sklearn',\n",
       "  'LogisticRegression'): {'default': [<mlsquare.architectures.sklearn.LogisticRegression at 0x7fe926d15048>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'LinearRegression'): {'default': [<mlsquare.architectures.sklearn.LinearRegression at 0x7fe926d15208>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Ridge'): {'default': [<mlsquare.architectures.sklearn.Ridge at 0x7fe926d153c8>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Lasso'): {'default': [<mlsquare.architectures.sklearn.Lasso at 0x7fe926d15588>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'ElasticNet'): {'default': [<mlsquare.architectures.sklearn.ElasticNet at 0x7fe926d15710>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'LinearSVC'): {'default': [<mlsquare.architectures.sklearn.LinearSVC at 0x7fe926d158d0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'SVC'): {'default': [<mlsquare.architectures.sklearn.SVC at 0x7fe926d15c18>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'DecisionTreeClassifier'): {'default': [<mlsquare.architectures.sklearn.DecisionTreeClassifier at 0x7fe926d15f60>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlsquare.base import registry\n",
    "registry.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Once the new model is registered & corresponding adapter is defined in mlsquare framework.**)\n",
    "#### User Interaction with `dope` with sklearn SVD preference & intent to utilise underlying TF SVD \n",
    "\n",
    "    \n",
    "\n",
    "    1. a) User instantiates a primal model `sklearn.decomposition.TruncatedSVD` with args --`n_components` as number of required singular components.\n",
    "    b) User loads the data & proceed with necessary data preparation steps \n",
    "    \n",
    "    \n",
    "    2. Now, import `dope` from mlsquare & `dope` the primal model by passing primal model to dope function. The `dope` function equips above primal model with standard sklearn methods--`fit, fit_transform, save, explain.`\n",
    "    \n",
    "    3.  Carry on with usual sklearn SVD methods; Try out sklearn \n",
    "    methods -- `.fit( )` & `.fit_transform( )` with the doped model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a Instantiate primal module\n",
    "* n_components: 10 (number of reduced dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "primal = TruncatedSVD(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'randomized',\n",
       " 'n_components': 10,\n",
       " 'n_iter': 5,\n",
       " 'random_state': None,\n",
       " 'tol': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primal.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b Following are data preparation steps required to instantiate a svd model\n",
    "* Also evaluating the regression results at various stages with varying dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "reg= linear_model.LinearRegression()\n",
    "\n",
    "boston =load_boston()\n",
    "df_x= pd.DataFrame(boston.data, columns= boston.feature_names)\n",
    "lbe= LabelEncoder()\n",
    "df_x = df_x.apply(lambda x: lbe.fit_transform(x))#df_x[col]))\n",
    "df_y= df_y= pd.DataFrame(boston.target)\n",
    "\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df_x, df_y, test_size=0.2)\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>320</td>\n",
       "      <td>172</td>\n",
       "      <td>297</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>356</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>279</td>\n",
       "      <td>225</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>356</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>400</td>\n",
       "      <td>159</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>271</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>383</td>\n",
       "      <td>112</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>311</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>395</td>\n",
       "      <td>139</td>\n",
       "      <td>361</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>356</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRIM  ZN  INDUS  CHAS  NOX   RM  AGE  DIS  RAD  TAX  PTRATIO    B  LSTAT\n",
       "0     0   3     19     0   51  320  172  297    0   34        9  356     53\n",
       "1    23   0     56     0   36  279  225  333    1   11       23  356    161\n",
       "2    22   0     56     0   36  400  159  333    1   11       23  271     28\n",
       "3    32   0     16     0   33  383  112  361    2    5       31  311      6\n",
       "4   110   0     16     0   33  395  139  361    2    5       31  356     64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating results with full dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565245838025516\n"
     ]
    }
   ],
   "source": [
    "reg= linear_model.LinearRegression()\n",
    "reg.fit(xtrain, ytrain)\n",
    "print(reg.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating results with reduced dimensionality through primal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn_svd truncated dims: (506, 10)\n",
      "0.7834073266399079\n"
     ]
    }
   ],
   "source": [
    "skl_truncated_x = primal.fit(df_x).transform(df_x)\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(skl_truncated_x, df_y, test_size=0.2)\n",
    "print('sklearn_svd truncated dims:', skl_truncated_x.shape)\n",
    "reg= linear_model.LinearRegression()\n",
    "reg.fit(xtrain, ytrain)\n",
    "print(reg.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. dope the model to obtain keras svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transpiling your model to it's Deep Neural Network equivalent...\n"
     ]
    }
   ],
   "source": [
    "from mlsquare import dope\n",
    "\n",
    "model = dope(primal)# adapter(proxy_model=proxy_model, primal_model=primal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy model object from registry:\n",
      " <__main__.SVD object at 0x7fe8ece73630>\n"
     ]
    }
   ],
   "source": [
    "print('proxy model object from registry:\\n', model.proxy_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Try out sklearn methods-- `.fit( )` & `.fit_transform( )` to obtain reduced dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input arr a:\n",
      " [[-1.04549857  0.08445003  0.46343894 -0.08542798]\n",
      " [ 0.1164637   0.14950925  0.46024374  0.41852031]\n",
      " [ 0.53976946  0.43226543  0.11751776  1.2850961 ]\n",
      " [ 1.43346079 -0.41787555 -0.85370613  0.1358221 ]\n",
      " [-1.7253289  -0.05526024 -0.63811273 -1.06074793]] \n",
      "\n",
      "shape of a: (5, 4) \n",
      "\n",
      "dtype of a: float64\n"
     ]
    }
   ],
   "source": [
    "a= np.random.randn(5,4)\n",
    "print('input arr a:\\n',a,'\\n\\nshape of a:', a.shape, '\\n\\ndtype of a:', a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.765971  ,  0.07249544, -1.10125291,  0.59645285],\n",
       "       [ 1.97173184, -1.00333899, -0.06425587, -0.67453579],\n",
       "       [-1.16614764,  1.03002233, -1.16152227, -0.52016207],\n",
       "       [-2.12782336, -1.44799052, -0.36044253,  0.15373504],\n",
       "       [ 0.04632845, -0.639334  , -1.07900081, -0.05999566]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_truncated_x= model.fit_transform(a)#This shouldn't work, since 4(i.e, a.shape[1]) < 10(i.e., n_components)\n",
    "tf_truncated_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_truncated_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components must be < n_features; got 10 >= 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-866a6ed46a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_truncated_x\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#Prints Valueerror; After adding a conditional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf_truncated_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mlsquare/src/mlsquare/adapters/sklearn.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m>=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             raise ValueError(\"n_components must be < n_features;\"\n\u001b[0;32m---> 43\u001b[0;31m                                  \" got %d >= %d\" % (k, n_features))\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#for TF  1.13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components must be < n_features; got 10 >= 4"
     ]
    }
   ],
   "source": [
    "tf_truncated_x= model.fit_transform(a)#Prints Valueerror; After adding a conditional\n",
    "tf_truncated_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Similarly with sklearn's `boston_dataset` from `1.b` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2= np.array(df_x.values, dtype= np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 471.04962214,  330.53051303,    8.67494127, ...,  -10.20964288,\n",
       "         -11.40944565,   26.75673524],\n",
       "       [ 545.473621  ,  266.09903932,   78.12796733, ...,   19.84120668,\n",
       "          -4.45406447,   -5.85600368],\n",
       "       [ 477.92571461,  357.67984616,  -89.8250494 , ...,   28.90475808,\n",
       "          -3.75504454,   -3.6268214 ],\n",
       "       ...,\n",
       "       [ 533.89491136,  184.50034054, -103.19963966, ...,   29.29001292,\n",
       "          13.7427487 ,   -3.59156992],\n",
       "       [ 545.86519119,  132.99450123, -118.31830091, ...,   28.33873663,\n",
       "          12.90476995,   -3.26489671],\n",
       "       [ 463.39533327,  126.36114053,   96.81230318, ...,   29.68789887,\n",
       "           7.78444792,    4.41248029]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dope_truncated_x= model.fit_transform(inp2)\n",
    "dope_truncated_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dope_truncated_x.shape\n",
    "#dimensionality reduced to n_components using tf.linalg.svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating results with reduced dimensionality through doped model & ascertaining approximately faithful results through underlying TF method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doped_svd truncated dims: (506, 10)\n",
      "0.7153780768050211\n"
     ]
    }
   ],
   "source": [
    "#truncated_x= model.fit(df_x).fit_transform(df_x)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(dope_truncated_x, df_y, test_size=0.2)\n",
    "\n",
    "print('doped_svd truncated dims:', dope_truncated_x.shape)\n",
    "\n",
    "reg= linear_model.LinearRegression()\n",
    "reg.fit(xtrain, ytrain)\n",
    "print(reg.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Arranging matrix tranformation operations into architecture\n",
    "* Utilising existing `SklearnKerasRegressor` methods\n",
    "* Restraining `SklearnKerasRegressor`'s standard methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Registering the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "\n",
    "class DimensionalityReductionModel:\n",
    "    @abstractmethod\n",
    "    def fit(self, X, y= None):\n",
    "        \"\"\"Needs Implementation in sub classes\"\"\"\n",
    "    @abstractmethod\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"Needs Implementation in sub classes\"\"\"\n",
    "\n",
    "\n",
    "@registry.register\n",
    "class SVD(DimensionalityReductionModel, GeneralizedLinearModel):\n",
    "    def __init__(self):\n",
    "        self.adapter = SklearnKerasRegressor#SklearnKerasDecompose\n",
    "        self.module_name = 'sklearn' \n",
    "        self.name = 'TruncatedSVD'\n",
    "        self.version = 'default'\n",
    "        model_params = {'full_matrices': False,\n",
    "                       'compute_uv': True,\n",
    "                      'name':None}\n",
    "\n",
    "        self.set_params(params=model_params, set_by='model_init')\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.fit_transform(X)\n",
    "        return self\n",
    "    def fit_transform(self, X, y=None,**kwargs):\n",
    "        kwargs.setdefault('full_matrices', False)\n",
    "        kwargs.setdefault('compute_uv', True)\n",
    "        kwargs.setdefault('name', None)\n",
    "        \n",
    "        X = np.array(X, dtype= np.float32 if str(X.values.dtype)=='float32' else np.float64) if isinstance(X, pandas.core.frame.DataFrame) else np.array(X, dtype= np.float32 if str(X.dtype)=='float32' else np.float64)#changing to recommended dtype, accomodating dataframe & numpy array\n",
    "\n",
    "        #X = np.array(X)\n",
    "        #y = np.array(y)\n",
    "        \n",
    "        n_components= self.primal.n_components#using primal attributes passed from adapter\n",
    "        n_features = X.shape[1]\n",
    "        if n_components>= n_features:\n",
    "                raise ValueError(\"n_components must be < n_features;\"\n",
    "                                 \" got %d >= %d\" % (n_components, n_features))\n",
    "                \n",
    "        sess= tf.Session()#for TF  1.13\n",
    "        s,u,v= sess.run(tf.linalg.svd(X, full_matrices=kwargs['full_matrices'], compute_uv=kwargs['compute_uv']))#for TF  1.13\n",
    "        \n",
    "        self.components_= v[:n_components,:]\n",
    "        X_transformed = u[:,:n_components] * s[:n_components]\n",
    "        \n",
    "        self.singular_values_ = s[:n_components]\n",
    "        return X_transformed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using existing adapter `SklearnKerasRegressor` for model with minor modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsquare.architectures import sklearn\n",
    "class SklearnKerasRegressor():\n",
    "    \n",
    "    def __init__(self, proxy_model, primal_model, **kwargs):\n",
    "        self.primal_model = primal_model\n",
    "        self.proxy_model = proxy_model\n",
    "        self.params = None\n",
    "\n",
    "    def fit(self, X, y, **kwargs):\n",
    "        self.proxy_model.X = X\n",
    "        self.proxy_model.y = y\n",
    "        self.proxy_model.primal = self.primal_model\n",
    "        kwargs.setdefault('verbose', 0)\n",
    "        kwargs.setdefault('epochs', 250)\n",
    "        kwargs.setdefault('batch_size', 30)\n",
    "        kwargs.setdefault('params', self.params)\n",
    "        self.params = kwargs['params']\n",
    "\n",
    "        if self.params != None: ## Validate implementation with different types of tune input\n",
    "            if not isinstance(self.params, dict):\n",
    "                raise TypeError(\"Params should be of type 'dict'\")\n",
    "            self.params = _parse_params(self.params, return_as='flat')\n",
    "            self.proxy_model.update_params(self.params)\n",
    "\n",
    "        #if self.proxy_model.__class__.__name in ['SVD', 'PCA']:\n",
    "        if isinstance(self.proxy_model, (sklearn.DimensionalityReductionModel)):#Triggers when adapter is being used for matrix decomposition apis\n",
    "            return self.proxy_model.fit_transform(X)\n",
    "        \n",
    "        primal_model = self.primal_model\n",
    "        primal_model.fit(X, y)\n",
    "        y_pred = primal_model.predict(X)\n",
    "        primal_data = {\n",
    "            'y_pred': y_pred,\n",
    "            'model_name': primal_model.__class__.__name__\n",
    "        }\n",
    "\n",
    "        self.final_model = get_best_model(X, y, proxy_model=self.proxy_model, primal_data=primal_data,\n",
    "                                          epochs=kwargs['epochs'], batch_size=kwargs['batch_size'],\n",
    "                                          verbose=kwargs['verbose'])\n",
    "        return self.final_model  # Not necessary.\n",
    "\n",
    "    def score(self, X, y, **kwargs):\n",
    "        if isinstance(self.proxy_model, (sklearn.DimensionalityReductionModel)):\n",
    "            raise AttributeError(\"'SklearnKerasRegressor' object has no attribute 'score'\")\n",
    "\n",
    "        score = self.final_model.evaluate(X, y, **kwargs)\n",
    "        return score\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Pending:\n",
    "        1) Write a 'filter_sk_params' function(check keras_regressor wrapper) if necessary.\n",
    "        2) Data checks and data conversions\n",
    "        '''\n",
    "        if isinstance(self.proxy_model, (sklearn.DimensionalityReductionModel)):\n",
    "            raise AttributeError(\"'SklearnKerasRegressor' object has no attribute 'predict'\")\n",
    "            \n",
    "        pred = self.final_model.predict(X)\n",
    "        return pred\n",
    "\n",
    "    def save(self, filename=None):\n",
    "        if filename == None:\n",
    "            raise ValueError(\n",
    "                'Name Error: to save the model you need to specify the filename')\n",
    "\n",
    "        pickle.dump(self.final_model, open(filename + '.pkl', 'wb'))\n",
    "\n",
    "        self.final_model.save(filename + '.h5')\n",
    "\n",
    "        onnx_model = onnxmltools.convert_keras(self.final_model)\n",
    "        onnxmltools.utils.save_model(onnx_model, filename + '.onnx')\n",
    "\n",
    "    def explain(self, **kwargs):\n",
    "        # @param: SHAP or interpret\n",
    "        print('Coming soon...')\n",
    "        return self.final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading dataframe for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original df_x dims: (506, 13)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "boston =load_boston()\n",
    "df_x= pd.DataFrame(boston.data, columns= boston.feature_names)\n",
    "lbe= LabelEncoder()\n",
    "df_x = df_x.apply(lambda x: lbe.fit_transform(x))#df_x[col]))\n",
    "df_y= df_y= pd.DataFrame(boston.target)\n",
    "\n",
    "print('original df_x dims:', df_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initiating `primal model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "primal = TruncatedSVD(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn_svd truncated dims: (506, 10)\n"
     ]
    }
   ],
   "source": [
    "skl_truncated_x = primal.fit(df_x).transform(df_x)\n",
    "\n",
    "print('sklearn_svd truncated dims:', skl_truncated_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trying the Base_model/Parent class methods from `sklearn svd` & other similar decomposition models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'randomized',\n",
       " 'n_components': 10,\n",
       " 'n_iter': 5,\n",
       " 'random_state': None,\n",
       " 'tol': 0.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primal.get_params()#inherited from TruncatedSVD.BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.__repr__ of TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
       "             random_state=None, tol=0.0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primal.__repr__#inherited from TruncatedSVD.BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.__getstate__ of TruncatedSVD(algorithm='randomized', n_components=10, n_iter=5,\n",
       "             random_state=None, tol=0.0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primal.__getstate__#inherited from TruncatedSVD.BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "#pca = PCA(n_components=10)\n",
    "#pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca_transformed_x = pca.fit_transform(df_x)# PCA's APIs\n",
    "#pca_transformed_x.shape#equivalent of left singular matrix from svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Doping the primal model to use `tf SVD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('sklearn',\n",
       "  'TruncatedSVD'): {'default': [<mlsquare.architectures.sklearn.SVD at 0x7f0b7413ceb8>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'LogisticRegression'): {'default': [<mlsquare.architectures.sklearn.LogisticRegression at 0x7f0bb57d8d30>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'LinearRegression'): {'default': [<mlsquare.architectures.sklearn.LinearRegression at 0x7f0bb57d8ef0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Ridge'): {'default': [<mlsquare.architectures.sklearn.Ridge at 0x7f0bb57e90f0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'Lasso'): {'default': [<mlsquare.architectures.sklearn.Lasso at 0x7f0bb57e92b0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'ElasticNet'): {'default': [<mlsquare.architectures.sklearn.ElasticNet at 0x7f0bb57e9470>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasRegressor]},\n",
       " ('sklearn',\n",
       "  'LinearSVC'): {'default': [<mlsquare.architectures.sklearn.LinearSVC at 0x7f0bb57e9630>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'SVC'): {'default': [<mlsquare.architectures.sklearn.SVC at 0x7f0bb57e9978>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]},\n",
       " ('sklearn',\n",
       "  'DecisionTreeClassifier'): {'default': [<mlsquare.architectures.sklearn.DecisionTreeClassifier at 0x7f0bb57e9cc0>,\n",
       "   mlsquare.adapters.sklearn.SklearnKerasClassifier]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlsquare.base import registry\n",
    "registry.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy model: <mlsquare.architectures.sklearn.SVD object at 0x7f0b7413ceb8> \n",
      "correspnding adapter: <class 'mlsquare.adapters.sklearn.SklearnKerasRegressor'>\n"
     ]
    }
   ],
   "source": [
    "mod,ada= registry[('sklearn', 'TruncatedSVD')]['default']\n",
    "print('proxy model:', mod,'\\ncorrespnding adapter:', ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlsquare.adapters.sklearn.SklearnKerasRegressor at 0x7f0bd035b2b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ada(primal_model=primal, proxy_model=mod)\n",
    "model#SklearnKerasRegressor class object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "??model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "inp2= np.array(df_x.values, dtype= np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fitting the doped model with -- Dataframe inputs Or Numpy array inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed input shape: (506, 10)\n"
     ]
    }
   ],
   "source": [
    "#trans_input= mode1.fit(df_x, df_y) #takes in dataframe input\n",
    "trans_input = model.fit(inp2, df_y) #takes in numpy array input\n",
    "\n",
    "print('transformed input shape:', trans_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Trying how sklearn SVD deals with anamoly methods--`.score()`, `.predict()` and implement similar error flagging for undefined proxy_model apis\n",
    "    * Chances are a user presuming TrucnatedSVD as a usual model will try out above methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TruncatedSVD' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4977baad7635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprimal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#error from sklearn_svd's undefined  api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#primal is an sklearn object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TruncatedSVD' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "primal.predict(df_x)#error from sklearn_svd's undefined  api\n",
    "#primal is an sklearn object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SklearnKerasRegressor' object has no attribute 'final_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1028fe8f35e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/mlsquare_experiments/src/mlsquare/adapters/sklearn.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SklearnKerasRegressor' object has no attribute 'final_model'"
     ]
    }
   ],
   "source": [
    "model.score(inp2, df_y)#before any explicit error flagging\n",
    "#model is a adapter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SklearnKerasRegressor' object has no attribute 'final_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e6bd785d478c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/mlsquare_experiments/src/mlsquare/adapters/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    347\u001b[0m         2) Data checks and data conversions\n\u001b[1;32m    348\u001b[0m         '''\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SklearnKerasRegressor' object has no attribute 'final_model'"
     ]
    }
   ],
   "source": [
    "model.predict(inp2)#before any explicit error flagging\n",
    "#model is a adapter object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un-implemented methods flag an `AttributeError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SklearnKerasRegressor' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-046c230fe354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#After flagging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#model is a adapter object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mlsquare_experiments/src/mlsquare/adapters/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    351\u001b[0m         '''\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDimensionalityReductionModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'SklearnKerasRegressor' object has no attribute 'predict'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SklearnKerasRegressor' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "model.predict(inp2)#After flagging \n",
    "#model is a adapter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SklearnKerasRegressor' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-73e375c2534e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#After flagging, an un-implemented methods will anyways shoot an `AttributeError`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#model is a adapter object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mlsquare_experiments/src/mlsquare/adapters/sklearn.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDimensionalityReductionModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'SklearnKerasRegressor' object has no attribute 'score'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SklearnKerasRegressor' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "model.score(inp2, df_y)#After flagging, an un-implemented methods will anyways shoot an `AttributeError`\n",
    "#model is a adapter object"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
