{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributing svd as a block through DeepCtr's methods to mlsquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fork mlsquare repository to your account and clone.**\n",
    "\n",
    "**Or just Clone https://github.com/mlsquare/mlsquare.git**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Navigate to `src/mlsquare/layers` folder, Where all potential lego blocks are to be added as python modules.\n",
    "* Add  `deepctr.py` containing code for deepctr's SVD. \n",
    "* The SVD implementation in deepctr module here is obtained/realised with available deepctr's classes & methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following notebook serves as walkthough procedure for contributing deepctr's svd to mlsquare layers.**\n",
    "* Towards the end the obatained model is evaluating against sample test values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Following code is saved as SVD function in `mlsquare/layers/deepctr.py`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from deepctr.inputs import build_input_features, input_from_feature_columns\n",
    "\n",
    "from deepctr.layers.interaction import FM\n",
    "from deepctr.layers.utils import concat_fun\n",
    "\n",
    "\n",
    "def SVD(feature_columns, embedding_size=100,\n",
    "        l2_reg_embedding=1e-5, l2_reg_linear=1e-5, l2_reg_dnn=0, init_std=0.0001, seed=1024, bi_dropout=0,\n",
    "        dnn_dropout=0):\n",
    "    \"\"\"Instantiates the Neural Factorization Machine architecture.\n",
    "\n",
    "    :param feature_columns: An iterable containing all the sparse features used by model.\n",
    "    :param num_factors: number of units in latent representation layer.\n",
    "    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n",
    "    :param l2_reg_linear: float. L2 regularizer strength applied to linear part.\n",
    "    :param l2_reg_dnn: float . L2 regularizer strength applied to DNN\n",
    "    :param init_std: float,to use as the initialize std of embedding vector\n",
    "    :param seed: integer ,to use as random seed.\n",
    "    :param biout_dropout: When not ``None``, the probability we will drop out the output of BiInteractionPooling Layer.\n",
    "    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n",
    "    :param act_func: Activation function to use at prediction layer.\n",
    "    :param task: str, ``\"binary\"`` for  'binary_crossentropy' loss or  ``\"multiclass\"`` for 'categorical_crossentropy' loss\n",
    "    :return: A Keras model instance.\n",
    "    \"\"\"\n",
    "    features = build_input_features(feature_columns)\n",
    "\n",
    "    input_layers = list(features.values())\n",
    "\n",
    "    sparse_embedding_list, _ = input_from_feature_columns(features,feature_columns, embedding_size, l2_reg_embedding, init_std, seed)\n",
    "    \n",
    "    fm_input = concat_fun(sparse_embedding_list, axis=1)\n",
    "    fm_logit = FM()(fm_input)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=input_layers, outputs=fm_logit)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to utilise above block as module to obtain a SVD equivalent dnn model, thereafter train & evaluate that model, Proceed as follows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import sample dataset as pandas dataframe\n",
    "* List `sparse_features` & label encode input dataframe.\n",
    "* Perform `train_test_split` to output training/test data and labels for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0      196       242       3  881250949\n",
       "1      186       302       3  891717742\n",
       "2       22       377       1  878887116"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "DeepCTR version 0.7.0 detected. Your version is 0.6.3.\n",
      "Use `pip install -U deepctr` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR/releases/tag/v0.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.inputs import SparseFeat\n",
    "\n",
    "\n",
    "data_path = os.path.expanduser('u.data')\n",
    "df= pd.read_csv(data_path, sep='\\t',names= 'user_id,movie_id,rating,timestamp'.split(','))#, header=None)#used for DeepCTR\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* List **sparse features** from input dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names: ['user_id', 'movie_id'] \n",
      "label name: ['rating']\n"
     ]
    }
   ],
   "source": [
    "sparse_features = [\"user_id\", \"movie_id\"]\n",
    "y= ['rating']\n",
    "print('feature names:',sparse_features, '\\nlabel name:',y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Label encoding features of input dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0      195       241       3  881250949\n",
       "1      185       301       3  891717742\n",
       "2       21       376       1  878887116"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        df[feat] = lbe.fit_transform(df[feat])\n",
    "        \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing training input data & target labels.**\n",
    "* Training & test input data should be a list of numpy arrays of `user_ids` & `movie_ids`.\n",
    "* Labels as numpy array of target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_model_input = [train[name].values for name in sparse_features]#includes values from only data[user_id], data[movie_id]\n",
    "train_lbl = train[y].values\n",
    "\n",
    "test_model_input = [test[name].values for name in sparse_features]\n",
    "test_lbl = test[y].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:\n",
      " [array([920, 380,  82, ..., 698, 561, 552]), array([ 172,  343,   78, ..., 1374,  805,   80])] \n",
      "\n",
      "training labels:\n",
      " [[5]\n",
      " [3]\n",
      " [5]\n",
      " ...\n",
      " [3]\n",
      " [1]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "print('training data:\\n', train_model_input, '\\n\\ntraining labels:\\n', train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Obtain feature columns, perform required data preparatory operations as described in DeepCtr docs (refer https://deepctr-doc.readthedocs.io/en/latest/Quick-Start.html)\n",
    "* **Defining feature columns as list of SparseFeat instances for each sparse feature, here -- `user_id`, `movie_id`, by passing in `feature_name`, `num_unique feature vals` as arguments.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat:user_id, SparseFeat:movie_id]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [SparseFeat(feat, df[feat].nunique()) for feat in sparse_features]\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Import `SVD` from `mlsquare.layers.deepctr`\n",
    "* Instantiate the model using `feature_columns` from above.\n",
    "* Train the model & evaluate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-12-05 21:14:42,520\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-12-05_21-14-42_7176/logs.\n",
      "2019-12-05 21:14:42,632\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:31143 to respond...\n",
      "2019-12-05 21:14:42,776\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:23786 to respond...\n",
      "2019-12-05 21:14:42,780\tINFO services.py:760 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-12-05 21:14:42,815\tINFO services.py:1384 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    }
   ],
   "source": [
    "from mlsquare.layers.deepctr import SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "??SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Now Instantiate the model by passing in args-- `feature_columns` & `embedding_size`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/deepctr/layers/utils.py:156: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/deepctr/layers/utils.py:156: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_id (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_user_id (Embedding)  (None, 1, 100)       94300       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_movie_id (Embedding) (None, 1, 100)       168200      movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "no_mask (NoMask)                (None, 1, 100)       0           sparse_emb_user_id[0][0]         \n",
      "                                                                 sparse_emb_movie_id[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2, 100)       0           no_mask[0][0]                    \n",
      "                                                                 no_mask[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fm (FM)                         (None, 1)            0           concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 262,500\n",
      "Trainable params: 262,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = SVD(feature_columns, embedding_size=100)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compile the model & fit on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64000 samples, validate on 16000 samples\n",
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kev/Desktop/pyvirtual2/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 6s - loss: 6.2337 - mean_squared_error: 6.2077 - val_loss: 1.4820 - val_mean_squared_error: 1.4288\n",
      "Epoch 2/8\n",
      " - 6s - loss: 1.1983 - mean_squared_error: 1.1364 - val_loss: 1.0701 - val_mean_squared_error: 1.0017\n",
      "Epoch 3/8\n",
      " - 6s - loss: 1.0345 - mean_squared_error: 0.9629 - val_loss: 1.0258 - val_mean_squared_error: 0.9516\n",
      "Epoch 4/8\n",
      " - 5s - loss: 0.9983 - mean_squared_error: 0.9223 - val_loss: 1.0076 - val_mean_squared_error: 0.9303\n",
      "Epoch 5/8\n",
      " - 4s - loss: 0.9780 - mean_squared_error: 0.8992 - val_loss: 0.9983 - val_mean_squared_error: 0.9187\n",
      "Epoch 6/8\n",
      " - 4s - loss: 0.9498 - mean_squared_error: 0.8691 - val_loss: 0.9835 - val_mean_squared_error: 0.9017\n",
      "Epoch 7/8\n",
      " - 4s - loss: 0.9190 - mean_squared_error: 0.8362 - val_loss: 0.9842 - val_mean_squared_error: 0.9007\n",
      "Epoch 8/8\n",
      " - 4s - loss: 0.8841 - mean_squared_error: 0.7993 - val_loss: 0.9677 - val_mean_squared_error: 0.8821\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"mse\", metrics=['mse'] )\n",
    "history = model.fit(train_model_input, train_lbl, batch_size=64, epochs=8, verbose=2, validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Evaluating model prediction on test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>39551</td>\n",
       "      <td>344</td>\n",
       "      <td>233</td>\n",
       "      <td>4</td>\n",
       "      <td>884991831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44160</td>\n",
       "      <td>480</td>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>885828426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25092</td>\n",
       "      <td>469</td>\n",
       "      <td>918</td>\n",
       "      <td>3</td>\n",
       "      <td>879178370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating  timestamp\n",
       "39551      344       233       4  884991831\n",
       "44160      480        99       4  885828426\n",
       "25092      469       918       3  879178370"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction for test user id: 480 & item id : 99 from above is: [4.0426135]\n"
     ]
    }
   ],
   "source": [
    "user_id = test_model_input[0][1]\n",
    "item_id = test_model_input[1][1]\n",
    "print('Model prediction for test user id: {} & item id : {} from above is: {}'.format(user_id, item_id, model.predict(test_model_input)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
