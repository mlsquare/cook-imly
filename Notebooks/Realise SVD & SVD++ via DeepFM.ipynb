{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0      196       242       3  881250949\n",
       "1      186       302       3  891717742\n",
       "2       22       377       1  878887116\n",
       "3      244        51       2  880606923\n",
       "4      166       346       1  886397596"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data_path = os.path.expanduser('C:\\\\Users\\\\might\\\\Desktop\\\\jupyter notebooks\\\\u.data')\n",
    "df= pd.read_csv(data_path, sep='\\t',names= 'user_id,movie_id,rating,timestamp'.split(','))#, header=None)#used for DeepCTR\n",
    "\n",
    "sparse_features = [\"movie_id\", \"user_id\"]\n",
    "y= ['rating']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To be used in surpriselib\n",
    "* above `trainset` & `testset` folds will be consistent across surprise SVD, NN_SVD, DeepCTR's SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1004 19:52:48.781906 23276 utils.py:41] \n",
      "DeepCTR version 0.6.2 detected. Your version is 0.6.1.\n",
      "Use `pip install -U deepctr` to upgrade.Changelog: https://github.com/shenweichen/DeepCTR/releases/tag/v0.6.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "??Dataset.load_from_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "rdr = Reader(rating_scale=(1,5))\n",
    "data= Dataset.load_from_df(trainset[sparse_features+ y], reader= rdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 24.751879692077637\n"
     ]
    }
   ],
   "source": [
    "train_s = data.build_full_trainset()\n",
    "from surprise import accuracy\n",
    "import time\n",
    "\n",
    "t1= time.time()\n",
    "\n",
    "algo_svd = SVD(n_factors=100, n_epochs=128)\n",
    "\n",
    "algo_svd.fit(train_s)\n",
    "\n",
    "print('training time:', time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9737\n",
      "MAE:  0.7629\n",
      "\n",
      "Test results on 80k training data & 20k test data -- rmse: 0.973745067502651, mae: 0.7629353508722497\n"
     ]
    }
   ],
   "source": [
    "test_s = Dataset.load_from_df(testset[sparse_features+y], reader=rdr)\n",
    "test_s= test_s.build_full_trainset().build_testset()\n",
    "\n",
    "pred = algo_svd.test(test_s)\n",
    "\n",
    "print('\\nTest results on 80k training data & 20k test data -- rmse: {}, mae: {}'.format(accuracy.rmse(pred), accuracy.mae(pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Reference NN model structure for SVD**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_id (InputLayer)            [(None, 943)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_id (InputLayer)           [(None, 1682)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "latent_embed_user_id (Dense)    (None, 100)          94400       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "latent_embed_movie_id (Dense)   (None, 100)          168300      movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_8 (Dot)                     (None, 1)            0           latent_embed_user_id[0][0]       \n",
      "                                                                 latent_embed_movie_id[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            2           dot_8[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 262,702\n",
      "Trainable params: 262,702\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "user_in_layer = Input(shape=(df[sparse_features[1]].nunique()), name='user_id')#top half of input layer,+1 to accomodate on-hot encoded vectors\n",
    "movie_in_layer = Input(shape=(df[sparse_features[0]].nunique()), name= 'movie_id')#bottom half of input layer\n",
    "\n",
    "\n",
    "#total input moves as concatenated user_id & movie_id one-hot encoded forms\n",
    "\n",
    "hid_layer_u = Dense(100, name='latent_embed_user_id')(user_in_layer)#latent dimension k=100 for user_id #_Embedding(100, )\n",
    "hid_layer_m= Dense(100,name='latent_embed_movie_id')(movie_in_layer)#latent dimension k=100 for movie_id\n",
    "\n",
    "merge_layer = keras.layers.dot([hid_layer_u, hid_layer_m], axes=1)\n",
    "\n",
    "\n",
    "\n",
    "#predictions = Dense(5, activation='softmax')(merge_layer)#treating problem as multi-class problem\n",
    "predictions = Dense(1, activation='relu')(merge_layer)\n",
    "\n",
    "model = Model(inputs=[user_in_layer, movie_in_layer], outputs= predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names: ['movie_id', 'user_id'] \n",
      "label name: ['rating']\n"
     ]
    }
   ],
   "source": [
    "print('feature names:',sparse_features, '\\nlabel name:',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train_user_in: (100000, 943) \n",
      "shape of x_train_movie_in: (100000, 1682) \n",
      "shape of x_train_user_in: (100000,)\n"
     ]
    }
   ],
   "source": [
    "x_train_movie_in = np.asarray(pd.get_dummies(df[sparse_features[0]]))#, num_classes=max(df[sparse_features[0]]))#contains the one-hot encoded movie_id data, shaped (batch_size, max(sm_df[1]))\n",
    "x_train_user_in = np.asarray(pd.get_dummies(df[sparse_features[1]]))#contains the one-hot encoded user_id data, shaped (batch_size, max(sm_df[0]))\n",
    "\n",
    "\n",
    "#y_ratings= np.asarray(pd.get_dummies(df[y[0]]))#treating problem as multi-class problem\n",
    "\n",
    "y_ratings= df[y].values.reshape(-1)\n",
    "print('shape of x_train_user_in:', x_train_user_in.shape,'\\nshape of x_train_movie_in:', x_train_movie_in.shape,\n",
    "      '\\nshape of x_train_user_in:',y_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/8\n",
      "80000/80000 [==============================] - 5s 58us/sample - loss: 1.4011 - mae: 0.9791 - accuracy: 0.0616 - val_loss: 1.2513 - val_mae: 0.9407 - val_accuracy: 0.0579\n",
      "Epoch 2/8\n",
      "80000/80000 [==============================] - 4s 55us/sample - loss: 1.2713 - mae: 0.9457 - accuracy: 0.0619 - val_loss: 1.2515 - val_mae: 0.9384 - val_accuracy: 0.0579\n",
      "Epoch 3/8\n",
      "80000/80000 [==============================] - 5s 60us/sample - loss: 1.2707 - mae: 0.9454 - accuracy: 0.0619 - val_loss: 1.2503 - val_mae: 0.9394 - val_accuracy: 0.0579\n",
      "Epoch 4/8\n",
      "80000/80000 [==============================] - 4s 52us/sample - loss: 1.2678 - mae: 0.9443 - accuracy: 0.0619 - val_loss: 1.2457 - val_mae: 0.9399 - val_accuracy: 0.0579\n",
      "Epoch 5/8\n",
      "80000/80000 [==============================] - 4s 53us/sample - loss: 1.2417 - mae: 0.9342 - accuracy: 0.0619 - val_loss: 1.1909 - val_mae: 0.9112 - val_accuracy: 0.0579\n",
      "Epoch 6/8\n",
      "80000/80000 [==============================] - 4s 53us/sample - loss: 1.0892 - mae: 0.8510 - accuracy: 0.0619 - val_loss: 1.0235 - val_mae: 0.8024 - val_accuracy: 0.0579\n",
      "Epoch 7/8\n",
      "80000/80000 [==============================] - 4s 54us/sample - loss: 0.9546 - mae: 0.7773 - accuracy: 0.0619 - val_loss: 0.9299 - val_mae: 0.7707 - val_accuracy: 0.0579\n",
      "Epoch 8/8\n",
      "80000/80000 [==============================] - 4s 56us/sample - loss: 0.9110 - mae: 0.7566 - accuracy: 0.0619 - val_loss: 0.9149 - val_mae: 0.7688 - val_accuracy: 0.0578\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics= ['mae', 'accuracy'])\n",
    "\n",
    "history = model.fit([x_train_user_in, x_train_movie_in], y_ratings, verbose=1, epochs=8, batch_size=32,validation_split=0.2)#, callbacks=[checkpoints])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **SVD Using `deepctr.DeepFM`**\n",
    "* Following code attempts to follow refrence model & produce a DNN equivalent of SVD using as many DeepCTR's given modules/functionalities as possible.\n",
    "* Especially layers from `deepctr.models.DeepFM` are tried without disturbing existing `DeepFM( )` function, for resulting similar transformations & producing a SVD model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.inputs import SparseFeat,get_fixlen_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0      196       242       3  881250949\n",
       "1      186       302       3  891717742\n",
       "2       22       377       1  878887116\n",
       "3      244        51       2  880606923"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp\n",
       "0      195       241       3  881250949\n",
       "1      185       301       3  891717742\n",
       "2       21       376       1  878887116\n",
       "3      243        50       2  880606923"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_features = [\"movie_id\", \"user_id\"]\n",
    "y= ['rating']\n",
    "for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        df[feat] = lbe.fit_transform(df[feat])\n",
    "    # 2.count #unique features for each sparse field\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, df[feat].nunique()) for feat in sparse_features]\n",
    "\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of columns included in train & test: 2\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_model_input = [train[name].values for name in sparse_features]#includes values from only data[user_id], data[movie_id]\n",
    "test_model_input = [test[name].values for name in sparse_features]#includes values from only data[user_id], data[movie_id]\n",
    "\n",
    "print('no. of columns included in train & test:', len(train_model_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the following DeepFM( ) model**\n",
    "* Embedding size ~ num_factors(surprise SVD)= 100\n",
    "\n",
    "* The Input layer receives the `OrdinalEncoded` values of `User_id` and `movie_id` which are further one-hot encoded before sparse layers `sparse_emb_movie_id` & `sparse_emb_user_id`.\n",
    "* The `user_factors` (pu) & `item_factors` (qi) vectors are realised as weights of shape (1682,100) and (943,100) resepectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique features in movie_id: 1682\n"
     ]
    }
   ],
   "source": [
    "print('number of unique features in movie_id:', df[sparse_features[0]].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique features in user_id: 943\n"
     ]
    }
   ],
   "source": [
    "print('number of unique features in user_id:', df[sparse_features[1]].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "movie_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_movie_id (Embedding) (None, 1, 100)       168200      movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_user_id (Embedding)  (None, 1, 100)       94300       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 1, 200)       0           sparse_emb_movie_id[0][0]        \n",
      "                                                                 sparse_emb_user_id[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_movie_id (Emb (None, 1, 1)         1682        movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "linear0sparse_emb_user_id (Embe (None, 1, 1)         943         user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 200)          0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 1, 2)         0           linear0sparse_emb_movie_id[0][0] \n",
      "                                                                 linear0sparse_emb_user_id[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 2, 100)       0           sparse_emb_movie_id[0][0]        \n",
      "                                                                 sparse_emb_user_id[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dnn_3 (DNN)                     (None, 128)          42240       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "linear_3 (Linear)               (None, 1, 1)         1           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fm_9 (FM)                       (None, 1)            0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            128         dnn_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 1, 1)         0           linear_3[0][0]                   \n",
      "                                                                 fm_9[0][0]                       \n",
      "                                                                 dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "prediction_layer_4 (PredictionL (None, 1)            1           add_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 307,495\n",
      "Trainable params: 307,495\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, embedding_size=100, task='regression')#DNN=Flase\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Above model summary exhibits some additional/irrelevant layers, which serve no utility in implementing SVD or mimicking structure mentioned before.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr.models import svd#svd is the custom module containing code pertaining to SVD's reference NN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "??svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Now will modify this custom module code using existing deepctr's functionalities (data processing methods & modules).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr.inputs import input_from_feature_columns, get_linear_logit,build_input_features,combined_dnn_input\n",
    "import tensorflow as tf\n",
    "from deepctr.layers.utils import concat_fun\n",
    "from deepctr.layers.interaction import FM\n",
    "from deepctr.layers.core import PredictionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD(feature_columns, embedding_size=100,\n",
    "        l2_reg_embedding=1e-5, l2_reg_linear=1e-5, l2_reg_dnn=0, init_std=0.0001, seed=1024, bi_dropout=0,\n",
    "        dnn_dropout=0, act_func='sigmoid', task='binary'):\n",
    "\n",
    "    features = build_input_features(feature_columns)\n",
    "\n",
    "    input_layers = list(features.values())\n",
    "    sparse_embedding_list, _ = input_from_feature_columns(features,feature_columns,\n",
    "                                                                              embedding_size,\n",
    "                                                                              l2_reg_embedding,init_std,\n",
    "                                                                              seed)\n",
    "    \n",
    "    fm_input = concat_fun(sparse_embedding_list, axis=1)\n",
    "    fm_logit = FM()(fm_input)\n",
    "    \n",
    "    #hid_layer_1= Dense(num_factors)(input_layers[0])\n",
    "    #output = PredictionLayer(task)(final_logit)\n",
    "    model = tf.keras.models.Model(inputs=input_layers, outputs=fm_logit)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "movie_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_movie_id (Embedding) (None, 1, 100)       168200      movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_user_id (Embedding)  (None, 1, 100)       94300       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 2, 100)       0           sparse_emb_movie_id[0][0]        \n",
      "                                                                 sparse_emb_user_id[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fm_10 (FM)                      (None, 1)            0           concatenate_18[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 262,500\n",
      "Trainable params: 262,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = SVD(linear_feature_columns, embedding_size=100)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64000 samples, validate on 16000 samples\n",
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\might\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64000/64000 - 4s - loss: 6.2732 - mse: 6.2476 - val_loss: 1.5095 - val_mse: 1.4566\n",
      "Epoch 2/8\n",
      "64000/64000 - 2s - loss: 1.1913 - mse: 1.1293 - val_loss: 1.0942 - val_mse: 1.0256\n",
      "Epoch 3/8\n",
      "64000/64000 - 2s - loss: 1.0188 - mse: 0.9470 - val_loss: 1.0355 - val_mse: 0.9608\n",
      "Epoch 4/8\n",
      "64000/64000 - 2s - loss: 0.9726 - mse: 0.8961 - val_loss: 1.0217 - val_mse: 0.9437\n",
      "Epoch 5/8\n",
      "64000/64000 - 2s - loss: 0.9396 - mse: 0.8602 - val_loss: 1.0089 - val_mse: 0.9283\n",
      "Epoch 6/8\n",
      "64000/64000 - 2s - loss: 0.9078 - mse: 0.8260 - val_loss: 0.9962 - val_mse: 0.9132\n",
      "Epoch 7/8\n",
      "64000/64000 - 2s - loss: 0.8758 - mse: 0.7918 - val_loss: 0.9913 - val_mse: 0.9062\n",
      "Epoch 8/8\n",
      "64000/64000 - 2s - loss: 0.8446 - mse: 0.7583 - val_loss: 0.9842 - val_mse: 0.8970\n"
     ]
    }
   ],
   "source": [
    "model2.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = model2.fit(train_model_input, train[y].values, batch_size=64, epochs=8, verbose=2, validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tapping trained equivalent of decomposed matrices (SVD's) `qi` & `pu` at `sparse_emb_movie` & `sparse_emb_user` layers; And estimating ratings for given a given pair of `uid` & `mid`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer name:  sparse_emb_movie_id \n",
      "shape of weight matrix:  (1682, 100)\n"
     ]
    }
   ],
   "source": [
    "#layer2= model2.layers[2].get_weights()[0]#sparse_movie weights Or qi\n",
    "#print('layer name: ', model2.layers[2].name,'\\nshape of weight matrix: ', layer2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer name:  sparse_emb_user_id \n",
      "shape of weight matrix:  (943, 100)\n"
     ]
    }
   ],
   "source": [
    "#layer3= model2.layers[3].get_weights()[0]#sparse_user weights Or pu\n",
    "#print('layer name: ', model2.layers[3].name,'\\nshape of weight matrix: ', layer3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following is the latent output at layer 2 & 3;\n",
    "* And also the rating result that follows from manual vector product between two latent representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for user_id: 533 & movie_id: 1033,\n",
      "predicted rating from SVD: 3.3714075088500977\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "t_ui = test_model_input[1][1]\n",
    "t_mi= test_model_input[0][1]\n",
    "\n",
    "\n",
    "#outputs the latent reprsentation of movie_id 1033 at layer 2 named:  sparse_emb_user_id \n",
    "output_sparse_emb_mov = K.function([model2.layers[0].input],[model2.layers[2].output])\n",
    "test_output_movie = output_sparse_emb_mov([t_mi])\n",
    "\n",
    "#outputs the latent reprsentatio of user_id 533 at layer 3 named:  sparse_emb_user_id \n",
    "output_sparse_emb_user = K.function([model2.layers[1].input],[model2.layers[3].output])\n",
    "test_output_user = output_sparse_emb_user([t_ui])\n",
    "\n",
    "pred_ui_mi = np.dot(test_output_movie[0], test_output_user[0])\n",
    "print('for user_id: {} & movie_id: {},\\npredicted rating from SVD: {}'.format(t_ui, t_mi,pred_ui_mi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparing above results with usual `model.predict(test_model_input)` i.e., predictions from complete model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predictions: [[3.3714075]]\n"
     ]
    }
   ],
   "source": [
    "print('Model predictions:', model2.predict([np.array([1033]),np.array([533])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Now to further with input transformation from Inputs, latent to final ratings; And understand code underneath `deepctr.layers.interaction.FM`.**\n",
    "\n",
    "\n",
    "* **Stripping last layer: `FM( )`; Output at layer `concatenate_18`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following is a test method, same as `SVD( )`, only missing link to `FM( )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'concatenate_18'"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.layers[4].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "movie_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_movie_id (Embedding) (None, 1, 100)       168200      movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_user_id (Embedding)  (None, 1, 100)       94300       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 100)       0           sparse_emb_movie_id[0][0]        \n",
      "                                                                 sparse_emb_user_id[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 262,500\n",
      "Trainable params: 262,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def test_out(feature_columns, embedding_size=100,\n",
    "        l2_reg_embedding=1e-5, l2_reg_linear=1e-5, l2_reg_dnn=0, init_std=0.0001, seed=1024, bi_dropout=0,\n",
    "        dnn_dropout=0, act_func='sigmoid', task='binary'):\n",
    "\n",
    "    features = build_input_features(feature_columns)\n",
    "\n",
    "    input_layers = list(features.values())\n",
    "    sparse_embedding_list, _ = input_from_feature_columns(features,feature_columns,\n",
    "                                                                              embedding_size,\n",
    "                                                                              l2_reg_embedding,init_std,\n",
    "                                                                              seed)\n",
    "    \n",
    "    fm_input = concat_fun(sparse_embedding_list, axis=1)\n",
    "    #fm_logit = FM()(fm_input)\n",
    "    \n",
    "    #hid_layer_1= Dense(num_factors)(input_layers[0])\n",
    "    #output = PredictionLayer(task)(final_logit)\n",
    "    model = tf.keras.models.Model(inputs=input_layers, outputs=fm_input)\n",
    "    return model\n",
    "\n",
    "test_output_model = test_out(linear_feature_columns, embedding_size=100)\n",
    "test_output_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output= test_output_model.predict([np.array([579]),np.array([171])])\n",
    "\n",
    "test_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_id: 171 \n",
      "m_id: 579\n"
     ]
    }
   ],
   "source": [
    "print('u_id:', t_ui,'\\nm_id:',t_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#outputs the latent reprsentation of movie_id 1033\n",
    "output_sparse_emb_mov = K.function([test_output_model.layers[0].input],[test_output_model.layers[2].output])\n",
    "test_output_movie = output_sparse_emb_mov([t_mi])#Same as test_output[0][0]\n",
    "\n",
    "#outputs the latent reprsentatio of user_id 533\n",
    "output_sparse_emb_user = K.function([test_output_model.layers[1].input],[test_output_model.layers[3].output])\n",
    "test_output_user = output_sparse_emb_user([t_ui])#Same as test_output[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manual_concat = np.concatenate((test_output_movie[0].reshape(1,-1),test_output_user[0].reshape(1,-1)), axis=0)\n",
    "#manual_concat.shape#Same as test_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The output here is a `dot` between raw latent embeddings, which are due to be passed into FM layer, wherein the supposition is that the code underlying `deepctr.layers.interaction.FM` is doing operations to more or less produce the same output as dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2116801e-07"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(test_output_movie[0], test_output_user[0])# qi*pu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Custom `FM( ) layer` code**\n",
    "\n",
    "* Following computes the feature interaction between `movie_id` & `user_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'sparse_emb_movie_id/Identity:0' shape=(None, 1, 100) dtype=float32>,\n",
       " <tf.Tensor 'sparse_emb_user_id/Identity:0' shape=(None, 1, 100) dtype=float32>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input to FM() layer\n",
    "sparse_embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate/Identity:0' shape=(None, 2, 100) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_input = concat_fun(sparse_embedding_list, axis=1)\n",
    "fm_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fm_layer/Identity:0' shape=(None, 1) dtype=float32>"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm_logit= FM(name='fm_layer')(fm_input)\n",
    "fm_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 100)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_embeds_value= test_output#test_output is obtained from above, for (user,item)\n",
    "concated_embeds_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_of_sum = tf.square(tf.math.reduce_sum(concated_embeds_value, axis=1, keepdims=True))\n",
    "\n",
    "sum_of_square = tf.math.reduce_sum(concated_embeds_value * concated_embeds_value, \n",
    "                                   axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_term= square_of_sum - sum_of_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=179, shape=(1, 1), dtype=float32, numpy=array([[1.2116803e-07]], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_term= 0.5* tf.math.reduce_sum(cross_term, axis=2, keepdims=False)\n",
    "cross_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **6 sparse features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./movielens_sample.txt')\n",
    "sparse_features_ext = [\"movie_id\", \"user_id\",\"gender\", \"age\", \"occupation\", \"zip\"]\n",
    "y= ['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>968035345</td>\n",
       "      <td>Ed Wood (1994)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123</td>\n",
       "      <td>169</td>\n",
       "      <td>3</td>\n",
       "      <td>966536874</td>\n",
       "      <td>Patriot Games (1992)</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>976203603</td>\n",
       "      <td>Bridges of Madison County, The (1995)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp  \\\n",
       "0      107        12       4  968035345   \n",
       "1      123       169       3  966536874   \n",
       "2       12         6       4  976203603   \n",
       "\n",
       "                                   title           genres  gender  age  \\\n",
       "0                         Ed Wood (1994)     Comedy|Drama       0    2   \n",
       "1                   Patriot Games (1992)  Action|Thriller       1    1   \n",
       "2  Bridges of Madison County, The (1995)    Drama|Romance       0    2   \n",
       "\n",
       "   occupation  zip  \n",
       "0           4   35  \n",
       "1           4  118  \n",
       "2          13   99  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for feat in sparse_features_ext:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feat] = lbe.fit_transform(data[feat])\n",
    "        \n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='movie_id', dimension=187, use_hash=False, dtype='int32', embedding_name='movie_id', embedding=True),\n",
       " SparseFeat(name='user_id', dimension=193, use_hash=False, dtype='int32', embedding_name='user_id', embedding=True),\n",
       " SparseFeat(name='gender', dimension=2, use_hash=False, dtype='int32', embedding_name='gender', embedding=True),\n",
       " SparseFeat(name='age', dimension=7, use_hash=False, dtype='int32', embedding_name='age', embedding=True),\n",
       " SparseFeat(name='occupation', dimension=20, use_hash=False, dtype='int32', embedding_name='occupation', embedding=True),\n",
       " SparseFeat(name='zip', dimension=188, use_hash=False, dtype='int32', embedding_name='zip', embedding=True)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique()) for feat in sparse_features_ext]\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "#unique features for each sparse field\n",
    "linear_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "movie_id (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_id (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gender (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "occupation (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zip (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_movie_id (Embedding) (None, 1, 100)       18700       movie_id[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_user_id (Embedding)  (None, 1, 100)       19300       user_id[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_gender (Embedding)   (None, 1, 100)       200         gender[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_age (Embedding)      (None, 1, 100)       700         age[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_occupation (Embeddin (None, 1, 100)       2000        occupation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "sparse_emb_zip (Embedding)      (None, 1, 100)       18800       zip[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6, 100)       0           sparse_emb_movie_id[0][0]        \n",
      "                                                                 sparse_emb_user_id[0][0]         \n",
      "                                                                 sparse_emb_gender[0][0]          \n",
      "                                                                 sparse_emb_age[0][0]             \n",
      "                                                                 sparse_emb_occupation[0][0]      \n",
      "                                                                 sparse_emb_zip[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 59,700\n",
      "Trainable params: 59,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_output_model_6 = test_out(linear_feature_columns, embedding_size=100)\n",
    "test_output_model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of columns included in train & test: 6\n"
     ]
    }
   ],
   "source": [
    "train_6, test_6 = train_test_split(data, test_size=0.2)\n",
    "train_model_input_6 = [train_6[name].values for name in sparse_features_ext]\n",
    "test_model_input_6 = [test_6[name].values for name in sparse_features_ext]\n",
    "\n",
    "print('no. of columns included in train & test:', len(train_model_input_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>975799925</td>\n",
       "      <td>High School High (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>86</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>974435324</td>\n",
       "      <td>Young Frankenstein (1974)</td>\n",
       "      <td>Comedy|Horror</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>110</td>\n",
       "      <td>169</td>\n",
       "      <td>5</td>\n",
       "      <td>980115327</td>\n",
       "      <td>Patriot Games (1992)</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  movie_id  rating  timestamp                      title  \\\n",
       "36        16        42       1  975799925    High School High (1996)   \n",
       "34        86        72       5  974435324  Young Frankenstein (1974)   \n",
       "190      110       169       5  980115327       Patriot Games (1992)   \n",
       "\n",
       "              genres  gender  age  occupation  zip  \n",
       "36            Comedy       1    1           4  149  \n",
       "34     Comedy|Horror       1    5           1   69  \n",
       "190  Action|Thriller       1    3           7  116  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_6.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_id', 'user_id', 'gender', 'age', 'occupation', 'zip']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_features_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#providing inputs from first index of above dataframe\n",
    "t_mi = test_model_input_6[0][0]\n",
    "t_ui =test_model_input_6[1][0]\n",
    "t_ge =test_model_input_6[2][0]\n",
    "t_ag= test_model_input_6[3][0]\n",
    "t_oc= test_model_input_6[4][0]\n",
    "t_zi= test_model_input_6[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_output_model_6.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#outputs the latent reprsentation of movie_id 1033\n",
    "output_sparse_emb_mov_6 = K.function([test_output_model_6.layers[0].input],[test_output_model_6.layers[6].output])\n",
    "test_output_movie_6 = output_sparse_emb_mov_6([t_mi])\n",
    "\n",
    "#outputs the latent reprsentatio of user_id 533\n",
    "output_sparse_emb_user_6 = K.function([test_output_model_6.layers[1].input],[test_output_model_6.layers[7].output])\n",
    "test_output_user_6 = output_sparse_emb_user_6([t_ui])\n",
    "\n",
    "output_sparse_emb_gender_6 = K.function([test_output_model_6.layers[2].input],[test_output_model_6.layers[8].output])\n",
    "test_output_gender_6 = output_sparse_emb_gender_6([t_ge])\n",
    "\n",
    "output_sparse_emb_age_6 = K.function([test_output_model_6.layers[3].input],[test_output_model_6.layers[9].output])\n",
    "test_output_age_6 = output_sparse_emb_age_6([t_ag])\n",
    "\n",
    "output_sparse_emb_oc_6 = K.function([test_output_model_6.layers[4].input],[test_output_model_6.layers[10].output])\n",
    "test_output_oc_6 = output_sparse_emb_oc_6([t_oc])\n",
    "\n",
    "output_sparse_emb_zip_6 = K.function([test_output_model_6.layers[5].input],[test_output_model_6.layers[11].output])\n",
    "test_output_zip_6 = output_sparse_emb_zip_6([t_zi])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Following computes feature interaction between above 6 latent embeddings through FM( ) layer operations, same as before whihch results rating values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 6, 100)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output_6= test_output_model_6.predict(test_model_input_6, batch_size=32)\n",
    "#test_output_6= test_output_model_6.predict([test_model_input_6[0][1],test_model_input_6[1][1], test_model_input_6[2][1],test_model_input_6[3][1],test_model_input_6[4][1],test_model_input_6[5][1]])\n",
    "test_output_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 100)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated_embeds_value= test_output_6[0].reshape(1,6,100)#test_output is same as fm_logit, for (user,item)\n",
    "concated_embeds_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_of_sum = tf.square(tf.math.reduce_sum(concated_embeds_value, axis=1, keepdims=True))\n",
    "\n",
    "sum_of_square = tf.math.reduce_sum(concated_embeds_value * concated_embeds_value, \n",
    "                                   axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=460, shape=(1, 1), dtype=float32, numpy=array([[1.2463119e-07]], dtype=float32)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_term= square_of_sum - sum_of_square\n",
    "\n",
    "cross_term= 0.5* tf.math.reduce_sum(cross_term, axis=2, keepdims=False)\n",
    "cross_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.3915721e-08"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(test_output_movie_6[0],test_output_user_6[0])\n",
    "#,test_output_gender_6[0],test_output_age_6[0],\n",
    "       #test_output_oc_6[0],test_output_zip_6[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
