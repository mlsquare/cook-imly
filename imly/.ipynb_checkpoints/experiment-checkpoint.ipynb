{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments using IMLY ###\n",
    "\n",
    "This notebook contains experimental runs of IMLY with different datasets.  \n",
    "The readings of these experiments can be referred to in this [sheet](https://docs.google.com/spreadsheets/d/1E5jcq2w42gN8bMIaeaRJpAdhgSVN-2XDJ_YTHe4qfwY/edit?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #1\n",
    "\n",
    "#### Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:16<00:00, 16.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "266/266 [==============================] - 0s 85us/step\n",
      "Uploading ../data/diabetes_linear_regression.pdf to Amazon S3 bucket mlsquare-pdf\n",
      "..."
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_info = automation_script.get_dataset_info(\"diabetes\")\n",
    "url = \"../data/diabetes.csv\" if path.exists(\"../data/diabetes.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "# X = preprocessing.scale(X)\n",
    "# Y = preprocessing.normalize(Y)\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'linear_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 10:33:05,836\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-02-26 10:33:05,836\tINFO tune.py:145 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 4.6/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 4.6/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_model_1_epochs=200,optimizer=adam:\tPENDING\n",
      " - train_model_2_epochs=100,optimizer=nadam:\tPENDING\n",
      " - train_model_3_epochs=200,optimizer=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_epochs=100,optimizer=adam:\tRUNNING\n",
      "\n",
      "Result for train_model_0_epochs=100,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''linear'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''mse'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_10-33-07\n",
      "  done: false\n",
      "  experiment_id: 33b729d05df24758ba5fe85671148c37\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3218\n",
      "  time_since_restore: 1.001121997833252\n",
      "  time_this_iter_s: 1.001121997833252\n",
      "  time_total_s: 1.001121997833252\n",
      "  timestamp: 1551157387\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_1_epochs=200,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''linear'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''mse'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_10-33-07\n",
      "  done: false\n",
      "  experiment_id: 153eae477db94beb80f2c7b34fff5ea0\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3194\n",
      "  time_since_restore: 1.0011217594146729\n",
      "  time_this_iter_s: 1.0011217594146729\n",
      "  time_total_s: 1.0011217594146729\n",
      "  timestamp: 1551157387\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_0_epochs=100,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''linear'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''mse'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_10-33-08\n",
      "  done: true\n",
      "  experiment_id: 33b729d05df24758ba5fe85671148c37\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3218\n",
      "  time_since_restore: 2.0026519298553467\n",
      "  time_this_iter_s: 1.0015299320220947\n",
      "  time_total_s: 2.0026519298553467\n",
      "  timestamp: 1551157388\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_model_1_epochs=200,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''linear'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''mse'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_10-33-08\n",
      "  done: true\n",
      "  experiment_id: 153eae477db94beb80f2c7b34fff5ea0\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3194\n",
      "  time_since_restore: 2.002711534500122\n",
      "  time_this_iter_s: 1.0015897750854492\n",
      "  time_total_s: 2.002711534500122\n",
      "  timestamp: 1551157388\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_model_3_epochs=200,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''linear'', ''optimizer'':\n",
      "    ''nadam'', ''losses'': ''mse'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_10-33-11\n",
      "  done: false\n",
      "  experiment_id: 00831bcce9684e87ba4c7349b86725d0\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3190\n",
      "  time_since_restore: 1.0000834465026855\n",
      "  time_this_iter_s: 1.0000834465026855\n",
      "  time_total_s: 1.0000834465026855\n",
      "  timestamp: 1551157391\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 4.7/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_model_2_epochs=100,optimizer=nadam:\tRUNNING\n",
      " - train_model_3_epochs=200,optimizer=nadam:\tRUNNING [pid=3190], 1 s, 1 iter, 0 acc\n",
      "TERMINATED trials:\n",
      " - train_model_0_epochs=100,optimizer=adam:\tTERMINATED [pid=3218], 2 s, 2 iter, 0 acc\n",
      " - train_model_1_epochs=200,optimizer=adam:\tTERMINATED [pid=3194], 2 s, 2 iter, 0 acc\n",
      "\n",
      "Result for train_model_2_epochs=100,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''linear'', ''optimizer'':\n",
      "    ''nadam'', ''losses'': ''mse'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_10-33-11\n",
      "  done: false\n",
      "  experiment_id: ab8c1afc8f9d4832a7a4b704f44cf2f5\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3193\n",
      "  time_since_restore: 1.00111985206604\n",
      "  time_this_iter_s: 1.00111985206604\n",
      "  time_total_s: 1.00111985206604\n",
      "  timestamp: 1551157391\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_3_epochs=200,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''linear'', ''optimizer'':\n",
      "    ''nadam'', ''losses'': ''mse'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_10-33-12\n",
      "  done: true\n",
      "  experiment_id: 00831bcce9684e87ba4c7349b86725d0\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3190\n",
      "  time_since_restore: 2.0016064643859863\n",
      "  time_this_iter_s: 1.0015230178833008\n",
      "  time_total_s: 2.0016064643859863\n",
      "  timestamp: 1551157392\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_model_2_epochs=100,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''linear'', ''optimizer'':\n",
      "    ''nadam'', ''losses'': ''mse'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_10-33-12\n",
      "  done: true\n",
      "  experiment_id: ab8c1afc8f9d4832a7a4b704f44cf2f5\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.0\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3193\n",
      "  time_since_restore: 2.0026187896728516\n",
      "  time_this_iter_s: 1.0014989376068115\n",
      "  time_total_s: 2.0026187896728516\n",
      "  timestamp: 1551157392\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 4.7/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_model_0_epochs=100,optimizer=adam:\tTERMINATED [pid=3218], 2 s, 2 iter, 0 acc\n",
      " - train_model_1_epochs=200,optimizer=adam:\tTERMINATED [pid=3194], 2 s, 2 iter, 0 acc\n",
      " - train_model_2_epochs=100,optimizer=nadam:\tTERMINATED [pid=3193], 2 s, 2 iter, 0 acc\n",
      " - train_model_3_epochs=200,optimizer=nadam:\tTERMINATED [pid=3190], 2 s, 2 iter, 0 acc\n",
      "\n",
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_epochs=100,optimizer=adam_2019-02-26_10-33-05nxat66bh/weights_tune_{'units': 1, 'activation': 'linear', 'optimizer': 'adam', 'losses': 'mse', 'epochs': 100}.h5\n"
     ]
    }
   ],
   "source": [
    "## Testing with Tune ##\n",
    "\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ray import tune\n",
    "from hyperopt import hp\n",
    "from imly import dope\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "url = \"../data/diabetes.csv\"\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.60, random_state=0)\n",
    "glm_1 = {\n",
    "    \"epochs\": tune.grid_search([100, 200]),\n",
    "    \"optimizer\": tune.grid_search([\"adam\", \"nadam\"])\n",
    "}\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.uniform(\"lr\", 0.001, 0.1),\n",
    "    'activation': hp.choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "}\n",
    "\n",
    "m = dope(LinearRegression())\n",
    "m.fit(x_train, y_train, params=glm_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #2\n",
    "\n",
    "#### UCI Abalone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "794/794 [==============================] - ETA:  - 0s 77us/step\n",
      "Confusion matrix, without normalization\n",
      "Uploading ../data/uci_abalone_logistic_regression.pdf to Amazon S3 bucket mlsquare-datasets\n",
      "..."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT0AAAEYCAYAAAAu+iEYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHt1JREFUeJzt3Xu8XdO99/HPd+8dEeISIi6RoCQhUoI0NERR9zvnaKlbUbfi4dD2icvpQauPHi2taimlSluRVhURJZS6BsEWIu6XCnGJuwSR+D1/zLljJdlZe25rrb3W3PP79pqvvdaYc43xW9nJzxhzzDmmIgIzs6JoqncAZmZdyUnPzArFSc/MCsVJz8wKxUnPzArFSc/MCsVJr5uR1EvSDZLek/SXCurZX9It1YytXiSNlvRUveOwxiBfp1cfkr4FnAisC3wAtAJnRcTdFdZ7IHAcMCoi5lYcaIOTFMCgiHi23rFYPrinVweSTgR+AfwEWBkYCPwG2KMK1a8BPF2EhJeFpJZ6x2ANJiK8deEGLAd8COxT5pieJEnx1XT7BdAz3bcVMB04CXgDmAEcku47A5gDfJq2cRhwOvDHkrrXBAJoSd9/G3iepLf5ArB/SfndJZ8bBTwIvJf+HFWy7w7gR8A9aT23AH0X893a4v9BSfx7AjsDTwNvA6eUHD8SuA94Nz32AmCJdN+d6XeZlX7fb5bU/3+B14Ar28rSz6ydtrFx+n41YCawVb3/bnjrmq3uARRtA3YE5rYlncUccyYwCegHrATcC/wo3bdV+vkzgR5pspgN9En3L5zkFpv0gKWB94Eh6b5VgfXT1/OTHrAC8A5wYPq5/dL3K6b77wCeAwYDvdL3Zy/mu7XF/8M0/sOBN4E/A8sA6wMfA19Kj98E2Cxtd01gGnBCSX0BrNNO/T8l+Z9Hr9Kklx5zeFrPUsDNwM/q/ffCW9dtHt52vRWBmVF++Lk/cGZEvBERb5L04A4s2f9puv/TiJhA0ssZ8gXj+QwYJqlXRMyIiKntHLML8ExEXBkRcyPiKuBJYLeSY34fEU9HxEfAOGB4mTY/JTl/+SkwFugL/DIiPkjbnwpsABARD0XEpLTdF4HfAl/L8J3+JyI+SeNZQERcAjwD3E+S6E/toD7rRpz0ut5bQN8OzjWtBrxU8v6ltGx+HQslzdlA784GEhGzSIaERwEzJN0oad0M8bTF1L/k/WudiOetiJiXvm5LSq+X7P+o7fOSBksaL+k1Se+TnAftW6ZugDcj4uMOjrkEGAb8KiI+6eBY60ac9LrefSTDtz3LHPMqyYREm4Fp2Rcxi2QY12aV0p0RcXNEbEfS43mSJBl0FE9bTK98wZg640KSuAZFxLLAKYA6+EzZSxIk9SY5T3opcLqkFaoRqOWDk14Xi4j3SM5n/VrSnpKWktRD0k6S/jc97CrgNEkrSeqbHv/HL9hkK7ClpIGSlgNObtshaWVJu0taGviEZJg8r506JgCDJX1LUoukbwJDgfFfMKbOWIbkvOOHaS/06IX2vw58qZN1/hJ4KCK+A9wIXFRxlJYbTnp1EBHnklyjdxrJSfyXgWOBv6eH/BiYDEwBHgMeTsu+SFsTgavTuh5iwUTVRDIL/CrJjObXgO+2U8dbwK7psW+RzLzuGhEzv0hMnfQ94Fsks8KXkHyXUqcDf5D0rqRvdFSZpD1IJpOOSotOBDaWtH/VIraG5ouTzaxQ3NMzs0Jx0jOzQnHSM7NCcdIzs0JpqJux1dIrtMQy9Q7DOmHY4AH1DsE6YfrLL/H2WzM7us6xU5qXXSNi7iI3vrQrPnrz5ojYsZrtd1ZjJb0llqHnkA6vOrAGcuNtP693CNYJu2wzqup1xtyPMv+7/bj11x3dTVNzHt6aWYUEasq2dVSTtKSkByQ9KmmqpDPS8sslvSCpNd2Gp+WSdL6kZyVNkbRxR200VE/PzHJIQFNztWr7BNgmIj6U1AO4W9JN6b7vR8RfFzp+J2BQum1KctvipuUacE/PzConZds6EIkP07c90q3cHRR7AFekn5sELC9p1XJtOOmZWYU6NbztK2lyyXbEIrVJzZJaSRaZnRgR96e7zkqHsOdJ6pmW9Se5jbPNdBZc/WcRHt6aWeUy9OJSMyNiRLkD0mXHhktaHrhW0jCShTJeA5YALiZZGftM2l9xp+y9te7pmVllRNUmMkpFxLskq3DvmC5wG+nah78neYwAJD270uumVqeDZdic9MysQhnP52XoDabLqS2fvu4FbAs82XaeTpJI1qJ8PP3I9cBB6SzuZsB7ETGjXBse3ppZ5ao3e7sqyVJhzSSdsnERMV7SPyWtRNKvbOXzpcEmkDwn5lmSFbsP6agBJz0zq5A6PXRdnIiYAmzUTvk2izk+gGM604aTnplVRnRmIqPunPTMrHJV6ul1BSc9M6tQ9Ya3XcFJz8wq1+ThrZkVRXXvva05Jz0zq5CHt2ZWNJ69NbNCcU/PzAoj4y1mjcJJz8wq54kMMysOT2SYWdF4eGtmhdG2nl5OOOmZWYU8vDWzovHw1swKxbO3ZlYY8vDWzIrGw1szKxI56ZlZUSSrxTvpmVlRiPYfud2gnPTMrEKiqckTGWZWIB7emlmhOOmZWXH4nJ6ZFYmQe3pmViyeyDCzQnFPz8yKw+f0zKxo3NMzs8LwRIaZFY6TnpkVh0BNTnpmViDu6ZlZoTjpmVlheCLDzIonPzmP/Nw70qB6LtHCXVd+j/uvHsNDfz2V047aGYCLzziAaeNPZ9LYMUwaO4YNBvcHYPQmg3jtznPml598xI71DL+wvnfcEWw0ZADbbr7xIvt+e8F5DFxxSd5+ayYAt0y4ge1Hj2DHr41kl21G8cCke7o63MamZHibZeuwKmlJSQ9IelTSVElnpOVrSbpf0jOSrpa0RFreM33/bLp/zY7acE+vQp/MmcuOR5zPrI/m0NLSxD8vO5Fb7nkCgFN+8XeuvbV1kc/c88hz/MfxF3V1qFZin/0O5ODvHM1/ffewBcpffeVl7rrjNvqvPmB+2eZbbs12O+2KJKZNfYzvHro/t98/patDbmhVvPf2E2CbiPhQUg/gbkk3AScC50XEWEkXAYcBF6Y/34mIdSTtC/wU+GbZWKsVaZHN+mgOAD1ammlpaSYi6hyRdWTTUaNZvk+fRcrPOPUHnHL6TxbolSzdu/f897Nnz8rV+asuo4xbByLxYfq2R7oFsA3w17T8D8Ce6es90vek+7+uDn5BTnpV0NQkJo0dw79vO5t/TnqSBx9/CYDTj9mNB64+mf89aW+W6PF5p3rTDdbi/qvH8PcLjma9L61Sr7BtIbfcNJ5VVl2NocM2WGTfP8Zfx9abbsC3992Lc3712zpE19g6MbztK2lyyXZEO3U1S2oF3gAmAs8B70bE3PSQ6UD/9HV/4GWAdP97wIrlYq1p0pO0o6Sn0vH2mFq2VU+ffRZstu/ZrLPDaYwYtgZD116VH/7qejbc60dsccA59FluaU46ZFsAWp98mSE7/zebfvNsLhz7L8adt8jv3Orgo9mzueDcn3LSyT9sd/+Ou+7B7fdP4XdXjuNnPzmji6NrbFkTXpr0ZkbEiJLt4oXri4h5ETEcWB0YCazXTrNtw6n2enVlh1o1S3qSmoFfAzsBQ4H9JA2tVXuN4L0PP+LOyc+w/aihvDbzfQDmfDqXK66bxIj11wTgg1kfzx8O33z3E/RoaWbF5ZeuV8iWeunF53n53y+y45ZfYdTwwcx49RV23noz3nj9tQWO23TUaP794vPzJzksUa2JjFIR8S5wB7AZsLyktuHS6sCr6evpwIA0hhZgOeDtcvXWsqc3Eng2Ip6PiDnAWJLxd7fSt09vluvdC4Ale/Zgm02H8NSLr7NK32XnH7P71hvwxHPJ72jlFZeZXz5i/TVoknjr3VldG7QtYt2hw3jkqZe5t/Vp7m19mlVX68+E2yfRb+VVePH55+afp33s0UeYM+dT+qxQdgRVOFWcvV1J0vLp617AtsA04HbgP9PDDgauS19fn74n3f/P6OCkei1nb+ePtVPTgU0XPigd0ydjvB69axhObazSd1kuOfNAmpuaaGoS10x8mJvuepybfnscffssgwRTnprOcWeNBWCvbTfi8H1GM3fePD7++FMOOvn3df4GxXTs4Qdy3z138c5bMxk5bG1OHHMa+x5wSLvHTrjhWq65+k/06NGDJZfsxa8vvdKTGQup4r23qwJ/SEeKTcC4iBgv6QlgrKQfA48Al6bHXwpcKelZkh7evh3GWquZRkn7ADtExHfS9wcCIyPiuMV9pmmpftFzyDdqEo/VxtO3/bzeIVgn7LLNKKa0PlTVjN1zlUGx+v7nZzr2+XN3figiRlSz/c6qZU9v/lg7VToON7NuQkCeOr61PKf3IDAovZJ6CZJu5/U1bM/M6qJTs7d1V7OeXkTMlXQscDPQDFwWEVNr1Z6Z1U+D5LNManobWkRMACbUsg0zqzMlF+jnhe+9NbOKCCc9MysYD2/NrFAaZZIiCyc9M6uM3NMzswJJrtPLT9Zz0jOzCskTGWZWLO7pmVlx+JyemRWJz+mZWeHkKOc56ZlZ5dzTM7Pi8L23ZlYkeVtPz0nPzCrUOGvlZeGkZ2YVy1HOc9Izs8q5p2dmhSFPZJhZ0binZ2aFkqOc56RnZpVzT8/MisMLDphZkcjX6ZlZ0TR79tbMiiRHHT0nPTOrjNRNJjIkLVvugxHxfvXDMbM8ytHotmxPbyoQJIsotGl7H8DAGsZlZjnSLXp6ETGgKwMxs/zKUc6jKctBkvaVdEr6enVJm9Q2LDPLCwHNUqatEXSY9CRdAGwNHJgWzQYuqmVQZpYjSq7Ty7I1giyzt6MiYmNJjwBExNuSlqhxXGaWIw2SzzLJkvQ+ldREMnmBpBWBz2oalZnlhoCmHGW9LOf0fg1cA6wk6QzgbuCnNY3KzHJFyrY1gg6TXkRcAZwG/Ax4G9gnIsbWOjAzy4e2RUSzbB3XpQGSbpc0TdJUScen5adLekVSa7rtXPKZkyU9K+kpSTt01EbWOzKagU9JhriZZnzNrDiqOLydC5wUEQ9LWgZ4SNLEdN95EfGz0oMlDQX2BdYHVgNulTQ4IuYtNtaOIpB0KnBVWuHqwJ8lnfyFvo6ZdUvKuHUkImZExMPp6w+AaUD/Mh/ZAxgbEZ9ExAvAs8DIcm1k6bUdAHwlIk6LiFPTCg/K8DkzK4hOXLLSV9Lkku2IMnWuCWwE3J8WHStpiqTLJPVJy/oDL5d8bDrlk2SmpPcSCw6DW4DnM3zOzAogmb3NtgEzI2JEyXZxu3VKvUkmUE9I7/O/EFgbGA7MAH5e0vzColy85RYcOC/98GxgqqSb0/fbk8zgmpnNvzi5etWpB0nC+1NE/A0gIl4v2X8JMD59Ox0ovWV2deDVcvWXm8h4PP05FbixpHxSpsjNrDCq9QhIJdnzUmBaRJxbUr5qRMxI3+7F5/npepJ5hnNJ5h0GAQ+Ua6PcggOXVhC7mRVE2/C2SjYnueX1MUmtadkpwH6ShpOMNl8EjgSIiKmSxgFPkMz8HlNu5hYyXLIiaW3gLGAosGRbeUQM7uy3MbPuqVrD24i4m/bP000o85mzSHJUJlkmMi4Hfp8GshMwDvDFyWY2X7UuWekKWZLeUhFxM0BEPBcRp5GsumJmltyRIWXaGkGWOzI+SU8uPifpKOAVoF9twzKzPGmQfJZJlqT3X0Bv4P+QjJuXAw6tZVBmli/Vmr3tCh0mvYhouxr6Az5fSNTMDEge9t0oQ9csyl2cfC1lrmyOiL1rEpGZ5UsDLRuVRbme3gVdFkVqo/UGcs/9Xd6sVaD1xXfrHYJ1wqfzarP+b6MsBZ9FuYuTb+vKQMwsv/K03lzW9fTMzNoluklPz8wsq5YcdfUyJz1JPSPik1oGY2b5kzz/Ij89vSwrJ4+U9BjwTPp+Q0m/qnlkZpYbnVhPr+6ydErPB3YF3gKIiEfxbWhmViJPT0PLMrxtioiXFuq+ll26xcyKI2/Pvc2S9F6WNBIISc3AccDTtQ3LzPKkOT85L1PSO5pkiDsQeB24NS0zM0MNtIJKFlnuvX2D5LmSZmbtylHOy7Ry8iW0cw9uRCz20W1mViyNMjObRZbh7a0lr5ckeSjHy4s51swKpttNZETE1aXvJV0JTKxZRGaWOznKeV/oNrS1gDWqHYiZ5ZSgOUdZL8s5vXf4/JxeE/A2MKaWQZlZflT5EZA1Vzbppc/G2JDkuRgAn0XEYhcWNbNiylPSK3sbWprgro2IeenmhGdmi5CUaWsEWe69fUDSxjWPxMxyqW14m5cFB8o9I6MlIuYCWwCHS3oOmEXyHSMinAjNrFs9I+MBYGNgzy6KxcxySEBLo3TjMiiX9AQQEc91USxmllPdpae3kqQTF7czIs6tQTxmljuiifxkvXJJrxnoDTn6NmbW5ZIHA9U7iuzKJb0ZEXFml0ViZvnUQDOzWXR4Ts/MrBwBzTnKeuWS3te7LAozy7VuscpKRLzdlYGYWX7lKOf5Yd9mVhmR7dauRuGkZ2aVydnDvp30zKxi+Ul5+eqVmlkDEskiolm2DuuSBki6XdI0SVMlHZ+WryBpoqRn0p990nJJOl/Ss5KmZFkcxUnPzComZdsymAucFBHrAZsBx0gaSrJw8W0RMQi4jc8XMt4JGJRuRwAXdtSAk56ZVSjbWnpZzvtFxIyIeDh9/QEwDegP7AH8IT3sD3y+EMoewBWRmAQsL2nVcm046ZlZRdpmb7NsQF9Jk0u2xT5KVtKawEbA/cDKETEDksQI9EsP68+CT2ecnpYtlicyzKxinZi9nRkRIzLU1xu4BjghIt4vU397O8qu8O6enplVTBm3THVJPUgS3p8i4m9p8ettw9b05xtp+XRgQMnHVwdeLVe/k56ZVUSq6uytgEuBaQstX3c9cHD6+mDgupLyg9JZ3M2A99qGwYvj4a2ZVayKFydvDhwIPCapNS07BTgbGCfpMODfwD7pvgnAzsCzwGzgkI4acNIzs4pVK+VFxN1lqltkEZT0CY3HdKYNJz0zq1iO7kJz0jOzyiSXrOQn6znpmVnF3NMzswJR91hE1MwsCw9vzaxYsi8m0BCc9MysYk56ZlYoytHw1rehVcGR3zmUgav1Y5Phw+aXXfPXv7Dxhuuz1BJNPDR58vzyOXPmcMRhhzBi+JcZufGG3PmvO+oQsf14zLHsvOkg9t/5q/PLTjv+UA7abTQH7TaavbbagIN2Gw3AzdeNm19+0G6jGTV4BZ5+4rF6hd5wqrmIaFdw0quCAw/+NteN/8cCZeuvP4yx4/7GFqO3XKD8st9dAsDk1scY/4+JjPn+SXz22WddFqsldtl7P8677K8LlP34l5dxxQ13ccUNd7H1Drvzte13A2CHPb4xv/yHP7uIVfsPZPDQL9cj7IZVxUVEa85Jrwq2GL0lK6ywwgJl6663HoOHDFnk2CenPcHW2yR30/Tr14/lll9+gZ6gdY2NRm7Ossv1aXdfRHDbhGvZfrf/WGTfxPHXsF075UWnjP81Aie9LvblDTbkhhuuY+7cubz4wgs88vBDTJ/+cscftC7T+uC9rNC3HwPWXHuRfbfdeC3b7eqkV0pAk7JtjaBmExmSLgN2Bd6IiGEdHV8UBx9yKE8+OY3NNx3BwDXWYLOvjqKlxfNJjWTi+GvaTWxTWyfTs1cv1h48tA5RNbLG6cVlUct/bZcDFwBX1LCN3GlpaeGcn583//1Wo0exzjqD6hiRlZo7dy533DKey6+9fZF9E2/8m3t57Wmg83VZ1Gx4GxF3Am/Xqv68mj17NrNmzQLgtlsn0tLSwnpD3XNoFA/eewdrfGkQ/VZd8DELn332Gf+86Tq228VJb2F5m72t+7gqfTDIEQADBg6sczRfzEEH7Mdd/7qDmTNnsvaaq/PfPzyDPiuswIknHMfMN99k7z12YYMNh3PDhJt584032G2XHWhqamK11fpz6eVX1jv8QvrhCYfx8AP38O47b7H7FuvznePHsPs+B3Lr+PZ7c60P3ku/VVaj/8A1uz7YHGiMdJaNkjX4alR58jSj8VnP6W2yyYi4537PZOZJ64vv1jsE64RD9tqaaY89UtUctd6XN4rf/33R0wHt+eo6fR7K8mCgWqp7T8/M8s8TGWZWKA1yui6Tmk1kSLoKuA8YIml6+kAPM+uGqvkIyFqrWU8vIvarVd1m1jhEVZ+GVnMe3ppZZXJ2nZ6TnplVLEc5z0nPzKogR1nPSc/MKuR7b82sQNpWWckLJz0zq5yTnpkViYe3ZlYovmTFzAolRznPSc/MKtRI95hl4KRnZhVJZm/zk/Wc9MysYvlJeU56ZlYNOcp6TnpmVjFfsmJmhZKjU3pOemZWuRzlvNqtnGxmxdC2iGiWrcO6pMskvSHp8ZKy0yW9Iqk13XYu2XeypGclPSVphyzxOumZWWXSRUSzbBlcDuzYTvl5ETE83SYASBoK7Ausn37mN5KaO2rASc/MKlatZ2RExJ3A2xmb3QMYGxGfRMQLwLPAyI4+5KRnZpWr/ZOBjpU0JR3+9knL+gMvlxwzPS0ry0nPzCqkzP8BfSVNLtmOyNDAhcDawHBgBvDz+Q0vKjqqzLO3ZlaRTi4iOjMiRnSm/oh4fX5b0iXA+PTtdGBAyaGrA692VJ97emZWuRoObyWtWvJ2L6BtZvd6YF9JPSWtBQwCHuioPvf0zKxi1bojQ9JVwFYkw+DpwP8AW0kaTjJ0fRE4EiAipkoaBzwBzAWOiYh5HbXhpGdmFavWHRkRsV87xZeWOf4s4KzOtOGkZ2YVy9MdGU56ZlaZ7BceNwQnPTOrSNttaHnhpGdmFctPynPSM7MqyFFHz0nPzCrnRUTNrFjyk/Oc9MyscjnKeU56ZlYZyY+ANLOiyU/Oc9Izs8rlKOc56ZlZ5XI0unXSM7NKyZesmFlxJLeh1TuK7Jz0zKxiTnpmVige3ppZcXhpKTMrksqf7ti1nPTMrHI5ynpOemZWMd+GZmaFkp+U56RnZtWQo6znpGdmFcvTJSuKiHrHMJ+kN4GX6h1HDfQFZtY7COuU7vo7WyMiVqpmhZL+QfLnlcXMiNixmu13VkMlve5K0uSIGFHvOCw7/866r6Z6B2Bm1pWc9MysUJz0usbF9Q7AOs2/s27K5/TMrFDc0zOzQnHSM7NCcdIzs0Jx0qsRSUMkfVVSD0nN9Y7HsvHvqvvzREYNSNob+AnwSrpNBi6PiPfrGpgtlqTBEfF0+ro5IubVOyarDff0qkxSD+CbwGER8XXgOmAA8ANJy9Y1OGuXpF2BVkl/BoiIee7xdV9OerWxLDAofX0tMB5YAviWlKOFxwpA0tLAscAJwBxJfwQnvu7MSa/KIuJT4Fxgb0mjI+Iz4G6gFdiirsHZIiJiFnAo8Gfge8CSpYmvnrFZbTjp1cZdwC3AgZK2jIh5EfFnYDVgw/qGZguLiFcj4sOImAkcCfRqS3ySNpa0bn0jtGryeno1EBEfS/oTEMDJ6T+aT4CVgRl1Dc7Kioi3JB0JnCPpSaAZ2LrOYVkVOenVSES8I+kS4AmS3sPHwAER8Xp9I7OORMRMSVOAnYDtImJ6vWOy6vElK10gPSEe6fk9a3CS+gDjgJMiYkq947HqctIza4ekJSPi43rHYdXnpGdmheLZWzMrFCc9MysUJz0zKxQnPTMrFCe9HJE0T1KrpMcl/UXSUhXUtZWk8enr3SWNKXPs8pK++wXaOF3S97KWL3TM5ZL+sxNtrSnp8c7GaMXjpJcvH0XE8IgYBswBjirdqUSnf6cRcX1EnF3mkOWBTic9s0bkpJdfdwHrpD2caZJ+AzwMDJC0vaT7JD2c9gh7A0jaUdKTku4G9m6rSNK3JV2Qvl5Z0rWSHk23UcDZwNppL/Oc9LjvS3pQ0hRJZ5TUdaqkpyTdCgzp6EtIOjyt51FJ1yzUe91W0l2Snk6Xf0JSs6RzSto+stI/SCsWJ70cktRCcovUY2nREOCKiNgImAWcBmwbERuTLGB6oqQlgUuA3YDRwCqLqf584F8RsSGwMTAVGAM8l/Yyvy9pe5Kls0YCw4FNJG0paRNgX2AjkqT6lQxf528R8ZW0vWnAYSX71gS+BuwCXJR+h8OA9yLiK2n9h0taK0M7ZoDvvc2bXpJa09d3AZeSrNzyUkRMSss3A4YC96RL9y0B3AesC7wQEc8ApKuIHNFOG9sAB8H8pZXeS2/LKrV9uj2Svu9NkgSXAa6NiNlpG9dn+E7DJP2YZAjdG7i5ZN+49Na9ZyQ9n36H7YENSs73LZe2/XSGtsyc9HLmo4gYXlqQJrZZpUXAxIjYb6HjhpOs+lINAv5fRPx2oTZO+AJtXA7sGRGPSvo2sFXJvoXrirTt4yKiNDkiac1OtmsF5eFt9zMJ2FzSOgCSlpI0GHgSWEvS2ulx+y3m87cBR6efbU6XuP+ApBfX5mbg0JJzhf0l9QPuBPaS1EvSMiRD6Y4sA8xIl9nff6F9+0hqSmP+EvBU2vbR6fFIGpyufmyWiXt63UxEvJn2mK6S1DMtPi0inpZ0BHCjpJkkqzkPa6eK44GLJR0GzAOOjoj7JN2TXhJyU3pebz3gvrSn+SHJslkPS7qaZJXol0iG4B35b+D+9PjHWDC5PgX8i2QdwqPSdQp/R3Ku72Eljb8J7JntT8fMCw6YWcF4eGtmheKkZ2aF4qRnZoXipGdmheKkZ2aF4qRnZoXipGdmhfL/ATRgvvCMJOC/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "dataset_info = automation_script.get_dataset_info(\"uci_abalone\")\n",
    "\n",
    "names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\",\n",
    "        \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "url = \"../data/abalone.data.csv\" if path.exists(\"../data/abalone.data.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names, index_col=False)\n",
    "data.head()\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "col_names = data.columns\n",
    "\n",
    "num_data = data.shape[0]\n",
    "\n",
    "categorical_col = ['sex']\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "    \n",
    "# Filter dataset to contain 'rings' 9 and 10 #\n",
    "data = data[data['rings'].isin([9,10])]\n",
    "data['rings'] = data['rings'].map({9: 0, 10: 1})\n",
    "\n",
    "\n",
    "feature_list = names[:7]\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['rings']]\n",
    "\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "2019-02-26 10:36:34,487\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-02-26 10:36:34,487\tINFO tune.py:145 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 4.4/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 4.4/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_model_1_epochs=200,optimizer=adam:\tPENDING\n",
      " - train_model_2_epochs=100,optimizer=nadam:\tPENDING\n",
      " - train_model_3_epochs=200,optimizer=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_epochs=100,optimizer=adam:\tRUNNING\n",
      "\n",
      "Result for train_model_0_epochs=100,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_10-36-36\n",
      "  done: false\n",
      "  experiment_id: 2f33c4ae29914a75be6aca1bbc061721\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.5103969754534994\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3195\n",
      "  time_since_restore: 1.0003676414489746\n",
      "  time_this_iter_s: 1.0003676414489746\n",
      "  time_total_s: 1.0003676414489746\n",
      "  timestamp: 1551157596\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_1_epochs=200,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_10-36-36\n",
      "  done: false\n",
      "  experiment_id: ce5fa672f8d541b9af1d59de6de3f570\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.5822306242128852\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3214\n",
      "  time_since_restore: 1.0010576248168945\n",
      "  time_this_iter_s: 1.0010576248168945\n",
      "  time_total_s: 1.0010576248168945\n",
      "  timestamp: 1551157596\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_0_epochs=100,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_10-36-37\n",
      "  done: true\n",
      "  experiment_id: 2f33c4ae29914a75be6aca1bbc061721\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.5103969754534994\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3195\n",
      "  time_since_restore: 2.00187349319458\n",
      "  time_this_iter_s: 1.0015058517456055\n",
      "  time_total_s: 2.00187349319458\n",
      "  timestamp: 1551157597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_model_1_epochs=200,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_10-36-37\n",
      "  done: true\n",
      "  experiment_id: ce5fa672f8d541b9af1d59de6de3f570\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.5822306242128852\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3214\n",
      "  time_since_restore: 2.002570629119873\n",
      "  time_this_iter_s: 1.0015130043029785\n",
      "  time_total_s: 2.002570629119873\n",
      "  timestamp: 1551157597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_model_2_epochs=100,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''nadam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_10-36-39\n",
      "  done: false\n",
      "  experiment_id: b398bb8b96db4d3bbe46bea961f0c515\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.62570888547681\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3192\n",
      "  time_since_restore: 1.0011212825775146\n",
      "  time_this_iter_s: 1.0011212825775146\n",
      "  time_total_s: 1.0011212825775146\n",
      "  timestamp: 1551157599\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 4.5/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_model_2_epochs=100,optimizer=nadam:\tRUNNING [pid=3192], 1 s, 1 iter, 0.626 acc\n",
      " - train_model_3_epochs=200,optimizer=nadam:\tRUNNING\n",
      "TERMINATED trials:\n",
      " - train_model_0_epochs=100,optimizer=adam:\tTERMINATED [pid=3195], 2 s, 2 iter, 0.51 acc\n",
      " - train_model_1_epochs=200,optimizer=adam:\tTERMINATED [pid=3214], 2 s, 2 iter, 0.582 acc\n",
      "\n",
      "Result for train_model_3_epochs=200,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''nadam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_10-36-39\n",
      "  done: false\n",
      "  experiment_id: ba1f0b97d391484f92cf2f0fef975a86\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.6049149342881258\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3191\n",
      "  time_since_restore: 1.0011262893676758\n",
      "  time_this_iter_s: 1.0011262893676758\n",
      "  time_total_s: 1.0011262893676758\n",
      "  timestamp: 1551157599\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_2_epochs=100,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''nadam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_10-36-40\n",
      "  done: true\n",
      "  experiment_id: b398bb8b96db4d3bbe46bea961f0c515\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.62570888547681\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3192\n",
      "  time_since_restore: 2.0026702880859375\n",
      "  time_this_iter_s: 1.0015490055084229\n",
      "  time_total_s: 2.0026702880859375\n",
      "  timestamp: 1551157600\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_model_3_epochs=200,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''nadam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_10-36-40\n",
      "  done: true\n",
      "  experiment_id: ba1f0b97d391484f92cf2f0fef975a86\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.6049149342881258\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 3191\n",
      "  time_since_restore: 2.0023508071899414\n",
      "  time_this_iter_s: 1.0012245178222656\n",
      "  time_total_s: 2.0023508071899414\n",
      "  timestamp: 1551157600\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 4.5/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_model_0_epochs=100,optimizer=adam:\tTERMINATED [pid=3195], 2 s, 2 iter, 0.51 acc\n",
      " - train_model_1_epochs=200,optimizer=adam:\tTERMINATED [pid=3214], 2 s, 2 iter, 0.582 acc\n",
      " - train_model_2_epochs=100,optimizer=nadam:\tTERMINATED [pid=3192], 2 s, 2 iter, 0.626 acc\n",
      " - train_model_3_epochs=200,optimizer=nadam:\tTERMINATED [pid=3191], 2 s, 2 iter, 0.605 acc\n",
      "\n",
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_2_epochs=100,optimizer=nadam_2019-02-26_10-36-3761kmoh9x/weights_tune_{'units': 1, 'activation': 'sigmoid', 'optimizer': 'nadam', 'losses': 'binary_crossentropy', 'epochs': 100}.h5\n"
     ]
    }
   ],
   "source": [
    "## Testing with Tune integration ##\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\",\n",
    "        \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "url = \"../data/abalone.data.csv\"\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names, index_col=False)\n",
    "data.head()\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "col_names = data.columns\n",
    "\n",
    "num_data = data.shape[0]\n",
    "\n",
    "categorical_col = ['sex']\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "    \n",
    "# Filter dataset to contain 'rings' 9 and 10 #\n",
    "data = data[data['rings'].isin([9,10])]\n",
    "data['rings'] = data['rings'].map({9: 0, 10: 1})\n",
    "\n",
    "\n",
    "feature_list = names[:7]\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['rings']]\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.60, random_state=0)\n",
    "glm_1 = {\n",
    "    \"epochs\": tune.grid_search([100, 200]),\n",
    "    \"optimizer\": tune.grid_search([\"adam\", \"nadam\"])\n",
    "}\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.uniform(\"lr\", 0.001, 0.1),\n",
    "    'activation': hp.choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "}\n",
    "\n",
    "m = dope(LogisticRegression())\n",
    "m.fit(x_train, y_train, params=glm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794/794 [==============================] - 0s 75us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5856423176055591"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #3\n",
    "\n",
    "#### UCI Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2019-02-26 11:04:30,592\tINFO node.py:278 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-02-26_11-04-30_5522/logs.\n",
      "2019-02-26 11:04:30,702\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:44334 to respond...\n",
      "2019-02-26 11:04:30,835\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:26924 to respond...\n",
      "2019-02-26 11:04:30,843\tINFO services.py:798 -- Starting Redis shard with 10.0 GB max memory.\n",
      "2019-02-26 11:04:30,893\tINFO services.py:1360 -- Starting the Plasma object store with 3.2851689470000003 GB memory using /dev/shm.\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2019-02-26 11:04:31,112\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-02-26 11:04:31,113\tINFO tune.py:145 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=e5f9773e40e84867d5c373497dbea75ba8fcce391008fa73\n",
      "======================================================================\n",
      "\n",
      "Keras classifier chosen\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 4.8/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 4.9/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING\n",
      "\n",
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 170}.h5'\n",
      "  date: 2019-02-26_11-04-33\n",
      "  done: false\n",
      "  experiment_id: 76652b25c3ab4bef84546694d9959d76\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.55\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 5566\n",
      "  time_since_restore: 1.0002424716949463\n",
      "  time_this_iter_s: 1.0002424716949463\n",
      "  time_total_s: 1.0002424716949463\n",
      "  timestamp: 1551159273\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 170}.h5'\n",
      "  date: 2019-02-26_11-04-34\n",
      "  done: true\n",
      "  experiment_id: 76652b25c3ab4bef84546694d9959d76\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.55\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 5566\n",
      "  time_since_restore: 2.001762628555298\n",
      "  time_this_iter_s: 1.0015201568603516\n",
      "  time_total_s: 2.001762628555298\n",
      "  timestamp: 1551159274\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.3/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_model_0:\tTERMINATED [pid=5566], 2 s, 2 iter, 0.55 acc\n",
      "\n",
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_2019-02-26_11-04-31aspjuqh1/weights_tune_{'units': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'losses': 'binary_crossentropy', 'epochs': 170}.h5\n",
      "60/60 [==============================] - 0s 252us/step\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"uci_iris\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "url = \"../data/iris.csv\" if path.exists(\"../data/iris.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "params = {\n",
    "    'epochs': 170\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 22]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "a, b = np.unique(y_train, return_counts=True)\n",
    "# len(y_test)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 5.509 - 0s 12ms/step - loss: 5.1482\n",
      "Epoch 2/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.240 - 0s 0us/step - loss: 5.1335\n",
      "Epoch 3/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.517 - 0s 391us/step - loss: 5.1188\n",
      "Epoch 4/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 5.011 - 0s 390us/step - loss: 5.1038\n",
      "Epoch 5/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.508 - 0s 391us/step - loss: 5.0873\n",
      "Epoch 6/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 5.215 - 0s 0us/step - loss: 5.0720\n",
      "Epoch 7/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 5.087 - 0s 390us/step - loss: 5.0557\n",
      "Epoch 8/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.836 - 0s 390us/step - loss: 5.0393\n",
      "Epoch 9/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 5.396 - 0s 391us/step - loss: 5.0238\n",
      "Epoch 10/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 5.395 - 0s 391us/step - loss: 5.0078\n",
      "Epoch 11/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 5.055 - 0s 391us/step - loss: 4.9915\n",
      "Epoch 12/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.953 - 0s 0us/step - loss: 4.9744\n",
      "Epoch 13/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 5.635 - 0s 391us/step - loss: 4.9605\n",
      "Epoch 14/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.623 - 0s 390us/step - loss: 4.9432\n",
      "Epoch 15/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.790 - 0s 391us/step - loss: 4.9275\n",
      "Epoch 16/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.494 - 0s 391us/step - loss: 4.9111\n",
      "Epoch 17/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.714 - 0s 390us/step - loss: 4.8952\n",
      "Epoch 18/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.580 - 0s 0us/step - loss: 4.8786\n",
      "Epoch 19/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.689 - 0s 391us/step - loss: 4.8623\n",
      "Epoch 20/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.878 - 0s 391us/step - loss: 4.8461\n",
      "Epoch 21/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.709 - 0s 0us/step - loss: 4.8294\n",
      "Epoch 22/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.673 - 0s 391us/step - loss: 4.8130\n",
      "Epoch 23/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.621 - 0s 390us/step - loss: 4.7966\n",
      "Epoch 24/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.869 - 0s 391us/step - loss: 4.7806\n",
      "Epoch 25/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.858 - 0s 0us/step - loss: 4.7642\n",
      "Epoch 26/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.628 - 0s 391us/step - loss: 4.7477\n",
      "Epoch 27/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.529 - 0s 391us/step - loss: 4.7315\n",
      "Epoch 28/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.308 - 0s 390us/step - loss: 4.7150\n",
      "Epoch 29/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.863 - 0s 0us/step - loss: 4.6993\n",
      "Epoch 30/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.463 - 0s 391us/step - loss: 4.6824\n",
      "Epoch 31/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.488 - 0s 391us/step - loss: 4.6661\n",
      "Epoch 32/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.270 - 0s 390us/step - loss: 4.6494\n",
      "Epoch 33/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.786 - 0s 391us/step - loss: 4.6336\n",
      "Epoch 34/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.702 - 0s 390us/step - loss: 4.6170\n",
      "Epoch 35/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.659 - 0s 781us/step - loss: 4.6007\n",
      "Epoch 36/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.110 - 0s 390us/step - loss: 4.5838\n",
      "Epoch 37/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.053 - 0s 0us/step - loss: 4.5675\n",
      "Epoch 38/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.404 - 0s 0us/step - loss: 4.5514\n",
      "Epoch 39/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.908 - 0s 391us/step - loss: 4.5354\n",
      "Epoch 40/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.359 - 0s 391us/step - loss: 4.5182\n",
      "Epoch 41/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.530 - 0s 391us/step - loss: 4.5022\n",
      "Epoch 42/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.781 - 0s 391us/step - loss: 4.4864\n",
      "Epoch 43/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 5.048 - 0s 390us/step - loss: 4.4707\n",
      "Epoch 44/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.526 - 0s 390us/step - loss: 4.4544\n",
      "Epoch 45/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.533 - 0s 0us/step - loss: 4.4391\n",
      "Epoch 46/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.277 - 0s 390us/step - loss: 4.4234\n",
      "Epoch 47/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.263 - 0s 391us/step - loss: 4.4079\n",
      "Epoch 48/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.745 - 0s 0us/step - loss: 4.3915\n",
      "Epoch 49/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.943 - 0s 390us/step - loss: 4.3771\n",
      "Epoch 50/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.038 - 0s 0us/step - loss: 4.3597\n",
      "Epoch 51/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.719 - 0s 391us/step - loss: 4.3433\n",
      "Epoch 52/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.439 - 0s 781us/step - loss: 4.3280\n",
      "Epoch 53/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.210 - 0s 391us/step - loss: 4.3111\n",
      "Epoch 54/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.314 - 0s 391us/step - loss: 4.2949\n",
      "Epoch 55/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.834 - 0s 391us/step - loss: 4.2779\n",
      "Epoch 56/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.171 - 0s 523us/step - loss: 4.2619\n",
      "Epoch 57/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.022 - 0s 0us/step - loss: 4.2452\n",
      "Epoch 58/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 5.090 - 0s 391us/step - loss: 4.2303\n",
      "Epoch 59/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.372 - 0s 390us/step - loss: 4.2130\n",
      "Epoch 60/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.004 - 0s 391us/step - loss: 4.1970\n",
      "Epoch 61/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.203 - 0s 392us/step - loss: 4.1817\n",
      "Epoch 62/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.513 - 0s 390us/step - loss: 4.1664\n",
      "Epoch 63/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.094 - 0s 390us/step - loss: 4.1501\n",
      "Epoch 64/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.275 - 0s 391us/step - loss: 4.1349\n",
      "Epoch 65/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.851 - 0s 0us/step - loss: 4.1188\n",
      "Epoch 66/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.861 - 0s 781us/step - loss: 4.1047\n",
      "Epoch 67/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.231 - 0s 391us/step - loss: 4.0882\n",
      "Epoch 68/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.723 - 0s 391us/step - loss: 4.0724\n",
      "Epoch 69/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.415 - 0s 0us/step - loss: 4.0566\n",
      "Epoch 70/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.104 - 0s 0us/step - loss: 4.0417\n",
      "Epoch 71/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.804 - 0s 391us/step - loss: 4.0250\n",
      "Epoch 72/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.847 - 0s 391us/step - loss: 4.0088\n",
      "Epoch 73/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.039 - 0s 390us/step - loss: 3.9928\n",
      "Epoch 74/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.277 - 0s 390us/step - loss: 3.9769\n",
      "Epoch 75/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.317 - 0s 0us/step - loss: 3.9608\n",
      "Epoch 76/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.784 - 0s 390us/step - loss: 3.9443\n",
      "Epoch 77/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.753 - 0s 390us/step - loss: 3.9287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.743 - 0s 391us/step - loss: 3.9128\n",
      "Epoch 79/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.752 - 0s 390us/step - loss: 3.8968\n",
      "Epoch 80/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.988 - 0s 391us/step - loss: 3.8810\n",
      "Epoch 81/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.013 - 0s 391us/step - loss: 3.8649\n",
      "Epoch 82/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.802 - 0s 390us/step - loss: 3.8486\n",
      "Epoch 83/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.492 - 0s 390us/step - loss: 3.8322\n",
      "Epoch 84/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.399 - 0s 391us/step - loss: 3.8160\n",
      "Epoch 85/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.101 - 0s 391us/step - loss: 3.8007\n",
      "Epoch 86/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.168 - 0s 391us/step - loss: 3.7843\n",
      "Epoch 87/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.587 - 0s 391us/step - loss: 3.7674\n",
      "Epoch 88/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.915 - 0s 0us/step - loss: 3.7522\n",
      "Epoch 89/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.781 - 0s 0us/step - loss: 3.7361\n",
      "Epoch 90/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.762 - 0s 0us/step - loss: 3.7204\n",
      "Epoch 91/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.485 - 0s 0us/step - loss: 3.7043\n",
      "Epoch 92/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.315 - 0s 391us/step - loss: 3.6881\n",
      "Epoch 93/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.937 - 0s 390us/step - loss: 3.6731\n",
      "Epoch 94/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.400 - 0s 0us/step - loss: 3.6560\n",
      "Epoch 95/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.745 - 0s 0us/step - loss: 3.6405\n",
      "Epoch 96/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.762 - 0s 390us/step - loss: 3.6244\n",
      "Epoch 97/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.713 - 0s 390us/step - loss: 3.6084\n",
      "Epoch 98/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.460 - 0s 391us/step - loss: 3.5922\n",
      "Epoch 99/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.474 - 0s 391us/step - loss: 3.5764\n",
      "Epoch 100/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.676 - 0s 391us/step - loss: 3.5608\n",
      "Epoch 101/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.412 - 0s 391us/step - loss: 3.5444\n",
      "Epoch 102/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.191 - 0s 391us/step - loss: 3.5281\n",
      "Epoch 103/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.802 - 0s 391us/step - loss: 3.5130\n",
      "Epoch 104/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.355 - 0s 0us/step - loss: 3.4960\n",
      "Epoch 105/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.545 - 0s 0us/step - loss: 3.4804\n",
      "Epoch 106/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.301 - 0s 0us/step - loss: 3.4639\n",
      "Epoch 107/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.530 - 0s 390us/step - loss: 3.4483\n",
      "Epoch 108/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.769 - 0s 391us/step - loss: 3.4327\n",
      "Epoch 109/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.130 - 0s 391us/step - loss: 3.4158\n",
      "Epoch 110/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.464 - 0s 391us/step - loss: 3.4007\n",
      "Epoch 111/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.222 - 0s 0us/step - loss: 3.3844\n",
      "Epoch 112/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.709 - 0s 0us/step - loss: 3.3694\n",
      "Epoch 113/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.640 - 0s 391us/step - loss: 3.3534\n",
      "Epoch 114/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.449 - 0s 391us/step - loss: 3.3377\n",
      "Epoch 115/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.202 - 0s 390us/step - loss: 3.3220\n",
      "Epoch 116/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.037 - 0s 0us/step - loss: 3.3064\n",
      "Epoch 117/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.792 - 0s 0us/step - loss: 3.2902\n",
      "Epoch 118/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.338 - 0s 0us/step - loss: 3.2751\n",
      "Epoch 119/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.517 - 0s 391us/step - loss: 3.2591\n",
      "Epoch 120/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.152 - 0s 391us/step - loss: 3.2422\n",
      "Epoch 121/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.443 - 0s 0us/step - loss: 3.2270\n",
      "Epoch 122/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.158 - 0s 0us/step - loss: 3.2106\n",
      "Epoch 123/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.128 - 0s 391us/step - loss: 3.1949\n",
      "Epoch 124/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.026 - 0s 391us/step - loss: 3.1790\n",
      "Epoch 125/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.434 - 0s 0us/step - loss: 3.1639\n",
      "Epoch 126/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.406 - 0s 0us/step - loss: 3.1480\n",
      "Epoch 127/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.360 - 0s 391us/step - loss: 3.1325\n",
      "Epoch 128/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.351 - 0s 0us/step - loss: 3.1174\n",
      "Epoch 129/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.308 - 0s 0us/step - loss: 3.1024\n",
      "Epoch 130/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.160 - 0s 391us/step - loss: 3.0874\n",
      "Epoch 131/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.276 - 0s 391us/step - loss: 3.0729\n",
      "Epoch 132/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.797 - 0s 0us/step - loss: 3.0573\n",
      "Epoch 133/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.941 - 0s 0us/step - loss: 3.0426\n",
      "Epoch 134/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.097 - 0s 391us/step - loss: 3.0276\n",
      "Epoch 135/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.317 - 0s 391us/step - loss: 3.0126\n",
      "Epoch 136/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.871 - 0s 0us/step - loss: 2.9965\n",
      "Epoch 137/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.615 - 0s 0us/step - loss: 2.9808\n",
      "Epoch 138/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.624 - 0s 391us/step - loss: 2.9652\n",
      "Epoch 139/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.206 - 0s 391us/step - loss: 2.9504\n",
      "Epoch 140/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.321 - 0s 0us/step - loss: 2.9345\n",
      "Epoch 141/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.950 - 0s 0us/step - loss: 2.9182\n",
      "Epoch 142/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.817 - 0s 0us/step - loss: 2.9027\n",
      "Epoch 143/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.303 - 0s 0us/step - loss: 2.8864\n",
      "Epoch 144/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.756 - 0s 0us/step - loss: 2.8715\n",
      "Epoch 145/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.132 - 0s 391us/step - loss: 2.8561\n",
      "Epoch 146/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.777 - 0s 390us/step - loss: 2.8392\n",
      "Epoch 147/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.689 - 0s 391us/step - loss: 2.8233\n",
      "Epoch 148/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 3.030 - 0s 0us/step - loss: 2.8082\n",
      "Epoch 149/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.840 - 0s 391us/step - loss: 2.7921\n",
      "Epoch 150/150\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.820 - 0s 391us/step - loss: 2.7766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imly import dope\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1,\n",
    "                input_dim=4,\n",
    "                activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy')\n",
    "\n",
    "# m = dope(LogisticRegression())\n",
    "# m.fit(x_train.values, y_train.values)\n",
    "# m.predict(x_test)\n",
    "model.fit(x_train.values, y_train.values, epochs=150)\n",
    "test = model.predict(x_test)\n",
    "test.argmax(axis=-1)\n",
    "# value, count = np.unique(test, return_counts=True)\n",
    "# count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../data/uci_iris_logistic_regression.pdf to Amazon S3 bucket mlsquare-datasets\n",
      "..."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://mlsquare-pdf.s3.ap-south-1.amazonaws.com:443/uci_iris_logistic_regression.pdf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto\n",
    "import sys\n",
    "from boto.s3.key import Key\n",
    "# from boto.s3.key import Key\n",
    "fig_path = '../data/uci_iris_logistic_regression.pdf'\n",
    "fig_name = 'uci_iris_logistic_regression.pdf'\n",
    "bucket_name = 'mlsquare-datasets'\n",
    "credentials_json = json.load(open('../data/aws_credentials.json'))\n",
    "AWS_ACCESS_KEY_ID = credentials_json['AWS_ACCESS_KEY_ID']\n",
    "AWS_SECRET_ACCESS_KEY = credentials_json['AWS_SECRET_ACCESS_KEY']\n",
    "REGION_HOST = 's3.ap-south-1.amazonaws.com'\n",
    "\n",
    "# bucket_name = AWS_ACCESS_KEY_ID.lower() + '-dump'\n",
    "conn = boto.connect_s3(AWS_ACCESS_KEY_ID,\n",
    "                       AWS_SECRET_ACCESS_KEY, host=REGION_HOST)\n",
    "bucket = conn.get_bucket('mlsquare-pdf', validate=False)\n",
    "\n",
    "# bucket = conn.create_bucket(bucket_name,\n",
    "#     location=boto.s3.connection.Location.DEFAULT)\n",
    "\n",
    "print('Uploading %s to Amazon S3 bucket %s' % (fig_path, bucket_name))\n",
    "\n",
    "def percent_cb(complete, total):\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "k = Key(bucket)\n",
    "k.key = fig_name\n",
    "k.set_contents_from_filename(fig_path,\n",
    "                             cb=percent_cb, num_cb=10)  # upload file\n",
    "url = k.generate_url(expires_in=0, query_auth=False)\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #4\n",
    "\n",
    "#### UCI Adult salary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n",
      "Epoch 1/1\n",
      "13024/13024 [==============================] - 0s 23us/step - loss: 14.3505 - acc: 0.0999\n",
      "19537/19537 [==============================] - 0s 8us/step\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from hyperopt import hp\n",
    "\n",
    "dataset_name = \"uci_adult_salary\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "\n",
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "         'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "         'hours-per-week', 'native-country', 'target']\n",
    "url = \"../data/adult.data.csv\" if path.exists(\"../data/adult.data.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names)\n",
    "\n",
    "\n",
    "data = data[data[\"workclass\"] != \"?\"]\n",
    "data = data[data[\"occupation\"] != \"?\"]\n",
    "data = data[data[\"native-country\"] != \"?\"]\n",
    "\n",
    "# Convert categorical fields #\n",
    "categorical_col = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                   'relationship', 'race', 'sex', 'native-country', 'target']\n",
    "\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "feature_list = names[:14]\n",
    "# Test train split #\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['target']]\n",
    "\n",
    "space = {\n",
    "    'epochs': hp.choice(\"epochs\",[100,200])\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60)\n",
    "\n",
    "# Split the dataset into test and train datasets\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #5\n",
    "\n",
    "#### UCI Ad dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2019-02-26 15:43:57,993\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-02-26 15:43:57,994\tINFO tune.py:145 -- Starting a new experiment.\n",
      "2019-02-26 15:43:58,053\tERROR worker.py:1632 -- Warning: The actor WrappedFunc has size 11765523 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n",
      "2019-02-26 15:43:58,100\tERROR worker.py:1632 -- Warning: The actor WrappedFunc has size 11765523 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.4/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.4/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_model_1_epochs=200:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_epochs=100:\tRUNNING\n",
      "\n",
      "Result for train_model_0_epochs=100:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_15-44-00\n",
      "  done: false\n",
      "  experiment_id: 0171d16c8e3a4d77b7b57534af433ead\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.8123011666795482\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 11985\n",
      "  time_since_restore: 1.0011260509490967\n",
      "  time_this_iter_s: 1.0011260509490967\n",
      "  time_total_s: 1.0011260509490967\n",
      "  timestamp: 1551176040\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_1_epochs=200:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_15-44-00\n",
      "  done: false\n",
      "  experiment_id: bf2b1a16fd6244e0bd53ee3f2c5781b7\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.8165429482277985\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 11987\n",
      "  time_since_restore: 1.0011229515075684\n",
      "  time_this_iter_s: 1.0011229515075684\n",
      "  time_total_s: 1.0011229515075684\n",
      "  timestamp: 1551176040\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_0_epochs=100:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_15-44-01\n",
      "  done: true\n",
      "  experiment_id: 0171d16c8e3a4d77b7b57534af433ead\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.8123011666795482\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 11985\n",
      "  time_since_restore: 2.002617359161377\n",
      "  time_this_iter_s: 1.0014913082122803\n",
      "  time_total_s: 2.002617359161377\n",
      "  timestamp: 1551176041\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_model_1_epochs=200:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_15-44-01\n",
      "  done: true\n",
      "  experiment_id: bf2b1a16fd6244e0bd53ee3f2c5781b7\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.8165429482277985\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 11987\n",
      "  time_since_restore: 2.0023839473724365\n",
      "  time_this_iter_s: 1.0012609958648682\n",
      "  time_total_s: 2.0023839473724365\n",
      "  timestamp: 1551176041\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.9/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_model_0_epochs=100:\tTERMINATED [pid=11985], 2 s, 2 iter, 0.812 acc\n",
      " - train_model_1_epochs=200:\tTERMINATED [pid=11987], 2 s, 2 iter, 0.817 acc\n",
      "\n",
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_1_epochs=200_2019-02-26_15-43-5858kseym3/weights_tune_{'units': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'losses': 'binary_crossentropy', 'epochs': 200}.h5\n",
      "1416/1416 [==============================] - 0s 51us/step\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ray import tune\n",
    "from hyperopt import hp\n",
    "\n",
    "dataset_name = \"uci_ad\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "url = \"../data/ad.data.csv\" if path.exists(\"../data/ad.data.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "\n",
    "data = data.applymap(lambda val: np.nan if str(val).strip() == '?' else val)\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "# Label encoding #\n",
    "\n",
    "lb = LabelEncoder()\n",
    "Y = lb.fit_transform(data.iloc[:, -1])\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "\n",
    "# Normalize the X values #\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "params = {\n",
    "    \"epochs\": tune.grid_search([100, 200])\n",
    "}\n",
    "\n",
    "space = {\n",
    "    'epochs': hp.choice(\"epochs\", [100, 200])\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #6\n",
    "\n",
    "#### UCI Mushroom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset info #\n",
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from hyperopt import hp\n",
    "from ray import tune\n",
    "\n",
    "dataset_name = \"uci_mushroom\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields with missing values\n",
      "stalk-root\n",
      "2480\n",
      "30.53%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = ['classes', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment',\n",
    "        'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
    "        'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring',\n",
    "        'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color',\n",
    "        'population', 'habitat']\n",
    "url = \"../data/mushroom.data.csv\" if path.exists(\"../data/mushroom.data.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names, index_col=False)\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "\n",
    "print(\"Fields with missing values\")\n",
    "col_names = data.columns\n",
    "num_data = data.shape[0]\n",
    "for c in col_names:\n",
    "    num_non = data[c].isin([\"?\"]).sum()\n",
    "    if num_non > 0:\n",
    "        print (c)\n",
    "        print (num_non)\n",
    "        print (\"{0:.2f}%\".format(float(num_non) / num_data * 100))\n",
    "        print (\"\\n\")\n",
    "\n",
    "data = data[data[\"stalk-root\"] != \"?\"]\n",
    "\n",
    "# Convert categorical fields #\n",
    "\n",
    "for col in names:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "# Split the dataset into test and train datasets #\n",
    "feature_list = names[1:23]\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['classes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2019-02-26 16:02:49,126\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-02-26 16:02:49,127\tINFO tune.py:145 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.3/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.3/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_model_1_epochs=200:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_epochs=100:\tRUNNING\n",
      "\n",
      "Result for train_model_0_epochs=100:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_16-02-51\n",
      "  done: false\n",
      "  experiment_id: b16163bb59874f86bfd4eb1b31b2e7a6\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.5618077095335545\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 13118\n",
      "  time_since_restore: 1.0011248588562012\n",
      "  time_this_iter_s: 1.0011248588562012\n",
      "  time_total_s: 1.0011248588562012\n",
      "  timestamp: 1551177171\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_1_epochs=200:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_16-02-51\n",
      "  done: false\n",
      "  experiment_id: 4d05e3627f3b4d97a7b4fb483f93bcc7\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.5618077095335545\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 13116\n",
      "  time_since_restore: 1.0011086463928223\n",
      "  time_this_iter_s: 1.0011086463928223\n",
      "  time_total_s: 1.0011086463928223\n",
      "  timestamp: 1551177171\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_0_epochs=100:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100}.h5'\n",
      "  date: 2019-02-26_16-02-52\n",
      "  done: true\n",
      "  experiment_id: b16163bb59874f86bfd4eb1b31b2e7a6\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.5618077095335545\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 13118\n",
      "  time_since_restore: 2.0026259422302246\n",
      "  time_this_iter_s: 1.0015010833740234\n",
      "  time_total_s: 2.0026259422302246\n",
      "  timestamp: 1551177172\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_model_1_epochs=200:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200}.h5'\n",
      "  date: 2019-02-26_16-02-52\n",
      "  done: true\n",
      "  experiment_id: 4d05e3627f3b4d97a7b4fb483f93bcc7\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.5618077095335545\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 13116\n",
      "  time_since_restore: 2.0023560523986816\n",
      "  time_this_iter_s: 1.0012474060058594\n",
      "  time_total_s: 2.0023560523986816\n",
      "  timestamp: 1551177172\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.8/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_model_0_epochs=100:\tTERMINATED [pid=13118], 2 s, 2 iter, 0.562 acc\n",
      " - train_model_1_epochs=200:\tTERMINATED [pid=13116], 2 s, 2 iter, 0.562 acc\n",
      "\n",
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_epochs=100_2019-02-26_16-02-49g6yixt6d/weights_tune_{'units': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'losses': 'binary_crossentropy', 'epochs': 100}.h5\n",
      "3387/3387 [==============================] - 0s 68us/step\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"epochs\": tune.grid_search([100, 200])\n",
    "}\n",
    "\n",
    "space = {\n",
    "    'epochs': hp.choice(\"epochs\", [30, 10])\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #7\n",
    "\n",
    "#### Covertype dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from ray import tune\n",
    "from hyperopt import hp\n",
    "\n",
    "dataset_name = \"covertype\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/covtype.data.csv\", delimiter=\",\", header=None, index_col=False)\n",
    "\n",
    "data = data[data[54].isin([1,2])]\n",
    "\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:,:-1]\n",
    "\n",
    "# Normalize the X values #\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2019-02-26 16:30:47,685\tINFO node.py:278 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-02-26_16-30-47_14505/logs.\n",
      "2019-02-26 16:30:47,816\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:41803 to respond...\n",
      "2019-02-26 16:30:47,947\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:55615 to respond...\n",
      "2019-02-26 16:30:47,949\tINFO services.py:798 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-02-26 16:30:48,036\tINFO services.py:1360 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=68d5054d6328dc9bacde3f2d7d21a167692a71c9d31bea63\n",
      "======================================================================\n",
      "\n",
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 16:30:52,411\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-02-26 16:30:52,412\tINFO tune.py:145 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.7/8.2 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 16:30:52,977\tERROR worker.py:1632 -- Warning: The actor WrappedFunc has size 87149043 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 7.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_model_1_epochs=200:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_epochs=100:\tRUNNING\n",
      "\n",
      "Result for train_model_0_epochs=100:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100, ''batch_size'':\n",
      "    100}.h5'\n",
      "  date: 2019-02-26_16-30-59\n",
      "  done: false\n",
      "  experiment_id: 4af12ae281a442c7b80fb7eb2f6921e2\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.4135749484994143\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 14541\n",
      "  time_since_restore: 5.0045411586761475\n",
      "  time_this_iter_s: 5.0045411586761475\n",
      "  time_total_s: 5.0045411586761475\n",
      "  timestamp: 1551178859\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 7.3/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_model_1_epochs=200:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_epochs=100:\tRUNNING [pid=14541], 5 s, 1 iter, 0.414 acc\n",
      "\n",
      "Result for train_model_0_epochs=100:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100, ''batch_size'':\n",
      "    100}.h5'\n",
      "  date: 2019-02-26_16-31-00\n",
      "  done: true\n",
      "  experiment_id: 4af12ae281a442c7b80fb7eb2f6921e2\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.4135749484994143\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 14541\n",
      "  time_since_restore: 6.00605320930481\n",
      "  time_this_iter_s: 1.001512050628662\n",
      "  time_total_s: 6.00605320930481\n",
      "  timestamp: 1551178860\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 16:31:00,610\tERROR worker.py:1632 -- Warning: The actor WrappedFunc has size 87149043 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_1_epochs=200:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200, ''batch_size'':\n",
      "    100}.h5'\n",
      "  date: 2019-02-26_16-31-06\n",
      "  done: false\n",
      "  experiment_id: 367af0f5cd9b4c54b76315964f0d1af0\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.4135749484994143\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 14542\n",
      "  time_since_restore: 5.004612684249878\n",
      "  time_this_iter_s: 5.004612684249878\n",
      "  time_total_s: 5.004612684249878\n",
      "  timestamp: 1551178866\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 7.2/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_model_1_epochs=200:\tRUNNING [pid=14542], 5 s, 1 iter, 0.414 acc\n",
      "TERMINATED trials:\n",
      " - train_model_0_epochs=100:\tTERMINATED [pid=14541], 6 s, 2 iter, 0.414 acc\n",
      "\n",
      "Result for train_model_1_epochs=200:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200, ''batch_size'':\n",
      "    100}.h5'\n",
      "  date: 2019-02-26_16-31-07\n",
      "  done: true\n",
      "  experiment_id: 367af0f5cd9b4c54b76315964f0d1af0\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.4135749484994143\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 14542\n",
      "  time_since_restore: 6.00609827041626\n",
      "  time_this_iter_s: 1.0014855861663818\n",
      "  time_total_s: 6.00609827041626\n",
      "  timestamp: 1551178867\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 7.2/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_model_0_epochs=100:\tTERMINATED [pid=14541], 6 s, 2 iter, 0.414 acc\n",
      " - train_model_1_epochs=200:\tTERMINATED [pid=14542], 6 s, 2 iter, 0.414 acc\n",
      "\n",
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_epochs=100_2019-02-26_16-30-52q3xgy681/weights_tune_{'units': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'losses': 'binary_crossentropy', 'epochs': 100, 'batch_size': 100}.h5\n",
      "297085/297085 [==============================] - 2s 5us/step\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"epochs\": tune.grid_search([100, 200]),\n",
    "    \"batch_size\": 100\n",
    "}\n",
    "\n",
    "space = {\n",
    "    'epochs': hp.choice(\"epochs\", [100, 200]),\n",
    "    \"batch_size\": 100\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #8\n",
    "\n",
    "#### TestData1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"test_data_1\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/testData1.csv\", delimiter=\",\", header=0, index_col=0)\n",
    "\n",
    "\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "600/600 [==============================] - ETA:  - 0s 105us/step\n",
      "Confusion matrix, without normalization\n",
      "Uploading ../data/test_data_1_logistic_regression.pdf to Amazon S3 bucket mlsquare-datasets\n",
      "..."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\":10\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #9\n",
    "\n",
    "#### TestData2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"test_data_2\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/testData2.csv\", delimiter=\",\", header=0, index_col=0)\n",
    "\n",
    "\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique,count = np.unique(Y,return_counts=True)\n",
    "class1=count[0]/X.shape[0]*100\n",
    "class2=count[1]/X.shape[0]*100\n",
    "class_distribution = round(class1, 2)\n",
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "2019-02-26 16:55:11,877\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-02-26 16:55:11,877\tINFO tune.py:145 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.9/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 5.9/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING\n",
      "\n",
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 1000, ''batch_size'':\n",
      "    100}.h5'\n",
      "  date: 2019-02-26_16-55-13\n",
      "  done: false\n",
      "  experiment_id: 8de9fff6f02842d1a96422200e31d48a\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.496875\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 14540\n",
      "  time_since_restore: 1.0011181831359863\n",
      "  time_this_iter_s: 1.0011181831359863\n",
      "  time_total_s: 1.0011181831359863\n",
      "  timestamp: 1551180313\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_0:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 1000, ''batch_size'':\n",
      "    100}.h5'\n",
      "  date: 2019-02-26_16-55-14\n",
      "  done: true\n",
      "  experiment_id: 8de9fff6f02842d1a96422200e31d48a\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.496875\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 14540\n",
      "  time_since_restore: 2.0028293132781982\n",
      "  time_this_iter_s: 1.001711130142212\n",
      "  time_total_s: 2.0028293132781982\n",
      "  timestamp: 1551180314\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_model_0:\tTERMINATED [pid=14540], 2 s, 2 iter, 0.497 acc\n",
      "\n",
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_2019-02-26_16-55-11mj4ugxfg/weights_tune_{'units': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'losses': 'binary_crossentropy', 'epochs': 1000, 'batch_size': 100}.h5\n",
      "480/480 [==============================] - 0s 64us/step\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\":100\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #10\n",
    "\n",
    "#### UCI Airfoil dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_name = \"uci_airfoil\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/uci_airfoil_self_noise.csv\", delimiter=\",\", header=0, index_col=0)\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "601/601 [==============================] - 0s 163us/step - loss: 3.0601 - acc: 0.0000e+00\n",
      "902/902 [==============================] - 0s 38us/step\n"
     ]
    }
   ],
   "source": [
    "automation_script.run_imly(dataset_info, 'linear_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #11\n",
    "\n",
    "#### UCI Auto-mpg dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_name = \"uci_auto_mpg\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/uci_auto_mpg.csv\", delimiter=\",\", header=0, index_col='car name')\n",
    "data = data[data.horsepower != '?']\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "Y = data.iloc[:,1]\n",
    "X = data.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "156/156 [==============================] - 0s 684us/step - loss: 0.8558 - acc: 0.0000e+00\n",
      "236/236 [==============================] - 0s 126us/step\n"
     ]
    }
   ],
   "source": [
    "automation_script.run_imly(dataset_info, 'linear_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2f5bc21b2f8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((int(1e12),int(1e12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #12\n",
    "\n",
    "#### Testdata 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_name = \"test_data_3\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/testData3.csv\", delimiter=\",\", header=0, index_col=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "400/400 [==============================] - 0s 353us/step - loss: 2.8405 - acc: 0.0000e+00\n",
      "600/600 [==============================] - 0s 90us/step\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\":100\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'linear_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #13\n",
    "\n",
    "#### Testdata 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset_name = \"test_data_4\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/testData4.csv\", delimiter=\",\", header=0, index_col=0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "Y = data.iloc[:, -1]\n",
    "X = data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:27<00:00, 27.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n",
      "600/600 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 843us/step\n",
      "Uploading ../data/test_data_4_linear_regression.pdf to Amazon S3 bucket mlsquare-pdf\n",
      "...."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    \"epochs\": 1000,\n",
    "    \"batch_size\":100\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'linear_regression', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #14\n",
    "\n",
    "#### Iris LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "2019-02-27 17:25:36,504\tWARNING worker.py:1354 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2019-02-27 17:25:36,527\tINFO node.py:278 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-02-27_17-25-36_1352/logs.\n",
      "2019-02-27 17:25:36,679\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:41754 to respond...\n",
      "2019-02-27 17:25:36,791\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:34342 to respond...\n",
      "2019-02-27 17:25:36,793\tINFO services.py:798 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-02-27 17:25:36,837\tINFO services.py:1360 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8890/notebooks/ray_ui.ipynb?token=5c45a972d5bb7c223bae8eb31e6b9126083531db1e838c91\n",
      "======================================================================\n",
      "\n",
      "Keras classifier chosen\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 0s 135us/step - loss: 0.4438 - acc: 0.5500\n",
      "60/60 [==============================] - 0s 23us/step\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"uci_iris_lda\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "url = \"../data/iris.csv\" if path.exists(\"../data/iris.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "params = {\n",
    "    'epochs': 170\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'linear_discrimant_analysis', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #15\n",
    "\n",
    "#### Adult salary LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "2019-02-26 17:28:42,012\tWARNING worker.py:1354 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2019-02-26 17:28:42,014\tINFO node.py:278 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-02-26_17-28-42_16711/logs.\n",
      "2019-02-26 17:28:42,155\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:10057 to respond...\n",
      "2019-02-26 17:28:42,293\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:32600 to respond...\n",
      "2019-02-26 17:28:42,302\tINFO services.py:798 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-02-26 17:28:42,368\tINFO services.py:1360 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n",
      "2019-02-26 17:28:42,523\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-02-26 17:28:42,524\tINFO tune.py:145 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8890/notebooks/ray_ui.ipynb?token=6c6f8f461e6b30cd0a9965c3f12c297797cc09cd8174bcad\n",
      "======================================================================\n",
      "\n",
      "Keras classifier chosen\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.0/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.1/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "RUNNING trials:\n",
      " - train_model_0:\tRUNNING\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-26 17:28:54,305\tERROR trial_runner.py:413 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shakkeel/anaconda3/envs/theano/lib/python3.6/site-packages/ray/tune/trial_runner.py\", line 378, in _process_events\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/shakkeel/anaconda3/envs/theano/lib/python3.6/site-packages/ray/tune/ray_trial_executor.py\", line 228, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/home/shakkeel/anaconda3/envs/theano/lib/python3.6/site-packages/ray/worker.py\", line 2132, in get\n",
      "    raise value\n",
      "ray.worker.RayTaskError: \u001b[36mray_worker\u001b[39m (pid=16772, host=shakkeel-TUF-GAMING-FX504GD-FX80GD)\n",
      "  File \"/home/shakkeel/anaconda3/envs/theano/lib/python3.6/site-packages/ray/tune/trainable.py\", line 151, in train\n",
      "    result = self._train()\n",
      "  File \"/home/shakkeel/anaconda3/envs/theano/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 128, in _train\n",
      "    result = self._status_reporter._get_and_clear_status()\n",
      "  File \"/home/shakkeel/anaconda3/envs/theano/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 50, in _get_and_clear_status\n",
      "    raise TuneError(\"Error running trial: \" + str(self._error))\n",
      "ray.tune.error.TuneError: Error running trial: InvalidValueError\n",
      "        type(variable) = TensorType(float32, matrix)\n",
      "        variable       = Elemwise{true_div,no_inplace}.0\n",
      "        type(value)    = <class 'numpy.ndarray'>\n",
      "        dtype(value)   = float32\n",
      "        shape(value)   = (1, 1)\n",
      "        value          = [[nan]]\n",
      "        min(value)     = nan\n",
      "        max(value)     = nan\n",
      "        isfinite       = False\n",
      "        client_node    = None\n",
      "        hint           = perform output\n",
      "        specific_hint  = non-finite elements not allowed\n",
      "        context        = ...\n",
      "  Elemwise{true_div,no_inplace} [id A] ''   \n",
      "   |Dot22 [id B] ''   \n",
      "   | |InplaceDimShuffle{1,0} [id C] ''   \n",
      "   | | |Elemwise{Sub}[(0, 0)] [id D] ''   \n",
      "   | |   |AdvancedSubtensor1 [id E] ''   \n",
      "   | |   | |<TensorType(float32, matrix)> [id F]\n",
      "   | |   | |Subtensor{int64} [id G] ''   \n",
      "   | |   |   |Nonzero [id H] ''   \n",
      "   | |   |   | |<TensorType(bool, vector)> [id I]\n",
      "   | |   |   |Constant{0} [id J]\n",
      "   | |   |Elemwise{TrueDiv}[(0, 0)] [id K] ''   \n",
      "   | |     |InplaceDimShuffle{x,0} [id L] ''   \n",
      "   | |     | |Sum{axis=[0], acc_dtype=float64} [id M] ''   \n",
      "   | |     |   |AdvancedSubtensor1 [id E] ''   \n",
      "   | |     |Elemwise{Cast{float32}} [id N] ''   \n",
      "   | |       |InplaceDimShuffle{x,x} [id O] ''   \n",
      "   | |         |Shape_i{1} [id P] ''   \n",
      "   | |           |Nonzero [id H] ''   \n",
      "   | |Elemwise{Sub}[(0, 0)] [id D] ''   \n",
      "   |Elemwise{Add}[(0, 1)] [id Q] ''   \n",
      "     |TensorConstant{(1, 1) of -1.0} [id R]\n",
      "     |Elemwise{Cast{float32}} [id N] ''   \n",
      "\n",
      "        \n",
      "Apply node that caused the error: for{cpu,scan_fn}(Shape_i{0}.0, Elemwise{eq,no_inplace}.0, Shape_i{0}.0, Elemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0)\n",
      "Toposort index: 70\n",
      "Inputs types: [TensorType(int64, scalar), TensorType(bool, matrix), TensorType(int64, scalar), TensorType(float32, matrix)]\n",
      "Inputs shapes: [(), (2, 32), (), (32, 1)]\n",
      "Inputs strides: [(), (32, 1), (), (4, 4)]\n",
      "Inputs values: [array(2), 'not shown', array(2), 'not shown']\n",
      "Outputs clients: [[Sum{axis=[0], acc_dtype=float64}(for{cpu,scan_fn}.0)]]\n",
      "\n",
      "HINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\n",
      "HINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.5/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "ERROR trials:\n",
      " - train_model_0:\tERROR, 1 failures: /home/shakkeel/ray_results/experiment_name/train_model_0_2019-02-26_17-28-4200u6xlme/error_2019-02-26_17-28-54.txt\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/0 GPUs\n",
      "Memory usage on this node: 6.5/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "ERROR trials:\n",
      " - train_model_0:\tERROR, 1 failures: /home/shakkeel/ray_results/experiment_name/train_model_0_2019-02-26_17-28-4200u6xlme/error_2019-02-26_17-28-54.txt\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_model_0])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c3c07585f780>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m }\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mautomation_script\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_imly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'linear_discrimant_analysis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/mlsquare/cook-imly/imly/automation_script.py\u001b[0m in \u001b[0;36mrun_imly\u001b[0;34m(dataset_info, model_name, X, Y, test_size, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'space'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mkeras_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mlsquare/cook-imly/imly/wrappers/sklearn/keras_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 self.model = get_best_model(x_train, y_train,\n\u001b[1;32m     54\u001b[0m                                             \u001b[0mprimal_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprimal_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                             params=self.params, space=hyperopt_space)\n\u001b[0m\u001b[1;32m     56\u001b[0m                 self.model.fit(x_train, y_train, epochs=200,\n\u001b[1;32m     57\u001b[0m                                batch_size=30, verbose=0)\n",
      "\u001b[0;32m~/Desktop/mlsquare/cook-imly/imly/optimizers/tune/tune.py\u001b[0m in \u001b[0;36mget_best_model\u001b[0;34m(x_train, y_train, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mean_accuracy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/theano/lib/python3.6/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, trial_executor, raise_on_failed_trial)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_model_0])"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "\n",
    "dataset_name = \"uci_adult_salary_lda\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "\n",
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "         'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "         'hours-per-week', 'native-country', 'target']\n",
    "url = \"../data/adult.data.csv\"\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names)\n",
    "\n",
    "\n",
    "data = data[data[\"workclass\"] != \"?\"]\n",
    "data = data[data[\"occupation\"] != \"?\"]\n",
    "data = data[data[\"native-country\"] != \"?\"]\n",
    "\n",
    "# Convert categorical fields #\n",
    "categorical_col = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                   'relationship', 'race', 'sex', 'native-country', 'target']\n",
    "\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "feature_list = names[:14]\n",
    "# Test train split #\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['target']]\n",
    "# Y = column_or_1d(Y, warn=True)\n",
    "\n",
    "params = {\n",
    "    'batch_size': 1000,\n",
    "    'epochs': 100\n",
    "}\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'linear_discrimant_analysis', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing tune by ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.tune as tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 1.6259 - acc: 0.5500\n",
      "60/60 [==============================] - 0s 630us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8434850215911864, 0.4666666626930237]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose iris with logistic regression as a test dataset #\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"../data/iris.csv\"\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "\n",
    "def make_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1,\n",
    "                    input_dim=4,\n",
    "                    activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_iris(args):\n",
    "    model = make_model()\n",
    "    model.fit(x_train,y_train)\n",
    "    model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-16 19:59:52,761\tWARNING worker.py:1354 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2019-02-16 19:59:52,763\tINFO node.py:278 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-02-16_19-59-52_11337/logs.\n",
      "2019-02-16 19:59:52,876\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:44284 to respond...\n",
      "2019-02-16 19:59:52,989\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:38375 to respond...\n",
      "2019-02-16 19:59:52,997\tINFO services.py:798 -- Starting Redis shard with 10.0 GB max memory.\n",
      "2019-02-16 19:59:53,049\tINFO services.py:1360 -- Starting the Plasma object store with 3.2850935800000003 GB memory using /dev/shm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8888/notebooks/ray_ui.ipynb?token=28905882e7b4006a0c688e21e69424958e0f2e952cc53040\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': None,\n",
       " 'redis_address': '192.168.1.4:44284',\n",
       " 'object_store_address': '/tmp/ray/session_2019-02-16_19-59-52_11337/sockets/plasma_store',\n",
       " 'webui_url': 'http://localhost:8888/notebooks/ray_ui.ipynb?token=28905882e7b4006a0c688e21e69424958e0f2e952cc53040',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-02-16_19-59-52_11337/sockets/raylet'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the signature of train function to accomodate Tune #\n",
    "def train_iris_tune(config, reporter):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        config (dict): Parameters provided from the search algorithm\n",
    "            or variant generation.\n",
    "        reporter (Reporter): Handle to report intermediate metrics to Tune.\n",
    "    \"\"\"\n",
    "    model = make_model()\n",
    "    model.fit(x_train,y_train)\n",
    "    accuracy = model.evaluate(x_test, y_test)[1]\n",
    "    reporter(mean_accuracy=accuracy, metric2=1, metric3=0.3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'test_reporter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a0aacb736dd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest_reporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtest_reporter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iris_tune\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'test_reporter'"
     ]
    }
   ],
   "source": [
    "from ray import test_reporter\n",
    "assert test_reporter(train_iris_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a Tune experiment #\n",
    "# 1) Search space\n",
    "# 2) Stopping criteria\n",
    "\n",
    "configuration = tune.Experiment(\n",
    "    \"experiment_name\",\n",
    "    run=train_iris_tune,\n",
    "    resources_per_trial={\"cpu\": 4},\n",
    "    stop={\"mean_accuracy\": 95},  # TODO: Part 1\n",
    "    config={\n",
    "        \"optimizer\": tune.grid_search(['adam', 'nadam'])\n",
    "    }  # TODO: Part 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-17 11:28:02,985\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-02-17 11:28:02,986\tINFO tune.py:145 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/8.2 GB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/8 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/8.2 GB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_iris_tune_1_optimizer=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_iris_tune_0_optimizer=adam:\tRUNNING\n",
      "\n",
      "Result for train_iris_tune_1_optimizer=nadam:\n",
      "  date: 2019-02-17_11-28-05\n",
      "  done: false\n",
      "  experiment_id: 49523f8d5a164a08a23bfbd2b5e5800c\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.4666666626930237\n",
      "  metric2: 1\n",
      "  metric3: 0.3\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 23323\n",
      "  time_since_restore: 1.0010333061218262\n",
      "  time_this_iter_s: 1.0010333061218262\n",
      "  time_total_s: 1.0010333061218262\n",
      "  timestamp: 1550383085\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_iris_tune_0_optimizer=adam:\n",
      "  date: 2019-02-17_11-28-05\n",
      "  done: false\n",
      "  experiment_id: cf285405c95e47e19c57db48b29f9ea7\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.4666666626930237\n",
      "  metric2: 1\n",
      "  metric3: 0.3\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 23321\n",
      "  time_since_restore: 1.0004656314849854\n",
      "  time_this_iter_s: 1.0004656314849854\n",
      "  time_total_s: 1.0004656314849854\n",
      "  timestamp: 1550383085\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_iris_tune_1_optimizer=nadam:\n",
      "  date: 2019-02-17_11-28-06\n",
      "  done: true\n",
      "  experiment_id: 49523f8d5a164a08a23bfbd2b5e5800c\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.4666666626930237\n",
      "  metric2: 1\n",
      "  metric3: 0.3\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 23323\n",
      "  time_since_restore: 2.0022518634796143\n",
      "  time_this_iter_s: 1.001218557357788\n",
      "  time_total_s: 2.0022518634796143\n",
      "  timestamp: 1550383086\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_iris_tune_0_optimizer=adam:\n",
      "  date: 2019-02-17_11-28-06\n",
      "  done: true\n",
      "  experiment_id: cf285405c95e47e19c57db48b29f9ea7\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.4666666626930237\n",
      "  metric2: 1\n",
      "  metric3: 0.3\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 23321\n",
      "  time_since_restore: 2.001732110977173\n",
      "  time_this_iter_s: 1.0012664794921875\n",
      "  time_total_s: 2.001732110977173\n",
      "  timestamp: 1550383086\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.6/8.2 GB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_iris_tune_0_optimizer=adam:\tTERMINATED [pid=23321], 2 s, 2 iter, 0.467 acc\n",
      " - train_iris_tune_1_optimizer=nadam:\tTERMINATED [pid=23323], 2 s, 2 iter, 0.467 acc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the experiment #\n",
    "trials = tune.run_experiments(configuration, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_best_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-3f9cda0cf31a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_best_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The best result is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_best_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean_accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_best_result'"
     ]
    }
   ],
   "source": [
    "from ray.tune.util import \n",
    "# print(\"The best result is\", get_best_result(trials, metric=\"mean_accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "workclass         False\n",
       "fnlwgt            False\n",
       "education         False\n",
       "education-num     False\n",
       "marital-status    False\n",
       "occupation        False\n",
       "relationship      False\n",
       "race              False\n",
       "sex               False\n",
       "capital-gain      False\n",
       "capital-loss      False\n",
       "hours-per-week    False\n",
       "native-country    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.isinf(X).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #16\n",
    "\n",
    "#### Abalone LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n",
      "Epoch 1/100\n",
      "529/529 [==============================] - 1s 1ms/step - loss: 0.0051 - acc: 0.4726\n",
      "Epoch 2/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0051 - acc: 0.4726\n",
      "Epoch 3/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0051 - acc: 0.4726\n",
      "Epoch 4/100\n",
      "529/529 [==============================] - 0s 8us/step - loss: 0.0051 - acc: 0.4726\n",
      "Epoch 5/100\n",
      "529/529 [==============================] - 0s 11us/step - loss: 0.0050 - acc: 0.4726\n",
      "Epoch 6/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0050 - acc: 0.4726\n",
      "Epoch 7/100\n",
      "529/529 [==============================] - 0s 11us/step - loss: 0.0050 - acc: 0.4726\n",
      "Epoch 8/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0050 - acc: 0.4726\n",
      "Epoch 9/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0050 - acc: 0.4726\n",
      "Epoch 10/100\n",
      "529/529 [==============================] - 0s 11us/step - loss: 0.0050 - acc: 0.4726\n",
      "Epoch 11/100\n",
      "529/529 [==============================] - 0s 8us/step - loss: 0.0050 - acc: 0.4726\n",
      "Epoch 12/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0050 - acc: 0.4726\n",
      "Epoch 13/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0049 - acc: 0.4726\n",
      "Epoch 14/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0049 - acc: 0.4726\n",
      "Epoch 15/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0049 - acc: 0.4726\n",
      "Epoch 16/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0049 - acc: 0.4726\n",
      "Epoch 17/100\n",
      "529/529 [==============================] - 0s 9us/step - loss: 0.0049 - acc: 0.4726\n",
      "Epoch 18/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0049 - acc: 0.4726\n",
      "Epoch 19/100\n",
      "529/529 [==============================] - 0s 8us/step - loss: 0.0049 - acc: 0.4726\n",
      "Epoch 20/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0049 - acc: 0.4726\n",
      "Epoch 21/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0048 - acc: 0.4726\n",
      "Epoch 22/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0048 - acc: 0.4726\n",
      "Epoch 23/100\n",
      "529/529 [==============================] - 0s 9us/step - loss: 0.0048 - acc: 0.4726\n",
      "Epoch 24/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0048 - acc: 0.4726\n",
      "Epoch 25/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0048 - acc: 0.4726\n",
      "Epoch 26/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0048 - acc: 0.4726\n",
      "Epoch 27/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0047 - acc: 0.4726\n",
      "Epoch 28/100\n",
      "529/529 [==============================] - 0s 13us/step - loss: 0.0047 - acc: 0.4726\n",
      "Epoch 29/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0047 - acc: 0.4726\n",
      "Epoch 30/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0047 - acc: 0.4726\n",
      "Epoch 31/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0047 - acc: 0.4726\n",
      "Epoch 32/100\n",
      "529/529 [==============================] - 0s 13us/step - loss: 0.0047 - acc: 0.4726\n",
      "Epoch 33/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0046 - acc: 0.4726\n",
      "Epoch 34/100\n",
      "529/529 [==============================] - 0s 15us/step - loss: 0.0046 - acc: 0.4726\n",
      "Epoch 35/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0046 - acc: 0.4726\n",
      "Epoch 36/100\n",
      "529/529 [==============================] - 0s 9us/step - loss: 0.0046 - acc: 0.4726\n",
      "Epoch 37/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0046 - acc: 0.4726\n",
      "Epoch 38/100\n",
      "529/529 [==============================] - 0s 9us/step - loss: 0.0045 - acc: 0.4726\n",
      "Epoch 39/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0045 - acc: 0.4726\n",
      "Epoch 40/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0045 - acc: 0.4726\n",
      "Epoch 41/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0045 - acc: 0.4726\n",
      "Epoch 42/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0045 - acc: 0.4726\n",
      "Epoch 43/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0044 - acc: 0.4726\n",
      "Epoch 44/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0044 - acc: 0.4726\n",
      "Epoch 45/100\n",
      "529/529 [==============================] - 0s 11us/step - loss: 0.0044 - acc: 0.4726\n",
      "Epoch 46/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0044 - acc: 0.4726\n",
      "Epoch 47/100\n",
      "529/529 [==============================] - 0s 17us/step - loss: 0.0043 - acc: 0.4726\n",
      "Epoch 48/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 0.4726\n",
      "Epoch 49/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0043 - acc: 0.4726\n",
      "Epoch 50/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0043 - acc: 0.4726\n",
      "Epoch 51/100\n",
      "529/529 [==============================] - 0s 15us/step - loss: 0.0042 - acc: 0.4726\n",
      "Epoch 52/100\n",
      "529/529 [==============================] - 0s 9us/step - loss: 0.0042 - acc: 0.4726\n",
      "Epoch 53/100\n",
      "529/529 [==============================] - 0s 9us/step - loss: 0.0042 - acc: 0.4726\n",
      "Epoch 54/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0042 - acc: 0.4726\n",
      "Epoch 55/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0041 - acc: 0.4726\n",
      "Epoch 56/100\n",
      "529/529 [==============================] - 0s 13us/step - loss: 0.0041 - acc: 0.4726\n",
      "Epoch 57/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0041 - acc: 0.4726\n",
      "Epoch 58/100\n",
      "529/529 [==============================] - 0s 15us/step - loss: 0.0040 - acc: 0.4726\n",
      "Epoch 59/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0040 - acc: 0.4726\n",
      "Epoch 60/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0040 - acc: 0.4726\n",
      "Epoch 61/100\n",
      "529/529 [==============================] - 0s 11us/step - loss: 0.0039 - acc: 0.4726\n",
      "Epoch 62/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0039 - acc: 0.4726\n",
      "Epoch 63/100\n",
      "529/529 [==============================] - 0s 11us/step - loss: 0.0039 - acc: 0.4726\n",
      "Epoch 64/100\n",
      "529/529 [==============================] - 0s 9us/step - loss: 0.0039 - acc: 0.4726\n",
      "Epoch 65/100\n",
      "529/529 [==============================] - 0s 8us/step - loss: 0.0038 - acc: 0.4726\n",
      "Epoch 66/100\n",
      "529/529 [==============================] - 0s 11us/step - loss: 0.0038 - acc: 0.4726\n",
      "Epoch 67/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0037 - acc: 0.4726\n",
      "Epoch 68/100\n",
      "529/529 [==============================] - 0s 11us/step - loss: 0.0037 - acc: 0.4726\n",
      "Epoch 69/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0037 - acc: 0.4726\n",
      "Epoch 70/100\n",
      "529/529 [==============================] - 0s 8us/step - loss: 0.0036 - acc: 0.4726\n",
      "Epoch 71/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0036 - acc: 0.4726\n",
      "Epoch 72/100\n",
      "529/529 [==============================] - 0s 17us/step - loss: 0.0036 - acc: 0.4726\n",
      "Epoch 73/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0035 - acc: 0.4726\n",
      "Epoch 74/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0035 - acc: 0.4726\n",
      "Epoch 75/100\n",
      "529/529 [==============================] - 0s 13us/step - loss: 0.0034 - acc: 0.4726\n",
      "Epoch 76/100\n",
      "529/529 [==============================] - 0s 8us/step - loss: 0.0034 - acc: 0.4726\n",
      "Epoch 77/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0034 - acc: 0.4726\n",
      "Epoch 78/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0033 - acc: 0.4726\n",
      "Epoch 79/100\n",
      "529/529 [==============================] - 0s 17us/step - loss: 0.0033 - acc: 0.4726\n",
      "Epoch 80/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 0.4726\n",
      "Epoch 81/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0032 - acc: 0.4726\n",
      "Epoch 82/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0031 - acc: 0.4726\n",
      "Epoch 83/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0031 - acc: 0.4726\n",
      "Epoch 84/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0030 - acc: 0.4726\n",
      "Epoch 85/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0030 - acc: 0.4726\n",
      "Epoch 86/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0030 - acc: 0.4726\n",
      "Epoch 87/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0029 - acc: 0.4726\n",
      "Epoch 88/100\n",
      "529/529 [==============================] - 0s 9us/step - loss: 0.0029 - acc: 0.4726\n",
      "Epoch 89/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0028 - acc: 0.4726\n",
      "Epoch 90/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0027 - acc: 0.4726\n",
      "Epoch 91/100\n",
      "529/529 [==============================] - 0s 8us/step - loss: 0.0027 - acc: 0.4726\n",
      "Epoch 92/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0026 - acc: 0.4726\n",
      "Epoch 93/100\n",
      "529/529 [==============================] - 0s 13us/step - loss: 0.0026 - acc: 0.4726\n",
      "Epoch 94/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0025 - acc: 0.4726\n",
      "Epoch 95/100\n",
      "529/529 [==============================] - 0s 6us/step - loss: 0.0025 - acc: 0.4726\n",
      "Epoch 96/100\n",
      "529/529 [==============================] - 0s 8us/step - loss: 0.0024 - acc: 0.4726\n",
      "Epoch 97/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0024 - acc: 0.4726\n",
      "Epoch 98/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0023 - acc: 0.4726\n",
      "Epoch 99/100\n",
      "529/529 [==============================] - 0s 8us/step - loss: 0.0022 - acc: 0.4726\n",
      "Epoch 100/100\n",
      "529/529 [==============================] - 0s 4us/step - loss: 0.0022 - acc: 0.4726\n",
      "794/794 [==============================] - ETA:  - 0s 14us/step\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "dataset_info = automation_script.get_dataset_info(\"uci_abalone_lda\")\n",
    "\n",
    "names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\",\n",
    "        \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "url = \"../data/abalone.data.csv\"\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names, index_col=False)\n",
    "data.head()\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "col_names = data.columns\n",
    "\n",
    "num_data = data.shape[0]\n",
    "\n",
    "categorical_col = ['sex']\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "    \n",
    "# Filter dataset to contain 'rings' 9 and 10 #\n",
    "data = data[data['rings'].isin([9,10])]\n",
    "data['rings'] = data['rings'].map({9: 0, 10: 1})\n",
    "\n",
    "\n",
    "feature_list = names[:7]\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['rings']]\n",
    "\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'linear_discrimant_analysis', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #17\n",
    "\n",
    "#### Mushroom LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields with missing values\n",
      "stalk-root\n",
      "2480\n",
      "30.53%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.0564 - acc: 0.5432\n",
      "Epoch 2/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0572 - acc: 0.5445\n",
      "Epoch 3/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.0581 - acc: 0.5467\n",
      "Epoch 4/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.0590 - acc: 0.5476\n",
      "Epoch 5/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.0599 - acc: 0.5498\n",
      "Epoch 6/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0608 - acc: 0.5516\n",
      "Epoch 7/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0617 - acc: 0.5516\n",
      "Epoch 8/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0627 - acc: 0.5521\n",
      "Epoch 9/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0636 - acc: 0.5529\n",
      "Epoch 10/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.0646 - acc: 0.5525\n",
      "Epoch 11/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.0656 - acc: 0.5543\n",
      "Epoch 12/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.0666 - acc: 0.5552\n",
      "Epoch 13/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0676 - acc: 0.5556\n",
      "Epoch 14/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0687 - acc: 0.5565\n",
      "Epoch 15/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0697 - acc: 0.5569\n",
      "Epoch 16/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0708 - acc: 0.5583\n",
      "Epoch 17/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0719 - acc: 0.5583\n",
      "Epoch 18/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.0730 - acc: 0.5591\n",
      "Epoch 19/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0741 - acc: 0.5605\n",
      "Epoch 20/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0752 - acc: 0.5614\n",
      "Epoch 21/100\n",
      "2257/2257 [==============================] - 0s 5us/step - loss: -0.0764 - acc: 0.5631\n",
      "Epoch 22/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0775 - acc: 0.5662\n",
      "Epoch 23/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0787 - acc: 0.5667\n",
      "Epoch 24/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0800 - acc: 0.5702\n",
      "Epoch 25/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.0812 - acc: 0.5698\n",
      "Epoch 26/100\n",
      "2257/2257 [==============================] - 0s 5us/step - loss: -0.0825 - acc: 0.5711\n",
      "Epoch 27/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0837 - acc: 0.5742\n",
      "Epoch 28/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0850 - acc: 0.5742\n",
      "Epoch 29/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0864 - acc: 0.5755\n",
      "Epoch 30/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0877 - acc: 0.5778\n",
      "Epoch 31/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.0891 - acc: 0.5778\n",
      "Epoch 32/100\n",
      "2257/2257 [==============================] - 0s 5us/step - loss: -0.0904 - acc: 0.5804\n",
      "Epoch 33/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0918 - acc: 0.5813\n",
      "Epoch 34/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.0933 - acc: 0.5813\n",
      "Epoch 35/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.0947 - acc: 0.5826\n",
      "Epoch 36/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.0962 - acc: 0.5840\n",
      "Epoch 37/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.0977 - acc: 0.5857\n",
      "Epoch 38/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.0992 - acc: 0.5866\n",
      "Epoch 39/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.1007 - acc: 0.5888\n",
      "Epoch 40/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1022 - acc: 0.5911\n",
      "Epoch 41/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.1038 - acc: 0.5919\n",
      "Epoch 42/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.1054 - acc: 0.5942\n",
      "Epoch 43/100\n",
      "2257/2257 [==============================] - 0s 6us/step - loss: -0.1070 - acc: 0.5937\n",
      "Epoch 44/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1086 - acc: 0.5942\n",
      "Epoch 45/100\n",
      "2257/2257 [==============================] - 0s 6us/step - loss: -0.1103 - acc: 0.5955\n",
      "Epoch 46/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.1119 - acc: 0.5959\n",
      "Epoch 47/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1136 - acc: 0.5981\n",
      "Epoch 48/100\n",
      "2257/2257 [==============================] - 0s 5us/step - loss: -0.1153 - acc: 0.5964\n",
      "Epoch 49/100\n",
      "2257/2257 [==============================] - 0s 5us/step - loss: -0.1170 - acc: 0.5977\n",
      "Epoch 50/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1187 - acc: 0.5995\n",
      "Epoch 51/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1205 - acc: 0.6008\n",
      "Epoch 52/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1223 - acc: 0.5999\n",
      "Epoch 53/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.1241 - acc: 0.5990\n",
      "Epoch 54/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1259 - acc: 0.6008\n",
      "Epoch 55/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1277 - acc: 0.6008\n",
      "Epoch 56/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1295 - acc: 0.6008\n",
      "Epoch 57/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.1314 - acc: 0.6026\n",
      "Epoch 58/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.1333 - acc: 0.6043\n",
      "Epoch 59/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1352 - acc: 0.6061\n",
      "Epoch 60/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.1371 - acc: 0.6061\n",
      "Epoch 61/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.1390 - acc: 0.6079\n",
      "Epoch 62/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1409 - acc: 0.6079\n",
      "Epoch 63/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.1429 - acc: 0.6088\n",
      "Epoch 64/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.1449 - acc: 0.6097\n",
      "Epoch 65/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.1469 - acc: 0.6097\n",
      "Epoch 66/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.1489 - acc: 0.6114\n",
      "Epoch 67/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1509 - acc: 0.6123\n",
      "Epoch 68/100\n",
      "2257/2257 [==============================] - 0s 4us/step - loss: -0.1529 - acc: 0.6128\n",
      "Epoch 69/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1549 - acc: 0.6128\n",
      "Epoch 70/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.1570 - acc: 0.6145\n",
      "Epoch 71/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1591 - acc: 0.6154\n",
      "Epoch 72/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1611 - acc: 0.6154\n",
      "Epoch 73/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1632 - acc: 0.6167\n",
      "Epoch 74/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1653 - acc: 0.6167\n",
      "Epoch 75/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1674 - acc: 0.6176\n",
      "Epoch 76/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1696 - acc: 0.6185\n",
      "Epoch 77/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1717 - acc: 0.6194\n",
      "Epoch 78/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.1738 - acc: 0.6207\n",
      "Epoch 79/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1760 - acc: 0.6221\n",
      "Epoch 80/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1781 - acc: 0.6234\n",
      "Epoch 81/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1803 - acc: 0.6238\n",
      "Epoch 82/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1825 - acc: 0.6243\n",
      "Epoch 83/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1847 - acc: 0.6256\n",
      "Epoch 84/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1868 - acc: 0.6269\n",
      "Epoch 85/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1890 - acc: 0.6269\n",
      "Epoch 86/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1912 - acc: 0.6287\n",
      "Epoch 87/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.1934 - acc: 0.6296\n",
      "Epoch 88/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1957 - acc: 0.6296\n",
      "Epoch 89/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.1979 - acc: 0.6305\n",
      "Epoch 90/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.2001 - acc: 0.6318\n",
      "Epoch 91/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.2023 - acc: 0.6323\n",
      "Epoch 92/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.2046 - acc: 0.6331\n",
      "Epoch 93/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.2068 - acc: 0.6336\n",
      "Epoch 94/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.2090 - acc: 0.6336\n",
      "Epoch 95/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.2113 - acc: 0.6340\n",
      "Epoch 96/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.2135 - acc: 0.6336\n",
      "Epoch 97/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.2158 - acc: 0.6349\n",
      "Epoch 98/100\n",
      "2257/2257 [==============================] - 0s 2us/step - loss: -0.2180 - acc: 0.6358\n",
      "Epoch 99/100\n",
      "2257/2257 [==============================] - 0s 3us/step - loss: -0.2202 - acc: 0.6380\n",
      "Epoch 100/100\n",
      "2257/2257 [==============================] - 0s 1us/step - loss: -0.2225 - acc: 0.6389\n",
      "3387/3387 [==============================] - ETA:  - 0s 13us/step\n"
     ]
    }
   ],
   "source": [
    "# Load dataset info #\n",
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "dataset_name = \"uci_mushroom_lda\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "names = ['classes', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment',\n",
    "        'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
    "        'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring',\n",
    "        'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color',\n",
    "        'population', 'habitat']\n",
    "url = \"../data/mushroom.data.csv\"\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names, index_col=False)\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "\n",
    "print(\"Fields with missing values\")\n",
    "col_names = data.columns\n",
    "num_data = data.shape[0]\n",
    "for c in col_names:\n",
    "    num_non = data[c].isin([\"?\"]).sum()\n",
    "    if num_non > 0:\n",
    "        print (c)\n",
    "        print (num_non)\n",
    "        print (\"{0:.2f}%\".format(float(num_non) / num_data * 100))\n",
    "        print (\"\\n\")\n",
    "\n",
    "data = data[data[\"stalk-root\"] != \"?\"]\n",
    "\n",
    "# Convert categorical fields #\n",
    "\n",
    "for col in names:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "# Split the dataset into test and train datasets #\n",
    "feature_list = names[1:23]\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['classes']]\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'linear_discrimant_analysis', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #18\n",
    "\n",
    "#### Ad dataset LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, object were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.linear_model' has no attribute 'LinearDiscriminantAnalysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-adec3f214c98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mautomation_script\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_imly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'linear_discrimant_analysis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/mlsquare/cook-imly/imly/automation_script.py\u001b[0m in \u001b[0;36mrun_imly\u001b[0;34m(dataset_info, model_name, X, Y, test_size, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sklearn.linear_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfromlist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m# module = __import__('sklearn.discriminant_analysis', fromlist=[name]) # Find a fix!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mimported_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimported_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mmodel_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.linear_model' has no attribute 'LinearDiscriminantAnalysis'"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset_name = \"uci_ad_lda\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "url = \"../data/ad.data.csv\"\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "\n",
    "data = data.applymap(lambda val: np.nan if str(val).strip() == '?' else val)\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "# Label encoding #\n",
    "\n",
    "lb = LabelEncoder()\n",
    "Y = lb.fit_transform(data.iloc[:, -1])\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "\n",
    "# Normalize the X values #\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "Y = pd.DataFrame(Y)\n",
    "\n",
    "automation_script.run_imly(dataset_info, 'linear_discrimant_analysis', X, Y, 0.60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset  #19\n",
    "\n",
    "#### Abalone multiclass version dataset (multi class logReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "dataset_info = automation_script.get_dataset_info(\"uci_abalone_multi_class\")\n",
    "\n",
    "names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\",\n",
    "        \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
    "url = \"../data/abalone.data.csv\"\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, names=names, index_col=False)\n",
    "data.head()\n",
    "\n",
    "# Check for columns that contain missing values #\n",
    "col_names = data.columns\n",
    "\n",
    "num_data = data.shape[0]\n",
    "\n",
    "categorical_col = ['sex']\n",
    "for col in categorical_col:\n",
    "    b, c = np.unique(data[col], return_inverse=True)\n",
    "    data[col] = c\n",
    "\n",
    "    \n",
    "# Filter dataset to contain 'rings' 9 and 10 #\n",
    "# data = data[data['rings'].isin([9,10])]\n",
    "# data['rings'] = data['rings'].map({9: 0, 10: 1})\n",
    "\n",
    "# Excluding labels 1, 2, 25, 26 and 29 since these labels contain just one sample\n",
    "# and this causes issue while creating a stratified Y.\n",
    "for x in [1,2,25,26,29]:\n",
    "    data = data[data['rings'] != x]\n",
    "\n",
    "\n",
    "feature_list = names[:7]\n",
    "X = data.loc[:, feature_list]\n",
    "Y = data[['rings']]\n",
    "\n",
    "# Y = to_categorical(Y)\n",
    "\n",
    "params = {\n",
    "    'epochs': {'grid_search': [100, 200]}\n",
    "}\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, stratify=Y, test_size=0.60, random_state=0)\n",
    "\n",
    "# automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "encoded_y_train = ohe.fit_transform(y_train)\n",
    "\n",
    "sklearn_model = LogisticRegression()\n",
    "sklearn_model.fit(x_train, y_train)\n",
    "y_pred = sklearn_model.predict(x_test)\n",
    "\n",
    "encoded_y_pred = ohe.transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (30,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-77c874a9ce91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdummy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdummy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (30,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers.core import Dense\n",
    "\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=x_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "dummy_model = make_model()\n",
    "dummy_model.fit(x_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 30)                240       \n",
      "=================================================================\n",
      "Total params: 240\n",
      "Trainable params: 240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from keras.utils import plot_model\n",
    "# plot_model(dummy_model, to_file='model.png')\n",
    "dummy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2507/2507 [==============================] - 0s 20us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2268173135415843, 0.22895891507355684]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 30)                240       \n",
      "=================================================================\n",
      "Total params: 240\n",
      "Trainable params: 240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dummy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-05 10:28:04,495\tINFO node.py:278 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-03-05_10-28-03_23505/logs.\n",
      "2019-03-05 10:28:04,666\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:37537 to respond...\n",
      "2019-03-05 10:28:04,980\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:44145 to respond...\n",
      "2019-03-05 10:28:04,982\tINFO services.py:798 -- Starting Redis shard with 20.0 GB max memory.\n",
      "2019-03-05 10:28:05,016\tINFO services.py:1360 -- Starting the Plasma object store with 1.0 GB memory using /dev/shm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=afbe20f78a8a0433c5761e2e6b749d7d49a00d175456a4d6\n",
      "======================================================================\n",
      "\n",
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "2019-03-05 10:28:08,546\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-03-05 10:28:08,546\tINFO tune.py:145 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionMultiClass  --- from keras_classifier.py\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.3/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_model_1_epochs=200:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_epochs=100:\tRUNNING\n",
      "\n",
      "Result for train_model_0_epochs=100:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100}.h5'\n",
      "  date: 2019-03-05_10-28-25\n",
      "  done: false\n",
      "  experiment_id: 9a2b86047d8e411db2d55f691c00b75e\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.4861111153515695\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 23571\n",
      "  time_since_restore: 9.007966995239258\n",
      "  time_this_iter_s: 9.007966995239258\n",
      "  time_total_s: 9.007966995239258\n",
      "  timestamp: 1551761905\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/4 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.5/8.2 GB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_model_1_epochs=200:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_model_0_epochs=100:\tRUNNING [pid=23571], 9 s, 1 iter, 0.486 acc\n",
      "\n",
      "Result for train_model_0_epochs=100:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 100}.h5'\n",
      "  date: 2019-03-05_10-28-27\n",
      "  done: true\n",
      "  experiment_id: 9a2b86047d8e411db2d55f691c00b75e\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.4861111153515695\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 23571\n",
      "  time_since_restore: 10.009236812591553\n",
      "  time_this_iter_s: 1.001269817352295\n",
      "  time_total_s: 10.009236812591553\n",
      "  timestamp: 1551761907\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_model_1_epochs=200:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200}.h5'\n",
      "  date: 2019-03-05_10-28-32\n",
      "  done: false\n",
      "  experiment_id: 5f2f79505df34e7fa23916332598e667\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.48581135515972296\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 23569\n",
      "  time_since_restore: 1.0008461475372314\n",
      "  time_this_iter_s: 1.0008461475372314\n",
      "  time_total_s: 1.0008461475372314\n",
      "  timestamp: 1551761912\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_model_1_epochs=200:\n",
      "  checkpoint: 'weights_tune_{''units'': 1, ''activation'': ''sigmoid'', ''optimizer'':\n",
      "    ''adam'', ''losses'': ''binary_crossentropy'', ''epochs'': 200}.h5'\n",
      "  date: 2019-03-05_10-28-33\n",
      "  done: true\n",
      "  experiment_id: 5f2f79505df34e7fa23916332598e667\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.48581135515972296\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 23569\n",
      "  time_since_restore: 2.001967191696167\n",
      "  time_this_iter_s: 1.0011210441589355\n",
      "  time_total_s: 2.001967191696167\n",
      "  timestamp: 1551761913\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_model_0_epochs=100:\tTERMINATED [pid=23571], 10 s, 2 iter, 0.486 acc\n",
      " - train_model_1_epochs=200:\tTERMINATED [pid=23569], 2 s, 2 iter, 0.486 acc\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/4 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.4/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_model_0_epochs=100:\tTERMINATED [pid=23571], 10 s, 2 iter, 0.486 acc\n",
      " - train_model_1_epochs=200:\tTERMINATED [pid=23569], 2 s, 2 iter, 0.486 acc\n",
      "\n",
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_model_0_epochs=100_2019-03-05_10-28-08c5u2u8_w/weights_tune_{'units': 1, 'activation': 'sigmoid', 'optimizer': 'adam', 'losses': 'binary_crossentropy', 'epochs': 100}.h5\n"
     ]
    }
   ],
   "source": [
    "from imly import dope\n",
    "from keras.utils import to_categorical\n",
    "primal = LogisticRegression(fit_intercept=False)\n",
    "imly_model = dope(primal)\n",
    "imly_model.fit(x_train, y_train, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = imly_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03909054646988432"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.accuracy_score(y_test, y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (12,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-17c6b490d7a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimly_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (12,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "score = imly_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, count = np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "sklearn_model = LogisticRegression()\n",
    "sklearn_model.fit(x_train, y_train)\n",
    "sklearn_pred = sklearn_model.predict(x_train)\n",
    "test_split = keras.utils.np_utils.to_categorical(sklearn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1670, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (12,) but got array with shape (30,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5b6d3cd89ffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mencoded_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimly_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (12,) but got array with shape (30,)"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "encoded_y_test = to_categorical(y_test)\n",
    "imly_model.model.evaluate(x_test, encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-27d3425f7a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import column_or_1d\n",
    "Y = column_or_1d(Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# m = LogisticRegression(solver='lbfgs', multi_class='ovr')\n",
    "m = LogisticRegression()\n",
    "\n",
    "m.fit(x_train, y_train)\n",
    "score = m.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 29])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test iris multiclass logreg #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "url = \"../data/iris.csv\"\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X2 = data.iloc[:,:-1]\n",
    "Y2 = data.iloc[:,-1]\n",
    "\n",
    "m2 = LogisticRegression()\n",
    "m2.fit(X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LogisticRegressionMultiClass'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.__class__.__name__ + 'MultiClass'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test bed ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Hyperas(Logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LogisticRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imly import dope\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LogisticRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import boto\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import sys\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from boto.s3.key import Key\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.utils.validation import column_or_1d\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LogisticRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import copy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import datasets\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import experiment_automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LinearRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import experiment_automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import re\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from automation_script import get_dataset_info\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imly import dope\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from utils.correlations import concordance_correlation_coefficient as ccc\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LinearRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imly import dope\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from utils.correlations import concordance_correlation_coefficient as ccc\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import boto\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import sys\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from boto.s3.key import Key\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.datasets import make_regression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import theano.tensor as T\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import theano\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from theano.compile.ops import as_op\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'optimizer': hp.choice('optimizer', ['adam', 'nadam']),\n",
      "        'batch_size': hp.choice('batch_size', [10, 30]),\n",
      "        'epochs': hp.choice('epochs', [100, 170]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: '''\n",
      "  3: Data providing function:\n",
      "  4: \n",
      "  5: Make sure to have every relevant import statement included here and return data as\n",
      "  6: used in model function below. This function is separated from model() so that hyperopt\n",
      "  7: won't reload data for each evaluation run.\n",
      "  8: '''\n",
      "  9: url = \"../data/iris.csv\"\n",
      " 10: data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
      " 11: class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
      " 12: data.iloc[:,-1] = index\n",
      " 13: data = data.loc[data[4] != 2]\n",
      " 14: X = data.iloc[:,:-1]\n",
      " 15: Y = data.iloc[:,-1]\n",
      " 16: x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
      " 17: \n",
      " 18: \n",
      " 19: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     '''\n",
      "   4:     Model providing function:\n",
      "   5: \n",
      "   6:     Create Keras model with double curly brackets dropped-in as needed.\n",
      "   7:     Return value has to be a valid python dictionary with two customary keys:\n",
      "   8:         - loss: Specify a numeric evaluation metric to be minimized\n",
      "   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
      "  10:     The last one is optional, though recommended, namely:\n",
      "  11:         - model: specify the model just created so that we can later use it again.\n",
      "  12:     '''\n",
      "  13: \n",
      "  14:     model = Sequential()\n",
      "  15:     model.add(Dense(1, input_dim=4, activation='sigmoid'))\n",
      "  16: \n",
      "  17:     model.compile(loss='binary_crossentropy', optimizer=space['optimizer'],\n",
      "  18:                  metrics=['accuracy'])\n",
      "  19: \n",
      "  20:     model.fit(x_train, y_train,\n",
      "  21:               batch_size=space['batch_size'],\n",
      "  22:               epochs=space['epochs'],\n",
      "  23:               verbose=2,\n",
      "  24:               validation_data=(x_test, y_test))\n",
      "  25:     score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
      "  26:     print('Test accuracy:', acc)\n",
      "  27:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  28: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40 samples, validate on 60 samples\n",
      "Epoch 1/170\n",
      " - 0s - loss: 0.8220 - acc: 0.5500 - val_loss: 0.8823 - val_acc: 0.4667\n",
      "Epoch 2/170\n",
      " - 0s - loss: 0.8120 - acc: 0.5500 - val_loss: 0.8704 - val_acc: 0.4667\n",
      "Epoch 3/170\n",
      " - 0s - loss: 0.8036 - acc: 0.5500 - val_loss: 0.8589 - val_acc: 0.4667\n",
      "Epoch 4/170\n",
      " - 0s - loss: 0.7932 - acc: 0.5500 - val_loss: 0.8484 - val_acc: 0.4667\n",
      "Epoch 5/170\n",
      " - 0s - loss: 0.7865 - acc: 0.5500 - val_loss: 0.8375 - val_acc: 0.4667\n",
      "Epoch 6/170\n",
      " - 0s - loss: 0.7778 - acc: 0.5500 - val_loss: 0.8276 - val_acc: 0.4667\n",
      "Epoch 7/170\n",
      " - 0s - loss: 0.7692 - acc: 0.5500 - val_loss: 0.8183 - val_acc: 0.4667\n",
      "Epoch 8/170\n",
      " - 0s - loss: 0.7628 - acc: 0.5500 - val_loss: 0.8088 - val_acc: 0.4667\n",
      "Epoch 9/170\n",
      " - 0s - loss: 0.7558 - acc: 0.5500 - val_loss: 0.7994 - val_acc: 0.4667\n",
      "Epoch 10/170\n",
      " - 0s - loss: 0.7486 - acc: 0.5500 - val_loss: 0.7904 - val_acc: 0.4667\n",
      "Epoch 11/170\n",
      " - 0s - loss: 0.7421 - acc: 0.5500 - val_loss: 0.7815 - val_acc: 0.4667\n",
      "Epoch 12/170\n",
      " - 0s - loss: 0.7358 - acc: 0.5500 - val_loss: 0.7729 - val_acc: 0.4667\n",
      "Epoch 13/170\n",
      " - 0s - loss: 0.7287 - acc: 0.5500 - val_loss: 0.7648 - val_acc: 0.4667\n",
      "Epoch 14/170\n",
      " - 0s - loss: 0.7218 - acc: 0.5500 - val_loss: 0.7575 - val_acc: 0.4667\n",
      "Epoch 15/170\n",
      " - 0s - loss: 0.7161 - acc: 0.5500 - val_loss: 0.7503 - val_acc: 0.4667\n",
      "Epoch 16/170\n",
      " - 0s - loss: 0.7110 - acc: 0.5500 - val_loss: 0.7427 - val_acc: 0.4667\n",
      "Epoch 17/170\n",
      " - 0s - loss: 0.7061 - acc: 0.5500 - val_loss: 0.7350 - val_acc: 0.4667\n",
      "Epoch 18/170\n",
      " - 0s - loss: 0.6991 - acc: 0.5500 - val_loss: 0.7284 - val_acc: 0.4667\n",
      "Epoch 19/170\n",
      " - 0s - loss: 0.6941 - acc: 0.5500 - val_loss: 0.7217 - val_acc: 0.4667\n",
      "Epoch 20/170\n",
      " - 0s - loss: 0.6882 - acc: 0.5500 - val_loss: 0.7157 - val_acc: 0.4667\n",
      "Epoch 21/170\n",
      " - 0s - loss: 0.6837 - acc: 0.5500 - val_loss: 0.7094 - val_acc: 0.4667\n",
      "Epoch 22/170\n",
      " - 0s - loss: 0.6786 - acc: 0.5500 - val_loss: 0.7031 - val_acc: 0.4667\n",
      "Epoch 23/170\n",
      " - 0s - loss: 0.6736 - acc: 0.5500 - val_loss: 0.6971 - val_acc: 0.4667\n",
      "Epoch 24/170\n",
      " - 0s - loss: 0.6687 - acc: 0.5500 - val_loss: 0.6913 - val_acc: 0.4667\n",
      "Epoch 25/170\n",
      " - 0s - loss: 0.6638 - acc: 0.5500 - val_loss: 0.6857 - val_acc: 0.4667\n",
      "Epoch 26/170\n",
      " - 0s - loss: 0.6591 - acc: 0.5500 - val_loss: 0.6802 - val_acc: 0.4667\n",
      "Epoch 27/170\n",
      " - 0s - loss: 0.6545 - acc: 0.5500 - val_loss: 0.6748 - val_acc: 0.4667\n",
      "Epoch 28/170\n",
      " - 0s - loss: 0.6508 - acc: 0.5500 - val_loss: 0.6690 - val_acc: 0.4667\n",
      "Epoch 29/170\n",
      " - 0s - loss: 0.6462 - acc: 0.5500 - val_loss: 0.6633 - val_acc: 0.4667\n",
      "Epoch 30/170\n",
      " - 0s - loss: 0.6415 - acc: 0.5500 - val_loss: 0.6581 - val_acc: 0.4667\n",
      "Epoch 31/170\n",
      " - 0s - loss: 0.6367 - acc: 0.5500 - val_loss: 0.6533 - val_acc: 0.4667\n",
      "Epoch 32/170\n",
      " - 0s - loss: 0.6325 - acc: 0.5500 - val_loss: 0.6484 - val_acc: 0.4667\n",
      "Epoch 33/170\n",
      " - 0s - loss: 0.6286 - acc: 0.5500 - val_loss: 0.6434 - val_acc: 0.4667\n",
      "Epoch 34/170\n",
      " - 0s - loss: 0.6244 - acc: 0.5500 - val_loss: 0.6385 - val_acc: 0.4667\n",
      "Epoch 35/170\n",
      " - 0s - loss: 0.6199 - acc: 0.5750 - val_loss: 0.6342 - val_acc: 0.4667\n",
      "Epoch 36/170\n",
      " - 0s - loss: 0.6162 - acc: 0.5750 - val_loss: 0.6295 - val_acc: 0.4667\n",
      "Epoch 37/170\n",
      " - 0s - loss: 0.6121 - acc: 0.5750 - val_loss: 0.6248 - val_acc: 0.4667\n",
      "Epoch 38/170\n",
      " - 0s - loss: 0.6080 - acc: 0.5750 - val_loss: 0.6205 - val_acc: 0.4667\n",
      "Epoch 39/170\n",
      " - 0s - loss: 0.6042 - acc: 0.5750 - val_loss: 0.6161 - val_acc: 0.4833\n",
      "Epoch 40/170\n",
      " - 0s - loss: 0.6004 - acc: 0.6000 - val_loss: 0.6116 - val_acc: 0.5000\n",
      "Epoch 41/170\n",
      " - 0s - loss: 0.5967 - acc: 0.6000 - val_loss: 0.6071 - val_acc: 0.5000\n",
      "Epoch 42/170\n",
      " - 0s - loss: 0.5926 - acc: 0.6000 - val_loss: 0.6029 - val_acc: 0.5000\n",
      "Epoch 43/170\n",
      " - 0s - loss: 0.5895 - acc: 0.6000 - val_loss: 0.5983 - val_acc: 0.5167\n",
      "Epoch 44/170\n",
      " - 0s - loss: 0.5852 - acc: 0.6250 - val_loss: 0.5942 - val_acc: 0.5167\n",
      "Epoch 45/170\n",
      " - 0s - loss: 0.5819 - acc: 0.6250 - val_loss: 0.5899 - val_acc: 0.5333\n",
      "Epoch 46/170\n",
      " - 0s - loss: 0.5778 - acc: 0.6500 - val_loss: 0.5861 - val_acc: 0.5333\n",
      "Epoch 47/170\n",
      " - 0s - loss: 0.5741 - acc: 0.6500 - val_loss: 0.5825 - val_acc: 0.5333\n",
      "Epoch 48/170\n",
      " - 0s - loss: 0.5710 - acc: 0.6500 - val_loss: 0.5784 - val_acc: 0.5333\n",
      "Epoch 49/170\n",
      " - 0s - loss: 0.5672 - acc: 0.6500 - val_loss: 0.5748 - val_acc: 0.5333\n",
      "Epoch 50/170\n",
      " - 0s - loss: 0.5636 - acc: 0.6500 - val_loss: 0.5713 - val_acc: 0.5667\n",
      "Epoch 51/170\n",
      " - 0s - loss: 0.5603 - acc: 0.6500 - val_loss: 0.5676 - val_acc: 0.5667\n",
      "Epoch 52/170\n",
      " - 0s - loss: 0.5569 - acc: 0.6500 - val_loss: 0.5639 - val_acc: 0.5667\n",
      "Epoch 53/170\n",
      " - 0s - loss: 0.5538 - acc: 0.6500 - val_loss: 0.5601 - val_acc: 0.5833\n",
      "Epoch 54/170\n",
      " - 0s - loss: 0.5503 - acc: 0.6750 - val_loss: 0.5564 - val_acc: 0.5833\n",
      "Epoch 55/170\n",
      " - 0s - loss: 0.5468 - acc: 0.6750 - val_loss: 0.5531 - val_acc: 0.6167\n",
      "Epoch 56/170\n",
      " - 0s - loss: 0.5438 - acc: 0.6750 - val_loss: 0.5494 - val_acc: 0.6167\n",
      "Epoch 57/170\n",
      " - 0s - loss: 0.5404 - acc: 0.6750 - val_loss: 0.5460 - val_acc: 0.6167\n",
      "Epoch 58/170\n",
      " - 0s - loss: 0.5371 - acc: 0.6750 - val_loss: 0.5427 - val_acc: 0.6167\n",
      "Epoch 59/170\n",
      " - 0s - loss: 0.5341 - acc: 0.6750 - val_loss: 0.5391 - val_acc: 0.6333\n",
      "Epoch 60/170\n",
      " - 0s - loss: 0.5308 - acc: 0.6750 - val_loss: 0.5357 - val_acc: 0.6333\n",
      "Epoch 61/170\n",
      " - 0s - loss: 0.5277 - acc: 0.6750 - val_loss: 0.5325 - val_acc: 0.6333\n",
      "Epoch 62/170\n",
      " - 0s - loss: 0.5246 - acc: 0.7000 - val_loss: 0.5293 - val_acc: 0.6333\n",
      "Epoch 63/170\n",
      " - 0s - loss: 0.5216 - acc: 0.7000 - val_loss: 0.5259 - val_acc: 0.6500\n",
      "Epoch 64/170\n",
      " - 0s - loss: 0.5184 - acc: 0.7000 - val_loss: 0.5229 - val_acc: 0.6667\n",
      "Epoch 65/170\n",
      " - 0s - loss: 0.5154 - acc: 0.7000 - val_loss: 0.5196 - val_acc: 0.7000\n",
      "Epoch 66/170\n",
      " - 0s - loss: 0.5123 - acc: 0.7000 - val_loss: 0.5164 - val_acc: 0.7000\n",
      "Epoch 67/170\n",
      " - 0s - loss: 0.5094 - acc: 0.7250 - val_loss: 0.5132 - val_acc: 0.7000\n",
      "Epoch 68/170\n",
      " - 0s - loss: 0.5066 - acc: 0.7250 - val_loss: 0.5100 - val_acc: 0.7167\n",
      "Epoch 69/170\n",
      " - 0s - loss: 0.5035 - acc: 0.7250 - val_loss: 0.5068 - val_acc: 0.7167\n",
      "Epoch 70/170\n",
      " - 0s - loss: 0.5006 - acc: 0.7250 - val_loss: 0.5039 - val_acc: 0.7333\n",
      "Epoch 71/170\n",
      " - 0s - loss: 0.4979 - acc: 0.7500 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 72/170\n",
      " - 0s - loss: 0.4949 - acc: 0.7500 - val_loss: 0.4977 - val_acc: 0.8167\n",
      "Epoch 73/170\n",
      " - 0s - loss: 0.4921 - acc: 0.7500 - val_loss: 0.4946 - val_acc: 0.8167\n",
      "Epoch 74/170\n",
      " - 0s - loss: 0.4892 - acc: 0.7750 - val_loss: 0.4918 - val_acc: 0.8167\n",
      "Epoch 75/170\n",
      " - 0s - loss: 0.4865 - acc: 0.7750 - val_loss: 0.4888 - val_acc: 0.8333\n",
      "Epoch 76/170\n",
      " - 0s - loss: 0.4837 - acc: 0.7750 - val_loss: 0.4859 - val_acc: 0.8333\n",
      "Epoch 77/170\n",
      " - 0s - loss: 0.4813 - acc: 0.7750 - val_loss: 0.4828 - val_acc: 0.8500\n",
      "Epoch 78/170\n",
      " - 0s - loss: 0.4783 - acc: 0.8000 - val_loss: 0.4800 - val_acc: 0.8500\n",
      "Epoch 79/170\n",
      " - 0s - loss: 0.4755 - acc: 0.8000 - val_loss: 0.4775 - val_acc: 0.8500\n",
      "Epoch 80/170\n",
      " - 0s - loss: 0.4729 - acc: 0.8000 - val_loss: 0.4748 - val_acc: 0.8500\n",
      "Epoch 81/170\n",
      " - 0s - loss: 0.4703 - acc: 0.8000 - val_loss: 0.4720 - val_acc: 0.8667\n",
      "Epoch 82/170\n",
      " - 0s - loss: 0.4676 - acc: 0.8250 - val_loss: 0.4694 - val_acc: 0.8667\n",
      "Epoch 83/170\n",
      " - 0s - loss: 0.4652 - acc: 0.8250 - val_loss: 0.4666 - val_acc: 0.8667\n",
      "Epoch 84/170\n",
      " - 0s - loss: 0.4625 - acc: 0.8250 - val_loss: 0.4643 - val_acc: 0.8667\n",
      "Epoch 85/170\n",
      " - 0s - loss: 0.4599 - acc: 0.8250 - val_loss: 0.4618 - val_acc: 0.8667\n",
      "Epoch 86/170\n",
      " - 0s - loss: 0.4574 - acc: 0.8250 - val_loss: 0.4590 - val_acc: 0.8667\n",
      "Epoch 87/170\n",
      " - 0s - loss: 0.4550 - acc: 0.8250 - val_loss: 0.4563 - val_acc: 0.9000\n",
      "Epoch 88/170\n",
      " - 0s - loss: 0.4524 - acc: 0.8250 - val_loss: 0.4537 - val_acc: 0.9000\n",
      "Epoch 89/170\n",
      " - 0s - loss: 0.4499 - acc: 0.8250 - val_loss: 0.4512 - val_acc: 0.9000\n",
      "Epoch 90/170\n",
      " - 0s - loss: 0.4475 - acc: 0.8250 - val_loss: 0.4488 - val_acc: 0.9000\n",
      "Epoch 91/170\n",
      " - 0s - loss: 0.4453 - acc: 0.8250 - val_loss: 0.4460 - val_acc: 0.9000\n",
      "Epoch 92/170\n",
      " - 0s - loss: 0.4428 - acc: 0.8250 - val_loss: 0.4434 - val_acc: 0.9000\n",
      "Epoch 93/170\n",
      " - 0s - loss: 0.4402 - acc: 0.8250 - val_loss: 0.4411 - val_acc: 0.9000\n",
      "Epoch 94/170\n",
      " - 0s - loss: 0.4379 - acc: 0.8500 - val_loss: 0.4386 - val_acc: 0.9333\n",
      "Epoch 95/170\n",
      " - 0s - loss: 0.4356 - acc: 0.8750 - val_loss: 0.4362 - val_acc: 0.9500\n",
      "Epoch 96/170\n",
      " - 0s - loss: 0.4332 - acc: 0.8750 - val_loss: 0.4340 - val_acc: 0.9500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/170\n",
      " - 0s - loss: 0.4310 - acc: 0.8750 - val_loss: 0.4319 - val_acc: 0.9500\n",
      "Epoch 98/170\n",
      " - 0s - loss: 0.4288 - acc: 0.8750 - val_loss: 0.4295 - val_acc: 0.9500\n",
      "Epoch 99/170\n",
      " - 0s - loss: 0.4265 - acc: 0.9000 - val_loss: 0.4271 - val_acc: 0.9500\n",
      "Epoch 100/170\n",
      " - 0s - loss: 0.4243 - acc: 0.9250 - val_loss: 0.4247 - val_acc: 0.9500\n",
      "Epoch 101/170\n",
      " - 0s - loss: 0.4219 - acc: 0.9500 - val_loss: 0.4225 - val_acc: 0.9500\n",
      "Epoch 102/170\n",
      " - 0s - loss: 0.4198 - acc: 0.9500 - val_loss: 0.4202 - val_acc: 0.9500\n",
      "Epoch 103/170\n",
      " - 0s - loss: 0.4176 - acc: 0.9500 - val_loss: 0.4179 - val_acc: 0.9500\n",
      "Epoch 104/170\n",
      " - 0s - loss: 0.4154 - acc: 0.9500 - val_loss: 0.4157 - val_acc: 0.9500\n",
      "Epoch 105/170\n",
      " - 0s - loss: 0.4132 - acc: 0.9500 - val_loss: 0.4136 - val_acc: 0.9667\n",
      "Epoch 106/170\n",
      " - 0s - loss: 0.4111 - acc: 0.9500 - val_loss: 0.4115 - val_acc: 0.9667\n",
      "Epoch 107/170\n",
      " - 0s - loss: 0.4089 - acc: 0.9500 - val_loss: 0.4094 - val_acc: 0.9667\n",
      "Epoch 108/170\n",
      " - 0s - loss: 0.4069 - acc: 0.9500 - val_loss: 0.4074 - val_acc: 0.9667\n",
      "Epoch 109/170\n",
      " - 0s - loss: 0.4048 - acc: 0.9750 - val_loss: 0.4054 - val_acc: 0.9667\n",
      "Epoch 110/170\n",
      " - 0s - loss: 0.4027 - acc: 0.9750 - val_loss: 0.4032 - val_acc: 0.9667\n",
      "Epoch 111/170\n",
      " - 0s - loss: 0.4006 - acc: 0.9750 - val_loss: 0.4012 - val_acc: 0.9667\n",
      "Epoch 112/170\n",
      " - 0s - loss: 0.3986 - acc: 0.9750 - val_loss: 0.3991 - val_acc: 0.9833\n",
      "Epoch 113/170\n",
      " - 0s - loss: 0.3965 - acc: 0.9750 - val_loss: 0.3969 - val_acc: 0.9833\n",
      "Epoch 114/170\n",
      " - 0s - loss: 0.3945 - acc: 0.9750 - val_loss: 0.3949 - val_acc: 0.9833\n",
      "Epoch 115/170\n",
      " - 0s - loss: 0.3925 - acc: 0.9750 - val_loss: 0.3928 - val_acc: 0.9833\n",
      "Epoch 116/170\n",
      " - 0s - loss: 0.3905 - acc: 0.9750 - val_loss: 0.3907 - val_acc: 0.9833\n",
      "Epoch 117/170\n",
      " - 0s - loss: 0.3886 - acc: 0.9750 - val_loss: 0.3885 - val_acc: 0.9833\n",
      "Epoch 118/170\n",
      " - 0s - loss: 0.3865 - acc: 0.9750 - val_loss: 0.3865 - val_acc: 0.9833\n",
      "Epoch 119/170\n",
      " - 0s - loss: 0.3846 - acc: 0.9750 - val_loss: 0.3845 - val_acc: 0.9833\n",
      "Epoch 120/170\n",
      " - 0s - loss: 0.3826 - acc: 0.9750 - val_loss: 0.3827 - val_acc: 0.9833\n",
      "Epoch 121/170\n",
      " - 0s - loss: 0.3807 - acc: 0.9750 - val_loss: 0.3807 - val_acc: 0.9833\n",
      "Epoch 122/170\n",
      " - 0s - loss: 0.3788 - acc: 0.9750 - val_loss: 0.3787 - val_acc: 0.9833\n",
      "Epoch 123/170\n",
      " - 0s - loss: 0.3769 - acc: 1.0000 - val_loss: 0.3768 - val_acc: 0.9833\n",
      "Epoch 124/170\n",
      " - 0s - loss: 0.3752 - acc: 1.0000 - val_loss: 0.3747 - val_acc: 0.9833\n",
      "Epoch 125/170\n",
      " - 0s - loss: 0.3731 - acc: 1.0000 - val_loss: 0.3729 - val_acc: 0.9833\n",
      "Epoch 126/170\n",
      " - 0s - loss: 0.3713 - acc: 1.0000 - val_loss: 0.3709 - val_acc: 0.9833\n",
      "Epoch 127/170\n",
      " - 0s - loss: 0.3694 - acc: 1.0000 - val_loss: 0.3691 - val_acc: 0.9833\n",
      "Epoch 128/170\n",
      " - 0s - loss: 0.3676 - acc: 1.0000 - val_loss: 0.3672 - val_acc: 0.9833\n",
      "Epoch 129/170\n",
      " - 0s - loss: 0.3658 - acc: 1.0000 - val_loss: 0.3653 - val_acc: 0.9833\n",
      "Epoch 130/170\n",
      " - 0s - loss: 0.3639 - acc: 1.0000 - val_loss: 0.3637 - val_acc: 0.9833\n",
      "Epoch 131/170\n",
      " - 0s - loss: 0.3623 - acc: 1.0000 - val_loss: 0.3617 - val_acc: 0.9833\n",
      "Epoch 132/170\n",
      " - 0s - loss: 0.3604 - acc: 1.0000 - val_loss: 0.3602 - val_acc: 0.9833\n",
      "Epoch 133/170\n",
      " - 0s - loss: 0.3586 - acc: 1.0000 - val_loss: 0.3583 - val_acc: 0.9833\n",
      "Epoch 134/170\n",
      " - 0s - loss: 0.3570 - acc: 1.0000 - val_loss: 0.3563 - val_acc: 0.9833\n",
      "Epoch 135/170\n",
      " - 0s - loss: 0.3551 - acc: 1.0000 - val_loss: 0.3546 - val_acc: 0.9833\n",
      "Epoch 136/170\n",
      " - 0s - loss: 0.3533 - acc: 1.0000 - val_loss: 0.3529 - val_acc: 0.9833\n",
      "Epoch 137/170\n",
      " - 0s - loss: 0.3516 - acc: 1.0000 - val_loss: 0.3513 - val_acc: 0.9833\n",
      "Epoch 138/170\n",
      " - 0s - loss: 0.3499 - acc: 1.0000 - val_loss: 0.3497 - val_acc: 0.9833\n",
      "Epoch 139/170\n",
      " - 0s - loss: 0.3483 - acc: 1.0000 - val_loss: 0.3479 - val_acc: 0.9833\n",
      "Epoch 140/170\n",
      " - 0s - loss: 0.3465 - acc: 1.0000 - val_loss: 0.3461 - val_acc: 0.9833\n",
      "Epoch 141/170\n",
      " - 0s - loss: 0.3449 - acc: 1.0000 - val_loss: 0.3446 - val_acc: 0.9833\n",
      "Epoch 142/170\n",
      " - 0s - loss: 0.3432 - acc: 1.0000 - val_loss: 0.3430 - val_acc: 0.9833\n",
      "Epoch 143/170\n",
      " - 0s - loss: 0.3415 - acc: 1.0000 - val_loss: 0.3414 - val_acc: 0.9833\n",
      "Epoch 144/170\n",
      " - 0s - loss: 0.3399 - acc: 1.0000 - val_loss: 0.3397 - val_acc: 0.9833\n",
      "Epoch 145/170\n",
      " - 0s - loss: 0.3383 - acc: 1.0000 - val_loss: 0.3380 - val_acc: 0.9833\n",
      "Epoch 146/170\n",
      " - 0s - loss: 0.3366 - acc: 1.0000 - val_loss: 0.3364 - val_acc: 0.9833\n",
      "Epoch 147/170\n",
      " - 0s - loss: 0.3352 - acc: 1.0000 - val_loss: 0.3346 - val_acc: 0.9833\n",
      "Epoch 148/170\n",
      " - 0s - loss: 0.3335 - acc: 1.0000 - val_loss: 0.3331 - val_acc: 0.9833\n",
      "Epoch 149/170\n",
      " - 0s - loss: 0.3318 - acc: 1.0000 - val_loss: 0.3315 - val_acc: 0.9833\n",
      "Epoch 150/170\n",
      " - 0s - loss: 0.3303 - acc: 1.0000 - val_loss: 0.3298 - val_acc: 0.9833\n",
      "Epoch 151/170\n",
      " - 0s - loss: 0.3287 - acc: 1.0000 - val_loss: 0.3282 - val_acc: 0.9833\n",
      "Epoch 152/170\n",
      " - 0s - loss: 0.3272 - acc: 1.0000 - val_loss: 0.3266 - val_acc: 0.9833\n",
      "Epoch 153/170\n",
      " - 0s - loss: 0.3256 - acc: 1.0000 - val_loss: 0.3250 - val_acc: 0.9833\n",
      "Epoch 154/170\n",
      " - 0s - loss: 0.3240 - acc: 1.0000 - val_loss: 0.3235 - val_acc: 0.9833\n",
      "Epoch 155/170\n",
      " - 0s - loss: 0.3225 - acc: 1.0000 - val_loss: 0.3220 - val_acc: 0.9833\n",
      "Epoch 156/170\n",
      " - 0s - loss: 0.3210 - acc: 1.0000 - val_loss: 0.3207 - val_acc: 0.9833\n",
      "Epoch 157/170\n",
      " - 0s - loss: 0.3195 - acc: 1.0000 - val_loss: 0.3192 - val_acc: 0.9833\n",
      "Epoch 158/170\n",
      " - 0s - loss: 0.3180 - acc: 1.0000 - val_loss: 0.3176 - val_acc: 0.9833\n",
      "Epoch 159/170\n",
      " - 0s - loss: 0.3166 - acc: 1.0000 - val_loss: 0.3161 - val_acc: 0.9833\n",
      "Epoch 160/170\n",
      " - 0s - loss: 0.3151 - acc: 1.0000 - val_loss: 0.3145 - val_acc: 0.9833\n",
      "Epoch 161/170\n",
      " - 0s - loss: 0.3136 - acc: 1.0000 - val_loss: 0.3131 - val_acc: 0.9833\n",
      "Epoch 162/170\n",
      " - 0s - loss: 0.3121 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.9833\n",
      "Epoch 163/170\n",
      " - 0s - loss: 0.3108 - acc: 1.0000 - val_loss: 0.3101 - val_acc: 0.9833\n",
      "Epoch 164/170\n",
      " - 0s - loss: 0.3093 - acc: 1.0000 - val_loss: 0.3088 - val_acc: 0.9833\n",
      "Epoch 165/170\n",
      " - 0s - loss: 0.3078 - acc: 1.0000 - val_loss: 0.3074 - val_acc: 0.9833\n",
      "Epoch 166/170\n",
      " - 0s - loss: 0.3064 - acc: 1.0000 - val_loss: 0.3059 - val_acc: 0.9833\n",
      "Epoch 167/170\n",
      " - 0s - loss: 0.3051 - acc: 1.0000 - val_loss: 0.3045 - val_acc: 0.9833\n",
      "Epoch 168/170\n",
      " - 0s - loss: 0.3036 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.9833\n",
      "Epoch 169/170\n",
      " - 0s - loss: 0.3022 - acc: 1.0000 - val_loss: 0.3017 - val_acc: 0.9833\n",
      "Epoch 170/170\n",
      " - 0s - loss: 0.3008 - acc: 1.0000 - val_loss: 0.3003 - val_acc: 0.9833\n",
      "Test accuracy: 0.9833333412806193\n",
      "Train on 40 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 0.6025 - acc: 0.5500 - val_loss: 0.5472 - val_acc: 0.5333\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.5933 - acc: 0.5500 - val_loss: 0.5400 - val_acc: 0.5333\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.5852 - acc: 0.5500 - val_loss: 0.5326 - val_acc: 0.5333\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.5768 - acc: 0.5500 - val_loss: 0.5252 - val_acc: 0.5333\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.5678 - acc: 0.5500 - val_loss: 0.5178 - val_acc: 0.5333\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.5597 - acc: 0.5500 - val_loss: 0.5105 - val_acc: 0.5333\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.5506 - acc: 0.5500 - val_loss: 0.5033 - val_acc: 0.5333\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.5427 - acc: 0.5750 - val_loss: 0.4962 - val_acc: 0.5833\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.5344 - acc: 0.5750 - val_loss: 0.4892 - val_acc: 0.5833\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.5265 - acc: 0.5750 - val_loss: 0.4824 - val_acc: 0.6000\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.5184 - acc: 0.5750 - val_loss: 0.4758 - val_acc: 0.6000\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.5101 - acc: 0.5750 - val_loss: 0.4693 - val_acc: 0.6333\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.5031 - acc: 0.5750 - val_loss: 0.4628 - val_acc: 0.6500\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4960 - acc: 0.6000 - val_loss: 0.4566 - val_acc: 0.6500\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.4880 - acc: 0.6750 - val_loss: 0.4507 - val_acc: 0.6500\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.4813 - acc: 0.7000 - val_loss: 0.4449 - val_acc: 0.7000\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.4752 - acc: 0.7000 - val_loss: 0.4392 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.4677 - acc: 0.7000 - val_loss: 0.4339 - val_acc: 0.7000\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.4619 - acc: 0.7000 - val_loss: 0.4287 - val_acc: 0.7167\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.4552 - acc: 0.7250 - val_loss: 0.4236 - val_acc: 0.7167\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4497 - acc: 0.7250 - val_loss: 0.4186 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100\n",
      " - 0s - loss: 0.4437 - acc: 0.7250 - val_loss: 0.4138 - val_acc: 0.7500\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4379 - acc: 0.7250 - val_loss: 0.4092 - val_acc: 0.7500\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4325 - acc: 0.7250 - val_loss: 0.4047 - val_acc: 0.7500\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4273 - acc: 0.7250 - val_loss: 0.4005 - val_acc: 0.8167\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4222 - acc: 0.7250 - val_loss: 0.3964 - val_acc: 0.8167\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4166 - acc: 0.7250 - val_loss: 0.3924 - val_acc: 0.8167\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4127 - acc: 0.7500 - val_loss: 0.3885 - val_acc: 0.8167\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4075 - acc: 0.7500 - val_loss: 0.3848 - val_acc: 0.8167\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4030 - acc: 0.7500 - val_loss: 0.3812 - val_acc: 0.8500\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.3987 - acc: 0.8250 - val_loss: 0.3776 - val_acc: 0.8667\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.3944 - acc: 0.8750 - val_loss: 0.3742 - val_acc: 0.9000\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.3903 - acc: 0.8750 - val_loss: 0.3710 - val_acc: 0.9000\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.3863 - acc: 0.8750 - val_loss: 0.3679 - val_acc: 0.9333\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.3824 - acc: 0.8750 - val_loss: 0.3649 - val_acc: 0.9500\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.3784 - acc: 0.9250 - val_loss: 0.3620 - val_acc: 0.9833\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.3749 - acc: 0.9250 - val_loss: 0.3591 - val_acc: 0.9833\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.3716 - acc: 0.9250 - val_loss: 0.3563 - val_acc: 0.9833\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.3682 - acc: 0.9500 - val_loss: 0.3537 - val_acc: 0.9833\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.3646 - acc: 0.9500 - val_loss: 0.3512 - val_acc: 0.9833\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.3614 - acc: 0.9500 - val_loss: 0.3488 - val_acc: 0.9833\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.3586 - acc: 0.9500 - val_loss: 0.3465 - val_acc: 0.9833\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.3558 - acc: 0.9500 - val_loss: 0.3443 - val_acc: 0.9833\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.3527 - acc: 0.9500 - val_loss: 0.3423 - val_acc: 0.9833\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.3500 - acc: 0.9500 - val_loss: 0.3402 - val_acc: 0.9833\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.3473 - acc: 0.9500 - val_loss: 0.3383 - val_acc: 0.9833\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.3447 - acc: 0.9500 - val_loss: 0.3363 - val_acc: 0.9833\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.3427 - acc: 0.9500 - val_loss: 0.3344 - val_acc: 0.9833\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.3396 - acc: 0.9750 - val_loss: 0.3327 - val_acc: 0.9833\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.3376 - acc: 0.9750 - val_loss: 0.3310 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.3353 - acc: 0.9750 - val_loss: 0.3294 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.3330 - acc: 0.9750 - val_loss: 0.3278 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.3312 - acc: 0.9750 - val_loss: 0.3263 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.3289 - acc: 1.0000 - val_loss: 0.3249 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.3271 - acc: 1.0000 - val_loss: 0.3236 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.3251 - acc: 1.0000 - val_loss: 0.3223 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.3234 - acc: 1.0000 - val_loss: 0.3210 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.3216 - acc: 1.0000 - val_loss: 0.3198 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.3201 - acc: 1.0000 - val_loss: 0.3186 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.3184 - acc: 1.0000 - val_loss: 0.3175 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.3167 - acc: 1.0000 - val_loss: 0.3165 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.3155 - acc: 1.0000 - val_loss: 0.3155 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.3137 - acc: 1.0000 - val_loss: 0.3146 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.3125 - acc: 1.0000 - val_loss: 0.3136 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.3112 - acc: 1.0000 - val_loss: 0.3127 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.3098 - acc: 1.0000 - val_loss: 0.3119 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.3085 - acc: 1.0000 - val_loss: 0.3110 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.3073 - acc: 1.0000 - val_loss: 0.3102 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.3061 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.3048 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.3037 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.3025 - acc: 1.0000 - val_loss: 0.3072 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.3015 - acc: 1.0000 - val_loss: 0.3065 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.3003 - acc: 1.0000 - val_loss: 0.3059 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.2994 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.2985 - acc: 1.0000 - val_loss: 0.3047 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.2976 - acc: 1.0000 - val_loss: 0.3041 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.2967 - acc: 1.0000 - val_loss: 0.3036 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.2957 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.2951 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.2944 - acc: 1.0000 - val_loss: 0.3021 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.2935 - acc: 1.0000 - val_loss: 0.3016 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.2929 - acc: 1.0000 - val_loss: 0.3012 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.2921 - acc: 1.0000 - val_loss: 0.3007 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.2915 - acc: 1.0000 - val_loss: 0.3003 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.2908 - acc: 1.0000 - val_loss: 0.2998 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.2901 - acc: 1.0000 - val_loss: 0.2994 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.2895 - acc: 1.0000 - val_loss: 0.2990 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.2889 - acc: 1.0000 - val_loss: 0.2986 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.2884 - acc: 1.0000 - val_loss: 0.2982 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.2877 - acc: 1.0000 - val_loss: 0.2978 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.2871 - acc: 1.0000 - val_loss: 0.2974 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.2866 - acc: 1.0000 - val_loss: 0.2970 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.2860 - acc: 1.0000 - val_loss: 0.2966 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.2855 - acc: 1.0000 - val_loss: 0.2962 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.2849 - acc: 1.0000 - val_loss: 0.2958 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.2844 - acc: 1.0000 - val_loss: 0.2954 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.2839 - acc: 1.0000 - val_loss: 0.2951 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.2833 - acc: 1.0000 - val_loss: 0.2947 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.2828 - acc: 1.0000 - val_loss: 0.2943 - val_acc: 1.0000\n",
      "Test accuracy: 1.0\n",
      "Train on 40 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 1.3511 - acc: 0.0000e+00 - val_loss: 1.3797 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.3415 - acc: 0.0000e+00 - val_loss: 1.3728 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.3321 - acc: 0.0000e+00 - val_loss: 1.3651 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.3223 - acc: 0.0250 - val_loss: 1.3571 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.3115 - acc: 0.0250 - val_loss: 1.3488 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.3020 - acc: 0.0250 - val_loss: 1.3407 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.2903 - acc: 0.0250 - val_loss: 1.3323 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1.2808 - acc: 0.0250 - val_loss: 1.3238 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1.2702 - acc: 0.0250 - val_loss: 1.3153 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.2614 - acc: 0.0250 - val_loss: 1.3070 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1.2522 - acc: 0.0750 - val_loss: 1.2989 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1.2427 - acc: 0.0500 - val_loss: 1.2902 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1.2316 - acc: 0.0750 - val_loss: 1.2818 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.2253 - acc: 0.0750 - val_loss: 1.2739 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.2142 - acc: 0.0750 - val_loss: 1.2657 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.2061 - acc: 0.0750 - val_loss: 1.2573 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      " - 0s - loss: 1.1967 - acc: 0.0750 - val_loss: 1.2488 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1.1883 - acc: 0.0750 - val_loss: 1.2404 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1.1788 - acc: 0.1000 - val_loss: 1.2319 - val_acc: 0.0167\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1.1717 - acc: 0.0750 - val_loss: 1.2234 - val_acc: 0.0167\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1.1620 - acc: 0.1000 - val_loss: 1.2151 - val_acc: 0.0333\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1.1535 - acc: 0.1000 - val_loss: 1.2066 - val_acc: 0.0500\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1.1465 - acc: 0.1250 - val_loss: 1.1988 - val_acc: 0.0667\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.1362 - acc: 0.1250 - val_loss: 1.1905 - val_acc: 0.0833\n",
      "Epoch 25/100\n",
      " - 0s - loss: 1.1277 - acc: 0.1250 - val_loss: 1.1823 - val_acc: 0.1000\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.1202 - acc: 0.1250 - val_loss: 1.1739 - val_acc: 0.1333\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1.1120 - acc: 0.1250 - val_loss: 1.1655 - val_acc: 0.1333\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1.1048 - acc: 0.1250 - val_loss: 1.1569 - val_acc: 0.1333\n",
      "Epoch 29/100\n",
      " - 0s - loss: 1.0952 - acc: 0.1250 - val_loss: 1.1485 - val_acc: 0.1333\n",
      "Epoch 30/100\n",
      " - 0s - loss: 1.0867 - acc: 0.1250 - val_loss: 1.1402 - val_acc: 0.1333\n",
      "Epoch 31/100\n",
      " - 0s - loss: 1.0803 - acc: 0.1750 - val_loss: 1.1323 - val_acc: 0.1667\n",
      "Epoch 32/100\n",
      " - 0s - loss: 1.0716 - acc: 0.2000 - val_loss: 1.1243 - val_acc: 0.1667\n",
      "Epoch 33/100\n",
      " - 0s - loss: 1.0628 - acc: 0.2000 - val_loss: 1.1158 - val_acc: 0.1667\n",
      "Epoch 34/100\n",
      " - 0s - loss: 1.0558 - acc: 0.2000 - val_loss: 1.1073 - val_acc: 0.1833\n",
      "Epoch 35/100\n",
      " - 0s - loss: 1.0486 - acc: 0.2250 - val_loss: 1.0992 - val_acc: 0.2500\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.0402 - acc: 0.2250 - val_loss: 1.0909 - val_acc: 0.2667\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.0335 - acc: 0.2250 - val_loss: 1.0830 - val_acc: 0.2667\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.0239 - acc: 0.2750 - val_loss: 1.0751 - val_acc: 0.2667\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.0177 - acc: 0.2500 - val_loss: 1.0670 - val_acc: 0.2667\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.0093 - acc: 0.3250 - val_loss: 1.0593 - val_acc: 0.3167\n",
      "Epoch 41/100\n",
      " - 0s - loss: 1.0015 - acc: 0.3500 - val_loss: 1.0515 - val_acc: 0.3333\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.9939 - acc: 0.3500 - val_loss: 1.0437 - val_acc: 0.3500\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.9875 - acc: 0.3500 - val_loss: 1.0357 - val_acc: 0.3667\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.9783 - acc: 0.3750 - val_loss: 1.0281 - val_acc: 0.3833\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.9713 - acc: 0.3750 - val_loss: 1.0202 - val_acc: 0.4000\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.9650 - acc: 0.4250 - val_loss: 1.0127 - val_acc: 0.4000\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.9567 - acc: 0.4500 - val_loss: 1.0052 - val_acc: 0.4000\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.9504 - acc: 0.4500 - val_loss: 0.9977 - val_acc: 0.4000\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.9422 - acc: 0.4500 - val_loss: 0.9900 - val_acc: 0.4000\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.9351 - acc: 0.4750 - val_loss: 0.9824 - val_acc: 0.4000\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.9279 - acc: 0.4750 - val_loss: 0.9749 - val_acc: 0.4167\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.9212 - acc: 0.4750 - val_loss: 0.9673 - val_acc: 0.4167\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.9142 - acc: 0.4750 - val_loss: 0.9598 - val_acc: 0.4167\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.9070 - acc: 0.4750 - val_loss: 0.9522 - val_acc: 0.4167\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.8993 - acc: 0.4750 - val_loss: 0.9450 - val_acc: 0.4167\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.8924 - acc: 0.5250 - val_loss: 0.9378 - val_acc: 0.4167\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.8865 - acc: 0.5250 - val_loss: 0.9305 - val_acc: 0.4333\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.8787 - acc: 0.5250 - val_loss: 0.9232 - val_acc: 0.4333\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.8721 - acc: 0.5250 - val_loss: 0.9158 - val_acc: 0.4333\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.8658 - acc: 0.5250 - val_loss: 0.9086 - val_acc: 0.4333\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.8598 - acc: 0.5250 - val_loss: 0.9016 - val_acc: 0.4500\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.8520 - acc: 0.5250 - val_loss: 0.8945 - val_acc: 0.4500\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.8464 - acc: 0.5250 - val_loss: 0.8878 - val_acc: 0.4500\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.8401 - acc: 0.5500 - val_loss: 0.8808 - val_acc: 0.4667\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.8324 - acc: 0.5500 - val_loss: 0.8737 - val_acc: 0.4667\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.8254 - acc: 0.5500 - val_loss: 0.8669 - val_acc: 0.4667\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.8198 - acc: 0.5500 - val_loss: 0.8599 - val_acc: 0.4667\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.8124 - acc: 0.5500 - val_loss: 0.8532 - val_acc: 0.4667\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.8065 - acc: 0.5500 - val_loss: 0.8464 - val_acc: 0.4667\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.7997 - acc: 0.5500 - val_loss: 0.8399 - val_acc: 0.4667\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.7936 - acc: 0.5500 - val_loss: 0.8334 - val_acc: 0.4667\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.7873 - acc: 0.5500 - val_loss: 0.8268 - val_acc: 0.4667\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.7822 - acc: 0.5500 - val_loss: 0.8204 - val_acc: 0.4667\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.7751 - acc: 0.5500 - val_loss: 0.8138 - val_acc: 0.4667\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.7686 - acc: 0.5500 - val_loss: 0.8072 - val_acc: 0.4667\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.7634 - acc: 0.5500 - val_loss: 0.8006 - val_acc: 0.4667\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.7574 - acc: 0.5500 - val_loss: 0.7942 - val_acc: 0.4667\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.7508 - acc: 0.5500 - val_loss: 0.7879 - val_acc: 0.4667\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.7449 - acc: 0.5500 - val_loss: 0.7816 - val_acc: 0.4667\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.7389 - acc: 0.5500 - val_loss: 0.7754 - val_acc: 0.4667\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.7343 - acc: 0.5500 - val_loss: 0.7695 - val_acc: 0.4667\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.7273 - acc: 0.5500 - val_loss: 0.7631 - val_acc: 0.4667\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.7229 - acc: 0.5500 - val_loss: 0.7572 - val_acc: 0.4667\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.7160 - acc: 0.5500 - val_loss: 0.7511 - val_acc: 0.4667\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.7099 - acc: 0.5500 - val_loss: 0.7451 - val_acc: 0.4667\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.7055 - acc: 0.5500 - val_loss: 0.7389 - val_acc: 0.4667\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.6987 - acc: 0.5500 - val_loss: 0.7331 - val_acc: 0.4667\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.6940 - acc: 0.5500 - val_loss: 0.7272 - val_acc: 0.4667\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.6885 - acc: 0.5500 - val_loss: 0.7214 - val_acc: 0.4667\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.6831 - acc: 0.5500 - val_loss: 0.7157 - val_acc: 0.4667\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.6774 - acc: 0.5500 - val_loss: 0.7100 - val_acc: 0.4667\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.6723 - acc: 0.5500 - val_loss: 0.7044 - val_acc: 0.4667\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.6673 - acc: 0.5500 - val_loss: 0.6989 - val_acc: 0.4667\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.6610 - acc: 0.5500 - val_loss: 0.6936 - val_acc: 0.4667\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.6562 - acc: 0.5500 - val_loss: 0.6882 - val_acc: 0.4667\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.6507 - acc: 0.5500 - val_loss: 0.6829 - val_acc: 0.4667\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.6457 - acc: 0.5500 - val_loss: 0.6775 - val_acc: 0.4667\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.6412 - acc: 0.5500 - val_loss: 0.6723 - val_acc: 0.4667\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.6355 - acc: 0.5500 - val_loss: 0.6670 - val_acc: 0.4667\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.6313 - acc: 0.5500 - val_loss: 0.6618 - val_acc: 0.4667\n",
      "Test accuracy: 0.4666666626930237\n",
      "Train on 40 samples, validate on 60 samples\n",
      "Epoch 1/170\n",
      " - 0s - loss: 2.5387 - acc: 0.5500 - val_loss: 2.9085 - val_acc: 0.4667\n",
      "Epoch 2/170\n",
      " - 0s - loss: 2.5212 - acc: 0.5500 - val_loss: 2.8939 - val_acc: 0.4667\n",
      "Epoch 3/170\n",
      " - 0s - loss: 2.5081 - acc: 0.5500 - val_loss: 2.8771 - val_acc: 0.4667\n",
      "Epoch 4/170\n",
      " - 0s - loss: 2.4935 - acc: 0.5500 - val_loss: 2.8592 - val_acc: 0.4667\n",
      "Epoch 5/170\n",
      " - 0s - loss: 2.4774 - acc: 0.5500 - val_loss: 2.8392 - val_acc: 0.4667\n",
      "Epoch 6/170\n",
      " - 0s - loss: 2.4605 - acc: 0.5500 - val_loss: 2.8196 - val_acc: 0.4667\n",
      "Epoch 7/170\n",
      " - 0s - loss: 2.4444 - acc: 0.5500 - val_loss: 2.8016 - val_acc: 0.4667\n",
      "Epoch 8/170\n",
      " - 0s - loss: 2.4270 - acc: 0.5500 - val_loss: 2.7791 - val_acc: 0.4667\n",
      "Epoch 9/170\n",
      " - 0s - loss: 2.4093 - acc: 0.5500 - val_loss: 2.7602 - val_acc: 0.4667\n",
      "Epoch 10/170\n",
      " - 0s - loss: 2.3920 - acc: 0.5500 - val_loss: 2.7392 - val_acc: 0.4667\n",
      "Epoch 11/170\n",
      " - 0s - loss: 2.3736 - acc: 0.5500 - val_loss: 2.7176 - val_acc: 0.4667\n",
      "Epoch 12/170\n",
      " - 0s - loss: 2.3560 - acc: 0.5500 - val_loss: 2.6978 - val_acc: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/170\n",
      " - 0s - loss: 2.3368 - acc: 0.5500 - val_loss: 2.6734 - val_acc: 0.4667\n",
      "Epoch 14/170\n",
      " - 0s - loss: 2.3162 - acc: 0.5500 - val_loss: 2.6503 - val_acc: 0.4667\n",
      "Epoch 15/170\n",
      " - 0s - loss: 2.2964 - acc: 0.5500 - val_loss: 2.6275 - val_acc: 0.4667\n",
      "Epoch 16/170\n",
      " - 0s - loss: 2.2765 - acc: 0.5500 - val_loss: 2.6043 - val_acc: 0.4667\n",
      "Epoch 17/170\n",
      " - 0s - loss: 2.2569 - acc: 0.5500 - val_loss: 2.5820 - val_acc: 0.4667\n",
      "Epoch 18/170\n",
      " - 0s - loss: 2.2378 - acc: 0.5500 - val_loss: 2.5600 - val_acc: 0.4667\n",
      "Epoch 19/170\n",
      " - 0s - loss: 2.2197 - acc: 0.5500 - val_loss: 2.5398 - val_acc: 0.4667\n",
      "Epoch 20/170\n",
      " - 0s - loss: 2.2008 - acc: 0.5500 - val_loss: 2.5170 - val_acc: 0.4667\n",
      "Epoch 21/170\n",
      " - 0s - loss: 2.1810 - acc: 0.5500 - val_loss: 2.4939 - val_acc: 0.4667\n",
      "Epoch 22/170\n",
      " - 0s - loss: 2.1607 - acc: 0.5500 - val_loss: 2.4699 - val_acc: 0.4667\n",
      "Epoch 23/170\n",
      " - 0s - loss: 2.1403 - acc: 0.5500 - val_loss: 2.4468 - val_acc: 0.4667\n",
      "Epoch 24/170\n",
      " - 0s - loss: 2.1208 - acc: 0.5500 - val_loss: 2.4247 - val_acc: 0.4667\n",
      "Epoch 25/170\n",
      " - 0s - loss: 2.1011 - acc: 0.5500 - val_loss: 2.4015 - val_acc: 0.4667\n",
      "Epoch 26/170\n",
      " - 0s - loss: 2.0807 - acc: 0.5500 - val_loss: 2.3773 - val_acc: 0.4667\n",
      "Epoch 27/170\n",
      " - 0s - loss: 2.0606 - acc: 0.5500 - val_loss: 2.3550 - val_acc: 0.4667\n",
      "Epoch 28/170\n",
      " - 0s - loss: 2.0415 - acc: 0.5500 - val_loss: 2.3330 - val_acc: 0.4667\n",
      "Epoch 29/170\n",
      " - 0s - loss: 2.0224 - acc: 0.5500 - val_loss: 2.3110 - val_acc: 0.4667\n",
      "Epoch 30/170\n",
      " - 0s - loss: 2.0034 - acc: 0.5500 - val_loss: 2.2891 - val_acc: 0.4667\n",
      "Epoch 31/170\n",
      " - 0s - loss: 1.9843 - acc: 0.5500 - val_loss: 2.2670 - val_acc: 0.4667\n",
      "Epoch 32/170\n",
      " - 0s - loss: 1.9654 - acc: 0.5500 - val_loss: 2.2452 - val_acc: 0.4667\n",
      "Epoch 33/170\n",
      " - 0s - loss: 1.9470 - acc: 0.5500 - val_loss: 2.2243 - val_acc: 0.4667\n",
      "Epoch 34/170\n",
      " - 0s - loss: 1.9290 - acc: 0.5500 - val_loss: 2.2037 - val_acc: 0.4667\n",
      "Epoch 35/170\n",
      " - 0s - loss: 1.9113 - acc: 0.5500 - val_loss: 2.1833 - val_acc: 0.4667\n",
      "Epoch 36/170\n",
      " - 0s - loss: 1.8935 - acc: 0.5500 - val_loss: 2.1628 - val_acc: 0.4667\n",
      "Epoch 37/170\n",
      " - 0s - loss: 1.8753 - acc: 0.5500 - val_loss: 2.1413 - val_acc: 0.4667\n",
      "Epoch 38/170\n",
      " - 0s - loss: 1.8568 - acc: 0.5500 - val_loss: 2.1200 - val_acc: 0.4667\n",
      "Epoch 39/170\n",
      " - 0s - loss: 1.8380 - acc: 0.5500 - val_loss: 2.0977 - val_acc: 0.4667\n",
      "Epoch 40/170\n",
      " - 0s - loss: 1.8192 - acc: 0.5500 - val_loss: 2.0762 - val_acc: 0.4667\n",
      "Epoch 41/170\n",
      " - 0s - loss: 1.8001 - acc: 0.5500 - val_loss: 2.0537 - val_acc: 0.4667\n",
      "Epoch 42/170\n",
      " - 0s - loss: 1.7817 - acc: 0.5500 - val_loss: 2.0331 - val_acc: 0.4667\n",
      "Epoch 43/170\n",
      " - 0s - loss: 1.7635 - acc: 0.5500 - val_loss: 2.0119 - val_acc: 0.4667\n",
      "Epoch 44/170\n",
      " - 0s - loss: 1.7447 - acc: 0.5500 - val_loss: 1.9896 - val_acc: 0.4667\n",
      "Epoch 45/170\n",
      " - 0s - loss: 1.7255 - acc: 0.5500 - val_loss: 1.9674 - val_acc: 0.4667\n",
      "Epoch 46/170\n",
      " - 0s - loss: 1.7063 - acc: 0.5500 - val_loss: 1.9449 - val_acc: 0.4667\n",
      "Epoch 47/170\n",
      " - 0s - loss: 1.6875 - acc: 0.5500 - val_loss: 1.9237 - val_acc: 0.4667\n",
      "Epoch 48/170\n",
      " - 0s - loss: 1.6687 - acc: 0.5500 - val_loss: 1.9015 - val_acc: 0.4667\n",
      "Epoch 49/170\n",
      " - 0s - loss: 1.6494 - acc: 0.5500 - val_loss: 1.8787 - val_acc: 0.4667\n",
      "Epoch 50/170\n",
      " - 0s - loss: 1.6309 - acc: 0.5500 - val_loss: 1.8585 - val_acc: 0.4667\n",
      "Epoch 51/170\n",
      " - 0s - loss: 1.6126 - acc: 0.5500 - val_loss: 1.8366 - val_acc: 0.4667\n",
      "Epoch 52/170\n",
      " - 0s - loss: 1.5938 - acc: 0.5500 - val_loss: 1.8148 - val_acc: 0.4667\n",
      "Epoch 53/170\n",
      " - 0s - loss: 1.5760 - acc: 0.5500 - val_loss: 1.7949 - val_acc: 0.4667\n",
      "Epoch 54/170\n",
      " - 0s - loss: 1.5590 - acc: 0.5500 - val_loss: 1.7755 - val_acc: 0.4667\n",
      "Epoch 55/170\n",
      " - 0s - loss: 1.5417 - acc: 0.5500 - val_loss: 1.7551 - val_acc: 0.4667\n",
      "Epoch 56/170\n",
      " - 0s - loss: 1.5247 - acc: 0.5500 - val_loss: 1.7359 - val_acc: 0.4667\n",
      "Epoch 57/170\n",
      " - 0s - loss: 1.5089 - acc: 0.5500 - val_loss: 1.7181 - val_acc: 0.4667\n",
      "Epoch 58/170\n",
      " - 0s - loss: 1.4915 - acc: 0.5500 - val_loss: 1.6958 - val_acc: 0.4667\n",
      "Epoch 59/170\n",
      " - 0s - loss: 1.4733 - acc: 0.5500 - val_loss: 1.6758 - val_acc: 0.4667\n",
      "Epoch 60/170\n",
      " - 0s - loss: 1.4559 - acc: 0.5500 - val_loss: 1.6553 - val_acc: 0.4667\n",
      "Epoch 61/170\n",
      " - 0s - loss: 1.4393 - acc: 0.5500 - val_loss: 1.6368 - val_acc: 0.4667\n",
      "Epoch 62/170\n",
      " - 0s - loss: 1.4230 - acc: 0.5500 - val_loss: 1.6176 - val_acc: 0.4667\n",
      "Epoch 63/170\n",
      " - 0s - loss: 1.4066 - acc: 0.5500 - val_loss: 1.5986 - val_acc: 0.4667\n",
      "Epoch 64/170\n",
      " - 0s - loss: 1.3903 - acc: 0.5500 - val_loss: 1.5797 - val_acc: 0.4667\n",
      "Epoch 65/170\n",
      " - 0s - loss: 1.3737 - acc: 0.5500 - val_loss: 1.5599 - val_acc: 0.4667\n",
      "Epoch 66/170\n",
      " - 0s - loss: 1.3574 - acc: 0.5500 - val_loss: 1.5414 - val_acc: 0.4667\n",
      "Epoch 67/170\n",
      " - 0s - loss: 1.3408 - acc: 0.5500 - val_loss: 1.5211 - val_acc: 0.4667\n",
      "Epoch 68/170\n",
      " - 0s - loss: 1.3239 - acc: 0.5500 - val_loss: 1.5019 - val_acc: 0.4667\n",
      "Epoch 69/170\n",
      " - 0s - loss: 1.3075 - acc: 0.5500 - val_loss: 1.4826 - val_acc: 0.4667\n",
      "Epoch 70/170\n",
      " - 0s - loss: 1.2912 - acc: 0.5500 - val_loss: 1.4635 - val_acc: 0.4667\n",
      "Epoch 71/170\n",
      " - 0s - loss: 1.2751 - acc: 0.5500 - val_loss: 1.4449 - val_acc: 0.4667\n",
      "Epoch 72/170\n",
      " - 0s - loss: 1.2601 - acc: 0.5500 - val_loss: 1.4280 - val_acc: 0.4667\n",
      "Epoch 73/170\n",
      " - 0s - loss: 1.2444 - acc: 0.5500 - val_loss: 1.4081 - val_acc: 0.4667\n",
      "Epoch 74/170\n",
      " - 0s - loss: 1.2281 - acc: 0.5500 - val_loss: 1.3899 - val_acc: 0.4667\n",
      "Epoch 75/170\n",
      " - 0s - loss: 1.2129 - acc: 0.5500 - val_loss: 1.3722 - val_acc: 0.4667\n",
      "Epoch 76/170\n",
      " - 0s - loss: 1.1980 - acc: 0.5500 - val_loss: 1.3546 - val_acc: 0.4667\n",
      "Epoch 77/170\n",
      " - 0s - loss: 1.1828 - acc: 0.5500 - val_loss: 1.3364 - val_acc: 0.4667\n",
      "Epoch 78/170\n",
      " - 0s - loss: 1.1684 - acc: 0.5500 - val_loss: 1.3204 - val_acc: 0.4667\n",
      "Epoch 79/170\n",
      " - 0s - loss: 1.1550 - acc: 0.5500 - val_loss: 1.3046 - val_acc: 0.4667\n",
      "Epoch 80/170\n",
      " - 0s - loss: 1.1422 - acc: 0.5500 - val_loss: 1.2900 - val_acc: 0.4667\n",
      "Epoch 81/170\n",
      " - 0s - loss: 1.1292 - acc: 0.5500 - val_loss: 1.2742 - val_acc: 0.4667\n",
      "Epoch 82/170\n",
      " - 0s - loss: 1.1161 - acc: 0.5500 - val_loss: 1.2589 - val_acc: 0.4667\n",
      "Epoch 83/170\n",
      " - 0s - loss: 1.1033 - acc: 0.5500 - val_loss: 1.2436 - val_acc: 0.4667\n",
      "Epoch 84/170\n",
      " - 0s - loss: 1.0920 - acc: 0.5500 - val_loss: 1.2311 - val_acc: 0.4667\n",
      "Epoch 85/170\n",
      " - 0s - loss: 1.0811 - acc: 0.5500 - val_loss: 1.2184 - val_acc: 0.4667\n",
      "Epoch 86/170\n",
      " - 0s - loss: 1.0694 - acc: 0.5500 - val_loss: 1.2036 - val_acc: 0.4667\n",
      "Epoch 87/170\n",
      " - 0s - loss: 1.0588 - acc: 0.5500 - val_loss: 1.1922 - val_acc: 0.4667\n",
      "Epoch 88/170\n",
      " - 0s - loss: 1.0479 - acc: 0.5500 - val_loss: 1.1782 - val_acc: 0.4667\n",
      "Epoch 89/170\n",
      " - 0s - loss: 1.0363 - acc: 0.5500 - val_loss: 1.1640 - val_acc: 0.4667\n",
      "Epoch 90/170\n",
      " - 0s - loss: 1.0262 - acc: 0.5500 - val_loss: 1.1532 - val_acc: 0.4667\n",
      "Epoch 91/170\n",
      " - 0s - loss: 1.0164 - acc: 0.5500 - val_loss: 1.1413 - val_acc: 0.4667\n",
      "Epoch 92/170\n",
      " - 0s - loss: 1.0067 - acc: 0.5500 - val_loss: 1.1298 - val_acc: 0.4667\n",
      "Epoch 93/170\n",
      " - 0s - loss: 0.9968 - acc: 0.5500 - val_loss: 1.1173 - val_acc: 0.4667\n",
      "Epoch 94/170\n",
      " - 0s - loss: 0.9867 - acc: 0.5500 - val_loss: 1.1054 - val_acc: 0.4667\n",
      "Epoch 95/170\n",
      " - 0s - loss: 0.9767 - acc: 0.5500 - val_loss: 1.0928 - val_acc: 0.4667\n",
      "Epoch 96/170\n",
      " - 0s - loss: 0.9671 - acc: 0.5500 - val_loss: 1.0819 - val_acc: 0.4667\n",
      "Epoch 97/170\n",
      " - 0s - loss: 0.9583 - acc: 0.5500 - val_loss: 1.0714 - val_acc: 0.4667\n",
      "Epoch 98/170\n",
      " - 0s - loss: 0.9495 - acc: 0.5500 - val_loss: 1.0605 - val_acc: 0.4667\n",
      "Epoch 99/170\n",
      " - 0s - loss: 0.9403 - acc: 0.5500 - val_loss: 1.0486 - val_acc: 0.4667\n",
      "Epoch 100/170\n",
      " - 0s - loss: 0.9318 - acc: 0.5500 - val_loss: 1.0394 - val_acc: 0.4667\n",
      "Epoch 101/170\n",
      " - 0s - loss: 0.9240 - acc: 0.5500 - val_loss: 1.0299 - val_acc: 0.4667\n",
      "Epoch 102/170\n",
      " - 0s - loss: 0.9165 - acc: 0.5500 - val_loss: 1.0209 - val_acc: 0.4667\n",
      "Epoch 103/170\n",
      " - 0s - loss: 0.9088 - acc: 0.5500 - val_loss: 1.0113 - val_acc: 0.4667\n",
      "Epoch 104/170\n",
      " - 0s - loss: 0.9008 - acc: 0.5500 - val_loss: 1.0005 - val_acc: 0.4667\n",
      "Epoch 105/170\n",
      " - 0s - loss: 0.8926 - acc: 0.5500 - val_loss: 0.9912 - val_acc: 0.4667\n",
      "Epoch 106/170\n",
      " - 0s - loss: 0.8850 - acc: 0.5500 - val_loss: 0.9816 - val_acc: 0.4667\n",
      "Epoch 107/170\n",
      " - 0s - loss: 0.8782 - acc: 0.5500 - val_loss: 0.9739 - val_acc: 0.4667\n",
      "Epoch 108/170\n",
      " - 0s - loss: 0.8715 - acc: 0.5500 - val_loss: 0.9654 - val_acc: 0.4667\n",
      "Epoch 109/170\n",
      " - 0s - loss: 0.8648 - acc: 0.5500 - val_loss: 0.9572 - val_acc: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/170\n",
      " - 0s - loss: 0.8588 - acc: 0.5500 - val_loss: 0.9503 - val_acc: 0.4667\n",
      "Epoch 111/170\n",
      " - 0s - loss: 0.8525 - acc: 0.5500 - val_loss: 0.9421 - val_acc: 0.4667\n",
      "Epoch 112/170\n",
      " - 0s - loss: 0.8462 - acc: 0.5500 - val_loss: 0.9346 - val_acc: 0.4667\n",
      "Epoch 113/170\n",
      " - 0s - loss: 0.8404 - acc: 0.5500 - val_loss: 0.9276 - val_acc: 0.4667\n",
      "Epoch 114/170\n",
      " - 0s - loss: 0.8355 - acc: 0.5500 - val_loss: 0.9221 - val_acc: 0.4667\n",
      "Epoch 115/170\n",
      " - 0s - loss: 0.8298 - acc: 0.5500 - val_loss: 0.9147 - val_acc: 0.4667\n",
      "Epoch 116/170\n",
      " - 0s - loss: 0.8243 - acc: 0.5500 - val_loss: 0.9084 - val_acc: 0.4667\n",
      "Epoch 117/170\n",
      " - 0s - loss: 0.8187 - acc: 0.5500 - val_loss: 0.9007 - val_acc: 0.4667\n",
      "Epoch 118/170\n",
      " - 0s - loss: 0.8129 - acc: 0.5500 - val_loss: 0.8940 - val_acc: 0.4667\n",
      "Epoch 119/170\n",
      " - 0s - loss: 0.8075 - acc: 0.5500 - val_loss: 0.8874 - val_acc: 0.4667\n",
      "Epoch 120/170\n",
      " - 0s - loss: 0.8021 - acc: 0.5500 - val_loss: 0.8804 - val_acc: 0.4667\n",
      "Epoch 121/170\n",
      " - 0s - loss: 0.7973 - acc: 0.5500 - val_loss: 0.8750 - val_acc: 0.4667\n",
      "Epoch 122/170\n",
      " - 0s - loss: 0.7922 - acc: 0.5500 - val_loss: 0.8684 - val_acc: 0.4667\n",
      "Epoch 123/170\n",
      " - 0s - loss: 0.7878 - acc: 0.5500 - val_loss: 0.8638 - val_acc: 0.4667\n",
      "Epoch 124/170\n",
      " - 0s - loss: 0.7830 - acc: 0.5500 - val_loss: 0.8567 - val_acc: 0.4667\n",
      "Epoch 125/170\n",
      " - 0s - loss: 0.7778 - acc: 0.5500 - val_loss: 0.8513 - val_acc: 0.4667\n",
      "Epoch 126/170\n",
      " - 0s - loss: 0.7733 - acc: 0.5500 - val_loss: 0.8462 - val_acc: 0.4667\n",
      "Epoch 127/170\n",
      " - 0s - loss: 0.7690 - acc: 0.5500 - val_loss: 0.8411 - val_acc: 0.4667\n",
      "Epoch 128/170\n",
      " - 0s - loss: 0.7647 - acc: 0.5500 - val_loss: 0.8358 - val_acc: 0.4667\n",
      "Epoch 129/170\n",
      " - 0s - loss: 0.7602 - acc: 0.5500 - val_loss: 0.8300 - val_acc: 0.4667\n",
      "Epoch 130/170\n",
      " - 0s - loss: 0.7557 - acc: 0.5500 - val_loss: 0.8247 - val_acc: 0.4667\n",
      "Epoch 131/170\n",
      " - 0s - loss: 0.7515 - acc: 0.5500 - val_loss: 0.8199 - val_acc: 0.4667\n",
      "Epoch 132/170\n",
      " - 0s - loss: 0.7472 - acc: 0.5500 - val_loss: 0.8147 - val_acc: 0.4667\n",
      "Epoch 133/170\n",
      " - 0s - loss: 0.7430 - acc: 0.5500 - val_loss: 0.8093 - val_acc: 0.4667\n",
      "Epoch 134/170\n",
      " - 0s - loss: 0.7387 - acc: 0.5500 - val_loss: 0.8043 - val_acc: 0.4667\n",
      "Epoch 135/170\n",
      " - 0s - loss: 0.7347 - acc: 0.5500 - val_loss: 0.7999 - val_acc: 0.4667\n",
      "Epoch 136/170\n",
      " - 0s - loss: 0.7307 - acc: 0.5500 - val_loss: 0.7951 - val_acc: 0.4667\n",
      "Epoch 137/170\n",
      " - 0s - loss: 0.7268 - acc: 0.5500 - val_loss: 0.7907 - val_acc: 0.4667\n",
      "Epoch 138/170\n",
      " - 0s - loss: 0.7232 - acc: 0.5500 - val_loss: 0.7868 - val_acc: 0.4667\n",
      "Epoch 139/170\n",
      " - 0s - loss: 0.7194 - acc: 0.5500 - val_loss: 0.7824 - val_acc: 0.4667\n",
      "Epoch 140/170\n",
      " - 0s - loss: 0.7157 - acc: 0.5500 - val_loss: 0.7769 - val_acc: 0.4667\n",
      "Epoch 141/170\n",
      " - 0s - loss: 0.7113 - acc: 0.5500 - val_loss: 0.7721 - val_acc: 0.4667\n",
      "Epoch 142/170\n",
      " - 0s - loss: 0.7073 - acc: 0.5500 - val_loss: 0.7675 - val_acc: 0.4667\n",
      "Epoch 143/170\n",
      " - 0s - loss: 0.7037 - acc: 0.5500 - val_loss: 0.7621 - val_acc: 0.4667\n",
      "Epoch 144/170\n",
      " - 0s - loss: 0.6997 - acc: 0.5500 - val_loss: 0.7583 - val_acc: 0.4667\n",
      "Epoch 145/170\n",
      " - 0s - loss: 0.6960 - acc: 0.5500 - val_loss: 0.7534 - val_acc: 0.4667\n",
      "Epoch 146/170\n",
      " - 0s - loss: 0.6921 - acc: 0.5500 - val_loss: 0.7488 - val_acc: 0.4667\n",
      "Epoch 147/170\n",
      " - 0s - loss: 0.6887 - acc: 0.5500 - val_loss: 0.7452 - val_acc: 0.4667\n",
      "Epoch 148/170\n",
      " - 0s - loss: 0.6853 - acc: 0.5500 - val_loss: 0.7417 - val_acc: 0.4667\n",
      "Epoch 149/170\n",
      " - 0s - loss: 0.6818 - acc: 0.5500 - val_loss: 0.7381 - val_acc: 0.4667\n",
      "Epoch 150/170\n",
      " - 0s - loss: 0.6788 - acc: 0.5500 - val_loss: 0.7351 - val_acc: 0.4667\n",
      "Epoch 151/170\n",
      " - 0s - loss: 0.6758 - acc: 0.5500 - val_loss: 0.7324 - val_acc: 0.4667\n",
      "Epoch 152/170\n",
      " - 0s - loss: 0.6725 - acc: 0.5500 - val_loss: 0.7289 - val_acc: 0.4667\n",
      "Epoch 153/170\n",
      " - 0s - loss: 0.6693 - acc: 0.5500 - val_loss: 0.7255 - val_acc: 0.4667\n",
      "Epoch 154/170\n",
      " - 0s - loss: 0.6661 - acc: 0.5500 - val_loss: 0.7222 - val_acc: 0.4667\n",
      "Epoch 155/170\n",
      " - 0s - loss: 0.6630 - acc: 0.5500 - val_loss: 0.7186 - val_acc: 0.4667\n",
      "Epoch 156/170\n",
      " - 0s - loss: 0.6597 - acc: 0.5500 - val_loss: 0.7145 - val_acc: 0.4667\n",
      "Epoch 157/170\n",
      " - 0s - loss: 0.6564 - acc: 0.5500 - val_loss: 0.7111 - val_acc: 0.4667\n",
      "Epoch 158/170\n",
      " - 0s - loss: 0.6532 - acc: 0.5500 - val_loss: 0.7077 - val_acc: 0.4667\n",
      "Epoch 159/170\n",
      " - 0s - loss: 0.6500 - acc: 0.5500 - val_loss: 0.7041 - val_acc: 0.4667\n",
      "Epoch 160/170\n",
      " - 0s - loss: 0.6468 - acc: 0.5500 - val_loss: 0.7004 - val_acc: 0.4667\n",
      "Epoch 161/170\n",
      " - 0s - loss: 0.6438 - acc: 0.5500 - val_loss: 0.6973 - val_acc: 0.4667\n",
      "Epoch 162/170\n",
      " - 0s - loss: 0.6407 - acc: 0.5500 - val_loss: 0.6940 - val_acc: 0.4667\n",
      "Epoch 163/170\n",
      " - 0s - loss: 0.6377 - acc: 0.5500 - val_loss: 0.6908 - val_acc: 0.4667\n",
      "Epoch 164/170\n",
      " - 0s - loss: 0.6346 - acc: 0.5500 - val_loss: 0.6873 - val_acc: 0.4667\n",
      "Epoch 165/170\n",
      " - 0s - loss: 0.6316 - acc: 0.5500 - val_loss: 0.6843 - val_acc: 0.4667\n",
      "Epoch 166/170\n",
      " - 0s - loss: 0.6286 - acc: 0.5500 - val_loss: 0.6808 - val_acc: 0.4667\n",
      "Epoch 167/170\n",
      " - 0s - loss: 0.6255 - acc: 0.5500 - val_loss: 0.6770 - val_acc: 0.4667\n",
      "Epoch 168/170\n",
      " - 0s - loss: 0.6225 - acc: 0.5500 - val_loss: 0.6740 - val_acc: 0.4667\n",
      "Epoch 169/170\n",
      " - 0s - loss: 0.6195 - acc: 0.5500 - val_loss: 0.6702 - val_acc: 0.4667\n",
      "Epoch 170/170\n",
      " - 0s - loss: 0.6163 - acc: 0.5500 - val_loss: 0.6668 - val_acc: 0.4667\n",
      "Test accuracy: 0.4666666626930237\n",
      "Train on 40 samples, validate on 60 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 2.2162 - acc: 0.5500 - val_loss: 2.5267 - val_acc: 0.4667\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.1981 - acc: 0.5500 - val_loss: 2.5105 - val_acc: 0.4667\n",
      "Epoch 3/100\n",
      " - 0s - loss: 2.1840 - acc: 0.5500 - val_loss: 2.4935 - val_acc: 0.4667\n",
      "Epoch 4/100\n",
      " - 0s - loss: 2.1692 - acc: 0.5500 - val_loss: 2.4754 - val_acc: 0.4667\n",
      "Epoch 5/100\n",
      " - 0s - loss: 2.1533 - acc: 0.5500 - val_loss: 2.4562 - val_acc: 0.4667\n",
      "Epoch 6/100\n",
      " - 0s - loss: 2.1367 - acc: 0.5500 - val_loss: 2.4365 - val_acc: 0.4667\n",
      "Epoch 7/100\n",
      " - 0s - loss: 2.1195 - acc: 0.5500 - val_loss: 2.4160 - val_acc: 0.4667\n",
      "Epoch 8/100\n",
      " - 0s - loss: 2.1021 - acc: 0.5500 - val_loss: 2.3960 - val_acc: 0.4667\n",
      "Epoch 9/100\n",
      " - 0s - loss: 2.0851 - acc: 0.5500 - val_loss: 2.3764 - val_acc: 0.4667\n",
      "Epoch 10/100\n",
      " - 0s - loss: 2.0669 - acc: 0.5500 - val_loss: 2.3537 - val_acc: 0.4667\n",
      "Epoch 11/100\n",
      " - 0s - loss: 2.0481 - acc: 0.5500 - val_loss: 2.3328 - val_acc: 0.4667\n",
      "Epoch 12/100\n",
      " - 0s - loss: 2.0288 - acc: 0.5500 - val_loss: 2.3090 - val_acc: 0.4667\n",
      "Epoch 13/100\n",
      " - 0s - loss: 2.0089 - acc: 0.5500 - val_loss: 2.2868 - val_acc: 0.4667\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.9901 - acc: 0.5500 - val_loss: 2.2655 - val_acc: 0.4667\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.9708 - acc: 0.5500 - val_loss: 2.2423 - val_acc: 0.4667\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.9515 - acc: 0.5500 - val_loss: 2.2207 - val_acc: 0.4667\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.9337 - acc: 0.5500 - val_loss: 2.2010 - val_acc: 0.4667\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1.9163 - acc: 0.5500 - val_loss: 2.1807 - val_acc: 0.4667\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1.8977 - acc: 0.5500 - val_loss: 2.1584 - val_acc: 0.4667\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1.8785 - acc: 0.5500 - val_loss: 2.1362 - val_acc: 0.4667\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1.8593 - acc: 0.5500 - val_loss: 2.1139 - val_acc: 0.4667\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1.8399 - acc: 0.5500 - val_loss: 2.0915 - val_acc: 0.4667\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1.8209 - acc: 0.5500 - val_loss: 2.0699 - val_acc: 0.4667\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.8023 - acc: 0.5500 - val_loss: 2.0484 - val_acc: 0.4667\n",
      "Epoch 25/100\n",
      " - 0s - loss: 1.7831 - acc: 0.5500 - val_loss: 2.0259 - val_acc: 0.4667\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.7637 - acc: 0.5500 - val_loss: 2.0035 - val_acc: 0.4667\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1.7443 - acc: 0.5500 - val_loss: 1.9811 - val_acc: 0.4667\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1.7249 - acc: 0.5500 - val_loss: 1.9586 - val_acc: 0.4667\n",
      "Epoch 29/100\n",
      " - 0s - loss: 1.7068 - acc: 0.5500 - val_loss: 1.9389 - val_acc: 0.4667\n",
      "Epoch 30/100\n",
      " - 0s - loss: 1.6903 - acc: 0.5500 - val_loss: 1.9205 - val_acc: 0.4667\n",
      "Epoch 31/100\n",
      " - 0s - loss: 1.6733 - acc: 0.5500 - val_loss: 1.9006 - val_acc: 0.4667\n",
      "Epoch 32/100\n",
      " - 0s - loss: 1.6545 - acc: 0.5500 - val_loss: 1.8768 - val_acc: 0.4667\n",
      "Epoch 33/100\n",
      " - 0s - loss: 1.6351 - acc: 0.5500 - val_loss: 1.8558 - val_acc: 0.4667\n",
      "Epoch 34/100\n",
      " - 0s - loss: 1.6160 - acc: 0.5500 - val_loss: 1.8329 - val_acc: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      " - 0s - loss: 1.5965 - acc: 0.5500 - val_loss: 1.8108 - val_acc: 0.4667\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.5771 - acc: 0.5500 - val_loss: 1.7880 - val_acc: 0.4667\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.5567 - acc: 0.5500 - val_loss: 1.7634 - val_acc: 0.4667\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.5362 - acc: 0.5500 - val_loss: 1.7409 - val_acc: 0.4667\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.5170 - acc: 0.5500 - val_loss: 1.7189 - val_acc: 0.4667\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.4987 - acc: 0.5500 - val_loss: 1.6985 - val_acc: 0.4667\n",
      "Epoch 41/100\n",
      " - 0s - loss: 1.4813 - acc: 0.5500 - val_loss: 1.6788 - val_acc: 0.4667\n",
      "Epoch 42/100\n",
      " - 0s - loss: 1.4636 - acc: 0.5500 - val_loss: 1.6582 - val_acc: 0.4667\n",
      "Epoch 43/100\n",
      " - 0s - loss: 1.4451 - acc: 0.5500 - val_loss: 1.6362 - val_acc: 0.4667\n",
      "Epoch 44/100\n",
      " - 0s - loss: 1.4260 - acc: 0.5500 - val_loss: 1.6140 - val_acc: 0.4667\n",
      "Epoch 45/100\n",
      " - 0s - loss: 1.4076 - acc: 0.5500 - val_loss: 1.5935 - val_acc: 0.4667\n",
      "Epoch 46/100\n",
      " - 0s - loss: 1.3899 - acc: 0.5500 - val_loss: 1.5732 - val_acc: 0.4667\n",
      "Epoch 47/100\n",
      " - 0s - loss: 1.3725 - acc: 0.5500 - val_loss: 1.5533 - val_acc: 0.4667\n",
      "Epoch 48/100\n",
      " - 0s - loss: 1.3552 - acc: 0.5500 - val_loss: 1.5334 - val_acc: 0.4667\n",
      "Epoch 49/100\n",
      " - 0s - loss: 1.3384 - acc: 0.5500 - val_loss: 1.5144 - val_acc: 0.4667\n",
      "Epoch 50/100\n",
      " - 0s - loss: 1.3213 - acc: 0.5500 - val_loss: 1.4941 - val_acc: 0.4667\n",
      "Epoch 51/100\n",
      " - 0s - loss: 1.3046 - acc: 0.5500 - val_loss: 1.4757 - val_acc: 0.4667\n",
      "Epoch 52/100\n",
      " - 0s - loss: 1.2885 - acc: 0.5500 - val_loss: 1.4571 - val_acc: 0.4667\n",
      "Epoch 53/100\n",
      " - 0s - loss: 1.2726 - acc: 0.5500 - val_loss: 1.4390 - val_acc: 0.4667\n",
      "Epoch 54/100\n",
      " - 0s - loss: 1.2558 - acc: 0.5500 - val_loss: 1.4185 - val_acc: 0.4667\n",
      "Epoch 55/100\n",
      " - 0s - loss: 1.2381 - acc: 0.5500 - val_loss: 1.3979 - val_acc: 0.4667\n",
      "Epoch 56/100\n",
      " - 0s - loss: 1.2211 - acc: 0.5500 - val_loss: 1.3790 - val_acc: 0.4667\n",
      "Epoch 57/100\n",
      " - 0s - loss: 1.2047 - acc: 0.5500 - val_loss: 1.3602 - val_acc: 0.4667\n",
      "Epoch 58/100\n",
      " - 0s - loss: 1.1877 - acc: 0.5500 - val_loss: 1.3397 - val_acc: 0.4667\n",
      "Epoch 59/100\n",
      " - 0s - loss: 1.1714 - acc: 0.5500 - val_loss: 1.3219 - val_acc: 0.4667\n",
      "Epoch 60/100\n",
      " - 0s - loss: 1.1556 - acc: 0.5500 - val_loss: 1.3036 - val_acc: 0.4667\n",
      "Epoch 61/100\n",
      " - 0s - loss: 1.1395 - acc: 0.5500 - val_loss: 1.2846 - val_acc: 0.4667\n",
      "Epoch 62/100\n",
      " - 0s - loss: 1.1240 - acc: 0.5500 - val_loss: 1.2674 - val_acc: 0.4667\n",
      "Epoch 63/100\n",
      " - 0s - loss: 1.1084 - acc: 0.5500 - val_loss: 1.2489 - val_acc: 0.4667\n",
      "Epoch 64/100\n",
      " - 0s - loss: 1.0927 - acc: 0.5500 - val_loss: 1.2310 - val_acc: 0.4667\n",
      "Epoch 65/100\n",
      " - 0s - loss: 1.0770 - acc: 0.5500 - val_loss: 1.2125 - val_acc: 0.4667\n",
      "Epoch 66/100\n",
      " - 0s - loss: 1.0612 - acc: 0.5500 - val_loss: 1.1942 - val_acc: 0.4667\n",
      "Epoch 67/100\n",
      " - 0s - loss: 1.0454 - acc: 0.5500 - val_loss: 1.1759 - val_acc: 0.4667\n",
      "Epoch 68/100\n",
      " - 0s - loss: 1.0292 - acc: 0.5500 - val_loss: 1.1565 - val_acc: 0.4667\n",
      "Epoch 69/100\n",
      " - 0s - loss: 1.0141 - acc: 0.5500 - val_loss: 1.1404 - val_acc: 0.4667\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.9991 - acc: 0.5500 - val_loss: 1.1220 - val_acc: 0.4667\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.9832 - acc: 0.5500 - val_loss: 1.1031 - val_acc: 0.4667\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.9679 - acc: 0.5500 - val_loss: 1.0864 - val_acc: 0.4667\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.9538 - acc: 0.5500 - val_loss: 1.0703 - val_acc: 0.4667\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.9396 - acc: 0.5500 - val_loss: 1.0535 - val_acc: 0.4667\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.9258 - acc: 0.5500 - val_loss: 1.0379 - val_acc: 0.4667\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.9126 - acc: 0.5500 - val_loss: 1.0226 - val_acc: 0.4667\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.8987 - acc: 0.5500 - val_loss: 1.0055 - val_acc: 0.4667\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.8844 - acc: 0.5500 - val_loss: 0.9892 - val_acc: 0.4667\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.8722 - acc: 0.5500 - val_loss: 0.9760 - val_acc: 0.4667\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.8593 - acc: 0.5500 - val_loss: 0.9597 - val_acc: 0.4667\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.8461 - acc: 0.5500 - val_loss: 0.9450 - val_acc: 0.4667\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.8337 - acc: 0.5500 - val_loss: 0.9305 - val_acc: 0.4667\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.8219 - acc: 0.5500 - val_loss: 0.9171 - val_acc: 0.4667\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.8100 - acc: 0.5500 - val_loss: 0.9027 - val_acc: 0.4667\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.7980 - acc: 0.5500 - val_loss: 0.8884 - val_acc: 0.4667\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.7867 - acc: 0.5500 - val_loss: 0.8758 - val_acc: 0.4667\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.7763 - acc: 0.5500 - val_loss: 0.8638 - val_acc: 0.4667\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.7669 - acc: 0.5500 - val_loss: 0.8532 - val_acc: 0.4667\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.7572 - acc: 0.5500 - val_loss: 0.8414 - val_acc: 0.4667\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.7476 - acc: 0.5500 - val_loss: 0.8303 - val_acc: 0.4667\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.7377 - acc: 0.5500 - val_loss: 0.8176 - val_acc: 0.4667\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.7280 - acc: 0.5500 - val_loss: 0.8069 - val_acc: 0.4667\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.7187 - acc: 0.5500 - val_loss: 0.7955 - val_acc: 0.4667\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.7093 - acc: 0.5500 - val_loss: 0.7842 - val_acc: 0.4667\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.7000 - acc: 0.5500 - val_loss: 0.7731 - val_acc: 0.4667\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.6911 - acc: 0.5500 - val_loss: 0.7625 - val_acc: 0.4667\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.6826 - acc: 0.5500 - val_loss: 0.7525 - val_acc: 0.4667\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.6747 - acc: 0.5500 - val_loss: 0.7431 - val_acc: 0.4667\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.6669 - acc: 0.5500 - val_loss: 0.7338 - val_acc: 0.4667\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.6597 - acc: 0.5500 - val_loss: 0.7254 - val_acc: 0.4667\n",
      "Test accuracy: 0.4666666626930237\n",
      "Evalutation of best performing model:\n",
      "60/60 [==============================] - 0s 17us/step\n",
      "[0.2943368494510651, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def data():\n",
    "    '''\n",
    "    Data providing function:\n",
    "\n",
    "    Make sure to have every relevant import statement included here and return data as\n",
    "    used in model function below. This function is separated from model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    '''\n",
    "    url = \"../data/iris.csv\"\n",
    "    data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "    class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "    data.iloc[:,-1] = index\n",
    "    data = data.loc[data[4] != 2]\n",
    "    X = data.iloc[:,:-1]\n",
    "    Y = data.iloc[:,-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def model(x_train, y_train, x_test, y_test):\n",
    "    '''\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    '''\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=4, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer={{choice(['adam', 'nadam'])}},\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size={{choice([10, 30])}},\n",
    "              epochs={{choice([100, 170])}},\n",
    "              verbose=2,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='experiment')\n",
    "x_train, y_train, x_test, y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Hyperas(Linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LogisticRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imly import dope\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LogisticRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import boto\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import sys\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from boto.s3.key import Key\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.utils.validation import column_or_1d\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LogisticRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import copy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import datasets\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import experiment_automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LinearRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import experiment_automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import re\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from automation_script import get_dataset_info\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imly import dope\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from utils.correlations import concordance_correlation_coefficient as ccc\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LinearRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imly import dope\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from utils.correlations import concordance_correlation_coefficient as ccc\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import boto\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import sys\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from boto.s3.key import Key\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.datasets import make_regression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import theano.tensor as T\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import theano\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from theano.compile.ops import as_op\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'optimizer': hp.choice('optimizer', ['adam', 'nadam']),\n",
      "        'batch_size': hp.choice('batch_size', [10, 30]),\n",
      "        'epochs': hp.choice('epochs', [100, 170]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: '''\n",
      "  3: Data providing function:\n",
      "  4: \n",
      "  5: Make sure to have every relevant import statement included here and return data as\n",
      "  6: used in model function below. This function is separated from model() so that hyperopt\n",
      "  7: won't reload data for each evaluation run.\n",
      "  8: '''\n",
      "  9: from os import path\n",
      " 10: import pandas as pd\n",
      " 11: from sklearn import preprocessing\n",
      " 12: from sklearn.preprocessing import StandardScaler\n",
      " 13: \n",
      " 14: url = \"../data/diabetes.csv\"\n",
      " 15: data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
      " 16: sc = StandardScaler()\n",
      " 17: data = sc.fit_transform(data)\n",
      " 18: data = pd.DataFrame(data)\n",
      " 19: \n",
      " 20: \n",
      " 21: X = data.iloc[:,:-1]\n",
      " 22: Y = data.iloc[:,-1]\n",
      " 23: x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
      " 24: \n",
      " 25: \n",
      " 26: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     '''\n",
      "   4:     Model providing function:\n",
      "   5: \n",
      "   6:     Create Keras model with double curly brackets dropped-in as needed.\n",
      "   7:     Return value has to be a valid python dictionary with two customary keys:\n",
      "   8:         - loss: Specify a numeric evaluation metric to be minimized\n",
      "   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
      "  10:     The last one is optional, though recommended, namely:\n",
      "  11:         - model: specify the model just created so that we can later use it again.\n",
      "  12:     '''\n",
      "  13: \n",
      "  14:     model = Sequential()\n",
      "  15:     model.add(Dense(1, input_dim=10, activation='linear'))\n",
      "  16: \n",
      "  17:     model.compile(loss='mse', optimizer=space['optimizer'])\n",
      "  18: \n",
      "  19:     model.fit(x_train, y_train,\n",
      "  20:               batch_size=space['batch_size'],\n",
      "  21:               epochs=space['epochs'],\n",
      "  22:               verbose=2,\n",
      "  23:               validation_data=(x_test, y_test))\n",
      "  24:     score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
      "  25:     print('Test accuracy:', acc)\n",
      "  26:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  27: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176 samples, validate on 266 samples\n",
      "Epoch 1/170\n",
      " - 0s - loss: 1.6659 - acc: 0.0000e+00 - val_loss: 1.5142 - val_acc: 0.0000e+00\n",
      "Epoch 2/170\n",
      " - 0s - loss: 1.6094 - acc: 0.0000e+00 - val_loss: 1.4674 - val_acc: 0.0000e+00\n",
      "Epoch 3/170\n",
      " - 0s - loss: 1.5604 - acc: 0.0000e+00 - val_loss: 1.4252 - val_acc: 0.0000e+00\n",
      "Epoch 4/170\n",
      " - 0s - loss: 1.5204 - acc: 0.0000e+00 - val_loss: 1.3813 - val_acc: 0.0000e+00\n",
      "Epoch 5/170\n",
      " - 0s - loss: 1.4753 - acc: 0.0000e+00 - val_loss: 1.3462 - val_acc: 0.0000e+00\n",
      "Epoch 6/170\n",
      " - 0s - loss: 1.4360 - acc: 0.0000e+00 - val_loss: 1.3165 - val_acc: 0.0000e+00\n",
      "Epoch 7/170\n",
      " - 0s - loss: 1.3996 - acc: 0.0000e+00 - val_loss: 1.2852 - val_acc: 0.0000e+00\n",
      "Epoch 8/170\n",
      " - 0s - loss: 1.3632 - acc: 0.0000e+00 - val_loss: 1.2518 - val_acc: 0.0000e+00\n",
      "Epoch 9/170\n",
      " - 0s - loss: 1.3302 - acc: 0.0000e+00 - val_loss: 1.2223 - val_acc: 0.0000e+00\n",
      "Epoch 10/170\n",
      " - 0s - loss: 1.2957 - acc: 0.0000e+00 - val_loss: 1.1963 - val_acc: 0.0000e+00\n",
      "Epoch 11/170\n",
      " - 0s - loss: 1.2650 - acc: 0.0000e+00 - val_loss: 1.1693 - val_acc: 0.0000e+00\n",
      "Epoch 12/170\n",
      " - 0s - loss: 1.2356 - acc: 0.0000e+00 - val_loss: 1.1414 - val_acc: 0.0000e+00\n",
      "Epoch 13/170\n",
      " - 0s - loss: 1.2079 - acc: 0.0000e+00 - val_loss: 1.1171 - val_acc: 0.0000e+00\n",
      "Epoch 14/170\n",
      " - 0s - loss: 1.1778 - acc: 0.0000e+00 - val_loss: 1.0964 - val_acc: 0.0000e+00\n",
      "Epoch 15/170\n",
      " - 0s - loss: 1.1536 - acc: 0.0000e+00 - val_loss: 1.0736 - val_acc: 0.0000e+00\n",
      "Epoch 16/170\n",
      " - 0s - loss: 1.1273 - acc: 0.0000e+00 - val_loss: 1.0521 - val_acc: 0.0000e+00\n",
      "Epoch 17/170\n",
      " - 0s - loss: 1.1030 - acc: 0.0000e+00 - val_loss: 1.0333 - val_acc: 0.0000e+00\n",
      "Epoch 18/170\n",
      " - 0s - loss: 1.0797 - acc: 0.0000e+00 - val_loss: 1.0138 - val_acc: 0.0000e+00\n",
      "Epoch 19/170\n",
      " - 0s - loss: 1.0573 - acc: 0.0000e+00 - val_loss: 0.9942 - val_acc: 0.0000e+00\n",
      "Epoch 20/170\n",
      " - 0s - loss: 1.0365 - acc: 0.0000e+00 - val_loss: 0.9776 - val_acc: 0.0000e+00\n",
      "Epoch 21/170\n",
      " - 0s - loss: 1.0154 - acc: 0.0000e+00 - val_loss: 0.9591 - val_acc: 0.0000e+00\n",
      "Epoch 22/170\n",
      " - 0s - loss: 0.9958 - acc: 0.0000e+00 - val_loss: 0.9389 - val_acc: 0.0000e+00\n",
      "Epoch 23/170\n",
      " - 0s - loss: 0.9760 - acc: 0.0000e+00 - val_loss: 0.9232 - val_acc: 0.0000e+00\n",
      "Epoch 24/170\n",
      " - 0s - loss: 0.9569 - acc: 0.0000e+00 - val_loss: 0.9071 - val_acc: 0.0000e+00\n",
      "Epoch 25/170\n",
      " - 0s - loss: 0.9396 - acc: 0.0000e+00 - val_loss: 0.8925 - val_acc: 0.0000e+00\n",
      "Epoch 26/170\n",
      " - 0s - loss: 0.9217 - acc: 0.0000e+00 - val_loss: 0.8776 - val_acc: 0.0000e+00\n",
      "Epoch 27/170\n",
      " - 0s - loss: 0.9045 - acc: 0.0000e+00 - val_loss: 0.8651 - val_acc: 0.0000e+00\n",
      "Epoch 28/170\n",
      " - 0s - loss: 0.8893 - acc: 0.0000e+00 - val_loss: 0.8498 - val_acc: 0.0000e+00\n",
      "Epoch 29/170\n",
      " - 0s - loss: 0.8741 - acc: 0.0000e+00 - val_loss: 0.8364 - val_acc: 0.0000e+00\n",
      "Epoch 30/170\n",
      " - 0s - loss: 0.8589 - acc: 0.0000e+00 - val_loss: 0.8254 - val_acc: 0.0000e+00\n",
      "Epoch 31/170\n",
      " - 0s - loss: 0.8440 - acc: 0.0000e+00 - val_loss: 0.8124 - val_acc: 0.0000e+00\n",
      "Epoch 32/170\n",
      " - 0s - loss: 0.8306 - acc: 0.0000e+00 - val_loss: 0.7989 - val_acc: 0.0000e+00\n",
      "Epoch 33/170\n",
      " - 0s - loss: 0.8164 - acc: 0.0000e+00 - val_loss: 0.7878 - val_acc: 0.0000e+00\n",
      "Epoch 34/170\n",
      " - 0s - loss: 0.8037 - acc: 0.0000e+00 - val_loss: 0.7759 - val_acc: 0.0000e+00\n",
      "Epoch 35/170\n",
      " - 0s - loss: 0.7916 - acc: 0.0000e+00 - val_loss: 0.7653 - val_acc: 0.0000e+00\n",
      "Epoch 36/170\n",
      " - 0s - loss: 0.7790 - acc: 0.0000e+00 - val_loss: 0.7573 - val_acc: 0.0000e+00\n",
      "Epoch 37/170\n",
      " - 0s - loss: 0.7675 - acc: 0.0000e+00 - val_loss: 0.7474 - val_acc: 0.0000e+00\n",
      "Epoch 38/170\n",
      " - 0s - loss: 0.7564 - acc: 0.0000e+00 - val_loss: 0.7361 - val_acc: 0.0000e+00\n",
      "Epoch 39/170\n",
      " - 0s - loss: 0.7450 - acc: 0.0000e+00 - val_loss: 0.7267 - val_acc: 0.0000e+00\n",
      "Epoch 40/170\n",
      " - 0s - loss: 0.7349 - acc: 0.0000e+00 - val_loss: 0.7191 - val_acc: 0.0000e+00\n",
      "Epoch 41/170\n",
      " - 0s - loss: 0.7244 - acc: 0.0000e+00 - val_loss: 0.7100 - val_acc: 0.0000e+00\n",
      "Epoch 42/170\n",
      " - 0s - loss: 0.7147 - acc: 0.0000e+00 - val_loss: 0.7014 - val_acc: 0.0000e+00\n",
      "Epoch 43/170\n",
      " - 0s - loss: 0.7063 - acc: 0.0000e+00 - val_loss: 0.6924 - val_acc: 0.0000e+00\n",
      "Epoch 44/170\n",
      " - 0s - loss: 0.6958 - acc: 0.0000e+00 - val_loss: 0.6877 - val_acc: 0.0000e+00\n",
      "Epoch 45/170\n",
      " - 0s - loss: 0.6875 - acc: 0.0000e+00 - val_loss: 0.6810 - val_acc: 0.0000e+00\n",
      "Epoch 46/170\n",
      " - 0s - loss: 0.6791 - acc: 0.0000e+00 - val_loss: 0.6740 - val_acc: 0.0000e+00\n",
      "Epoch 47/170\n",
      " - 0s - loss: 0.6702 - acc: 0.0000e+00 - val_loss: 0.6662 - val_acc: 0.0000e+00\n",
      "Epoch 48/170\n",
      " - 0s - loss: 0.6623 - acc: 0.0000e+00 - val_loss: 0.6592 - val_acc: 0.0000e+00\n",
      "Epoch 49/170\n",
      " - 0s - loss: 0.6549 - acc: 0.0000e+00 - val_loss: 0.6542 - val_acc: 0.0000e+00\n",
      "Epoch 50/170\n",
      " - 0s - loss: 0.6475 - acc: 0.0000e+00 - val_loss: 0.6479 - val_acc: 0.0000e+00\n",
      "Epoch 51/170\n",
      " - 0s - loss: 0.6406 - acc: 0.0000e+00 - val_loss: 0.6424 - val_acc: 0.0000e+00\n",
      "Epoch 52/170\n",
      " - 0s - loss: 0.6333 - acc: 0.0000e+00 - val_loss: 0.6384 - val_acc: 0.0000e+00\n",
      "Epoch 53/170\n",
      " - 0s - loss: 0.6274 - acc: 0.0000e+00 - val_loss: 0.6336 - val_acc: 0.0000e+00\n",
      "Epoch 54/170\n",
      " - 0s - loss: 0.6213 - acc: 0.0000e+00 - val_loss: 0.6271 - val_acc: 0.0000e+00\n",
      "Epoch 55/170\n",
      " - 0s - loss: 0.6146 - acc: 0.0000e+00 - val_loss: 0.6228 - val_acc: 0.0000e+00\n",
      "Epoch 56/170\n",
      " - 0s - loss: 0.6087 - acc: 0.0000e+00 - val_loss: 0.6168 - val_acc: 0.0000e+00\n",
      "Epoch 57/170\n",
      " - 0s - loss: 0.6027 - acc: 0.0000e+00 - val_loss: 0.6127 - val_acc: 0.0000e+00\n",
      "Epoch 58/170\n",
      " - 0s - loss: 0.5972 - acc: 0.0000e+00 - val_loss: 0.6092 - val_acc: 0.0000e+00\n",
      "Epoch 59/170\n",
      " - 0s - loss: 0.5920 - acc: 0.0000e+00 - val_loss: 0.6043 - val_acc: 0.0000e+00\n",
      "Epoch 60/170\n",
      " - 0s - loss: 0.5866 - acc: 0.0000e+00 - val_loss: 0.6005 - val_acc: 0.0000e+00\n",
      "Epoch 61/170\n",
      " - 0s - loss: 0.5813 - acc: 0.0000e+00 - val_loss: 0.5970 - val_acc: 0.0000e+00\n",
      "Epoch 62/170\n",
      " - 0s - loss: 0.5769 - acc: 0.0000e+00 - val_loss: 0.5940 - val_acc: 0.0000e+00\n",
      "Epoch 63/170\n",
      " - 0s - loss: 0.5719 - acc: 0.0000e+00 - val_loss: 0.5907 - val_acc: 0.0000e+00\n",
      "Epoch 64/170\n",
      " - 0s - loss: 0.5675 - acc: 0.0000e+00 - val_loss: 0.5877 - val_acc: 0.0000e+00\n",
      "Epoch 65/170\n",
      " - 0s - loss: 0.5627 - acc: 0.0000e+00 - val_loss: 0.5847 - val_acc: 0.0000e+00\n",
      "Epoch 66/170\n",
      " - 0s - loss: 0.5592 - acc: 0.0000e+00 - val_loss: 0.5815 - val_acc: 0.0000e+00\n",
      "Epoch 67/170\n",
      " - 0s - loss: 0.5546 - acc: 0.0000e+00 - val_loss: 0.5796 - val_acc: 0.0000e+00\n",
      "Epoch 68/170\n",
      " - 0s - loss: 0.5510 - acc: 0.0000e+00 - val_loss: 0.5770 - val_acc: 0.0000e+00\n",
      "Epoch 69/170\n",
      " - 0s - loss: 0.5473 - acc: 0.0000e+00 - val_loss: 0.5758 - val_acc: 0.0000e+00\n",
      "Epoch 70/170\n",
      " - 0s - loss: 0.5439 - acc: 0.0000e+00 - val_loss: 0.5723 - val_acc: 0.0000e+00\n",
      "Epoch 71/170\n",
      " - 0s - loss: 0.5394 - acc: 0.0000e+00 - val_loss: 0.5701 - val_acc: 0.0000e+00\n",
      "Epoch 72/170\n",
      " - 0s - loss: 0.5368 - acc: 0.0000e+00 - val_loss: 0.5685 - val_acc: 0.0000e+00\n",
      "Epoch 73/170\n",
      " - 0s - loss: 0.5329 - acc: 0.0000e+00 - val_loss: 0.5669 - val_acc: 0.0000e+00\n",
      "Epoch 74/170\n",
      " - 0s - loss: 0.5301 - acc: 0.0000e+00 - val_loss: 0.5640 - val_acc: 0.0000e+00\n",
      "Epoch 75/170\n",
      " - 0s - loss: 0.5271 - acc: 0.0000e+00 - val_loss: 0.5629 - val_acc: 0.0000e+00\n",
      "Epoch 76/170\n",
      " - 0s - loss: 0.5238 - acc: 0.0000e+00 - val_loss: 0.5614 - val_acc: 0.0000e+00\n",
      "Epoch 77/170\n",
      " - 0s - loss: 0.5214 - acc: 0.0000e+00 - val_loss: 0.5586 - val_acc: 0.0000e+00\n",
      "Epoch 78/170\n",
      " - 0s - loss: 0.5193 - acc: 0.0000e+00 - val_loss: 0.5578 - val_acc: 0.0000e+00\n",
      "Epoch 79/170\n",
      " - 0s - loss: 0.5163 - acc: 0.0000e+00 - val_loss: 0.5559 - val_acc: 0.0000e+00\n",
      "Epoch 80/170\n",
      " - 0s - loss: 0.5134 - acc: 0.0000e+00 - val_loss: 0.5553 - val_acc: 0.0000e+00\n",
      "Epoch 81/170\n",
      " - 0s - loss: 0.5112 - acc: 0.0000e+00 - val_loss: 0.5547 - val_acc: 0.0000e+00\n",
      "Epoch 82/170\n",
      " - 0s - loss: 0.5083 - acc: 0.0000e+00 - val_loss: 0.5533 - val_acc: 0.0000e+00\n",
      "Epoch 83/170\n",
      " - 0s - loss: 0.5062 - acc: 0.0000e+00 - val_loss: 0.5522 - val_acc: 0.0000e+00\n",
      "Epoch 84/170\n",
      " - 0s - loss: 0.5039 - acc: 0.0000e+00 - val_loss: 0.5512 - val_acc: 0.0000e+00\n",
      "Epoch 85/170\n",
      " - 0s - loss: 0.5019 - acc: 0.0000e+00 - val_loss: 0.5497 - val_acc: 0.0000e+00\n",
      "Epoch 86/170\n",
      " - 0s - loss: 0.5004 - acc: 0.0000e+00 - val_loss: 0.5487 - val_acc: 0.0000e+00\n",
      "Epoch 87/170\n",
      " - 0s - loss: 0.4983 - acc: 0.0000e+00 - val_loss: 0.5486 - val_acc: 0.0000e+00\n",
      "Epoch 88/170\n",
      " - 0s - loss: 0.4968 - acc: 0.0000e+00 - val_loss: 0.5480 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/170\n",
      " - 0s - loss: 0.4939 - acc: 0.0000e+00 - val_loss: 0.5473 - val_acc: 0.0000e+00\n",
      "Epoch 90/170\n",
      " - 0s - loss: 0.4932 - acc: 0.0000e+00 - val_loss: 0.5462 - val_acc: 0.0000e+00\n",
      "Epoch 91/170\n",
      " - 0s - loss: 0.4908 - acc: 0.0000e+00 - val_loss: 0.5469 - val_acc: 0.0000e+00\n",
      "Epoch 92/170\n",
      " - 0s - loss: 0.4895 - acc: 0.0000e+00 - val_loss: 0.5461 - val_acc: 0.0000e+00\n",
      "Epoch 93/170\n",
      " - 0s - loss: 0.4880 - acc: 0.0000e+00 - val_loss: 0.5459 - val_acc: 0.0000e+00\n",
      "Epoch 94/170\n",
      " - 0s - loss: 0.4863 - acc: 0.0000e+00 - val_loss: 0.5453 - val_acc: 0.0000e+00\n",
      "Epoch 95/170\n",
      " - 0s - loss: 0.4846 - acc: 0.0000e+00 - val_loss: 0.5446 - val_acc: 0.0000e+00\n",
      "Epoch 96/170\n",
      " - 0s - loss: 0.4838 - acc: 0.0000e+00 - val_loss: 0.5445 - val_acc: 0.0000e+00\n",
      "Epoch 97/170\n",
      " - 0s - loss: 0.4822 - acc: 0.0000e+00 - val_loss: 0.5445 - val_acc: 0.0000e+00\n",
      "Epoch 98/170\n",
      " - 0s - loss: 0.4813 - acc: 0.0000e+00 - val_loss: 0.5443 - val_acc: 0.0000e+00\n",
      "Epoch 99/170\n",
      " - 0s - loss: 0.4800 - acc: 0.0000e+00 - val_loss: 0.5433 - val_acc: 0.0000e+00\n",
      "Epoch 100/170\n",
      " - 0s - loss: 0.4791 - acc: 0.0000e+00 - val_loss: 0.5433 - val_acc: 0.0000e+00\n",
      "Epoch 101/170\n",
      " - 0s - loss: 0.4773 - acc: 0.0000e+00 - val_loss: 0.5428 - val_acc: 0.0000e+00\n",
      "Epoch 102/170\n",
      " - 0s - loss: 0.4764 - acc: 0.0000e+00 - val_loss: 0.5431 - val_acc: 0.0000e+00\n",
      "Epoch 103/170\n",
      " - 0s - loss: 0.4756 - acc: 0.0000e+00 - val_loss: 0.5430 - val_acc: 0.0000e+00\n",
      "Epoch 104/170\n",
      " - 0s - loss: 0.4742 - acc: 0.0000e+00 - val_loss: 0.5425 - val_acc: 0.0000e+00\n",
      "Epoch 105/170\n",
      " - 0s - loss: 0.4735 - acc: 0.0000e+00 - val_loss: 0.5430 - val_acc: 0.0000e+00\n",
      "Epoch 106/170\n",
      " - 0s - loss: 0.4726 - acc: 0.0000e+00 - val_loss: 0.5431 - val_acc: 0.0000e+00\n",
      "Epoch 107/170\n",
      " - 0s - loss: 0.4712 - acc: 0.0000e+00 - val_loss: 0.5431 - val_acc: 0.0000e+00\n",
      "Epoch 108/170\n",
      " - 0s - loss: 0.4709 - acc: 0.0000e+00 - val_loss: 0.5437 - val_acc: 0.0000e+00\n",
      "Epoch 109/170\n",
      " - 0s - loss: 0.4697 - acc: 0.0000e+00 - val_loss: 0.5435 - val_acc: 0.0000e+00\n",
      "Epoch 110/170\n",
      " - 0s - loss: 0.4694 - acc: 0.0000e+00 - val_loss: 0.5437 - val_acc: 0.0000e+00\n",
      "Epoch 111/170\n",
      " - 0s - loss: 0.4686 - acc: 0.0000e+00 - val_loss: 0.5434 - val_acc: 0.0000e+00\n",
      "Epoch 112/170\n",
      " - 0s - loss: 0.4674 - acc: 0.0000e+00 - val_loss: 0.5437 - val_acc: 0.0000e+00\n",
      "Epoch 113/170\n",
      " - 0s - loss: 0.4672 - acc: 0.0000e+00 - val_loss: 0.5439 - val_acc: 0.0000e+00\n",
      "Epoch 114/170\n",
      " - 0s - loss: 0.4662 - acc: 0.0000e+00 - val_loss: 0.5437 - val_acc: 0.0000e+00\n",
      "Epoch 115/170\n",
      " - 0s - loss: 0.4656 - acc: 0.0000e+00 - val_loss: 0.5443 - val_acc: 0.0000e+00\n",
      "Epoch 116/170\n",
      " - 0s - loss: 0.4650 - acc: 0.0000e+00 - val_loss: 0.5446 - val_acc: 0.0000e+00\n",
      "Epoch 117/170\n",
      " - 0s - loss: 0.4653 - acc: 0.0000e+00 - val_loss: 0.5448 - val_acc: 0.0000e+00\n",
      "Epoch 118/170\n",
      " - 0s - loss: 0.4638 - acc: 0.0000e+00 - val_loss: 0.5456 - val_acc: 0.0000e+00\n",
      "Epoch 119/170\n",
      " - 0s - loss: 0.4636 - acc: 0.0000e+00 - val_loss: 0.5446 - val_acc: 0.0000e+00\n",
      "Epoch 120/170\n",
      " - 0s - loss: 0.4627 - acc: 0.0000e+00 - val_loss: 0.5452 - val_acc: 0.0000e+00\n",
      "Epoch 121/170\n",
      " - 0s - loss: 0.4624 - acc: 0.0000e+00 - val_loss: 0.5458 - val_acc: 0.0000e+00\n",
      "Epoch 122/170\n",
      " - 0s - loss: 0.4623 - acc: 0.0000e+00 - val_loss: 0.5458 - val_acc: 0.0000e+00\n",
      "Epoch 123/170\n",
      " - 0s - loss: 0.4617 - acc: 0.0000e+00 - val_loss: 0.5464 - val_acc: 0.0000e+00\n",
      "Epoch 124/170\n",
      " - 0s - loss: 0.4611 - acc: 0.0000e+00 - val_loss: 0.5469 - val_acc: 0.0000e+00\n",
      "Epoch 125/170\n",
      " - 0s - loss: 0.4607 - acc: 0.0000e+00 - val_loss: 0.5468 - val_acc: 0.0000e+00\n",
      "Epoch 126/170\n",
      " - 0s - loss: 0.4604 - acc: 0.0000e+00 - val_loss: 0.5479 - val_acc: 0.0000e+00\n",
      "Epoch 127/170\n",
      " - 0s - loss: 0.4604 - acc: 0.0000e+00 - val_loss: 0.5478 - val_acc: 0.0000e+00\n",
      "Epoch 128/170\n",
      " - 0s - loss: 0.4600 - acc: 0.0000e+00 - val_loss: 0.5489 - val_acc: 0.0000e+00\n",
      "Epoch 129/170\n",
      " - 0s - loss: 0.4588 - acc: 0.0000e+00 - val_loss: 0.5486 - val_acc: 0.0000e+00\n",
      "Epoch 130/170\n",
      " - 0s - loss: 0.4594 - acc: 0.0000e+00 - val_loss: 0.5487 - val_acc: 0.0000e+00\n",
      "Epoch 131/170\n",
      " - 0s - loss: 0.4581 - acc: 0.0000e+00 - val_loss: 0.5495 - val_acc: 0.0000e+00\n",
      "Epoch 132/170\n",
      " - 0s - loss: 0.4577 - acc: 0.0000e+00 - val_loss: 0.5498 - val_acc: 0.0000e+00\n",
      "Epoch 133/170\n",
      " - 0s - loss: 0.4574 - acc: 0.0000e+00 - val_loss: 0.5498 - val_acc: 0.0000e+00\n",
      "Epoch 134/170\n",
      " - 0s - loss: 0.4573 - acc: 0.0000e+00 - val_loss: 0.5506 - val_acc: 0.0000e+00\n",
      "Epoch 135/170\n",
      " - 0s - loss: 0.4573 - acc: 0.0000e+00 - val_loss: 0.5506 - val_acc: 0.0000e+00\n",
      "Epoch 136/170\n",
      " - 0s - loss: 0.4568 - acc: 0.0000e+00 - val_loss: 0.5508 - val_acc: 0.0000e+00\n",
      "Epoch 137/170\n",
      " - 0s - loss: 0.4572 - acc: 0.0000e+00 - val_loss: 0.5513 - val_acc: 0.0000e+00\n",
      "Epoch 138/170\n",
      " - 0s - loss: 0.4562 - acc: 0.0000e+00 - val_loss: 0.5517 - val_acc: 0.0000e+00\n",
      "Epoch 139/170\n",
      " - 0s - loss: 0.4561 - acc: 0.0000e+00 - val_loss: 0.5520 - val_acc: 0.0000e+00\n",
      "Epoch 140/170\n",
      " - 0s - loss: 0.4556 - acc: 0.0000e+00 - val_loss: 0.5526 - val_acc: 0.0000e+00\n",
      "Epoch 141/170\n",
      " - 0s - loss: 0.4564 - acc: 0.0000e+00 - val_loss: 0.5520 - val_acc: 0.0000e+00\n",
      "Epoch 142/170\n",
      " - 0s - loss: 0.4551 - acc: 0.0000e+00 - val_loss: 0.5530 - val_acc: 0.0000e+00\n",
      "Epoch 143/170\n",
      " - 0s - loss: 0.4554 - acc: 0.0000e+00 - val_loss: 0.5533 - val_acc: 0.0000e+00\n",
      "Epoch 144/170\n",
      " - 0s - loss: 0.4547 - acc: 0.0000e+00 - val_loss: 0.5537 - val_acc: 0.0000e+00\n",
      "Epoch 145/170\n",
      " - 0s - loss: 0.4549 - acc: 0.0000e+00 - val_loss: 0.5536 - val_acc: 0.0000e+00\n",
      "Epoch 146/170\n",
      " - 0s - loss: 0.4546 - acc: 0.0000e+00 - val_loss: 0.5544 - val_acc: 0.0000e+00\n",
      "Epoch 147/170\n",
      " - 0s - loss: 0.4543 - acc: 0.0000e+00 - val_loss: 0.5543 - val_acc: 0.0000e+00\n",
      "Epoch 148/170\n",
      " - 0s - loss: 0.4540 - acc: 0.0000e+00 - val_loss: 0.5550 - val_acc: 0.0000e+00\n",
      "Epoch 149/170\n",
      " - 0s - loss: 0.4538 - acc: 0.0000e+00 - val_loss: 0.5551 - val_acc: 0.0000e+00\n",
      "Epoch 150/170\n",
      " - 0s - loss: 0.4534 - acc: 0.0000e+00 - val_loss: 0.5549 - val_acc: 0.0000e+00\n",
      "Epoch 151/170\n",
      " - 0s - loss: 0.4535 - acc: 0.0000e+00 - val_loss: 0.5556 - val_acc: 0.0000e+00\n",
      "Epoch 152/170\n",
      " - 0s - loss: 0.4537 - acc: 0.0000e+00 - val_loss: 0.5553 - val_acc: 0.0000e+00\n",
      "Epoch 153/170\n",
      " - 0s - loss: 0.4532 - acc: 0.0000e+00 - val_loss: 0.5564 - val_acc: 0.0000e+00\n",
      "Epoch 154/170\n",
      " - 0s - loss: 0.4530 - acc: 0.0000e+00 - val_loss: 0.5563 - val_acc: 0.0000e+00\n",
      "Epoch 155/170\n",
      " - 0s - loss: 0.4528 - acc: 0.0000e+00 - val_loss: 0.5568 - val_acc: 0.0000e+00\n",
      "Epoch 156/170\n",
      " - 0s - loss: 0.4527 - acc: 0.0000e+00 - val_loss: 0.5571 - val_acc: 0.0000e+00\n",
      "Epoch 157/170\n",
      " - 0s - loss: 0.4527 - acc: 0.0000e+00 - val_loss: 0.5576 - val_acc: 0.0000e+00\n",
      "Epoch 158/170\n",
      " - 0s - loss: 0.4531 - acc: 0.0000e+00 - val_loss: 0.5575 - val_acc: 0.0000e+00\n",
      "Epoch 159/170\n",
      " - 0s - loss: 0.4524 - acc: 0.0000e+00 - val_loss: 0.5576 - val_acc: 0.0000e+00\n",
      "Epoch 160/170\n",
      " - 0s - loss: 0.4525 - acc: 0.0000e+00 - val_loss: 0.5582 - val_acc: 0.0000e+00\n",
      "Epoch 161/170\n",
      " - 0s - loss: 0.4524 - acc: 0.0000e+00 - val_loss: 0.5587 - val_acc: 0.0000e+00\n",
      "Epoch 162/170\n",
      " - 0s - loss: 0.4521 - acc: 0.0000e+00 - val_loss: 0.5590 - val_acc: 0.0000e+00\n",
      "Epoch 163/170\n",
      " - 0s - loss: 0.4522 - acc: 0.0000e+00 - val_loss: 0.5585 - val_acc: 0.0000e+00\n",
      "Epoch 164/170\n",
      " - 0s - loss: 0.4525 - acc: 0.0000e+00 - val_loss: 0.5586 - val_acc: 0.0000e+00\n",
      "Epoch 165/170\n",
      " - 0s - loss: 0.4520 - acc: 0.0000e+00 - val_loss: 0.5595 - val_acc: 0.0000e+00\n",
      "Epoch 166/170\n",
      " - 0s - loss: 0.4516 - acc: 0.0000e+00 - val_loss: 0.5607 - val_acc: 0.0000e+00\n",
      "Epoch 167/170\n",
      " - 0s - loss: 0.4520 - acc: 0.0000e+00 - val_loss: 0.5597 - val_acc: 0.0000e+00\n",
      "Epoch 168/170\n",
      " - 0s - loss: 0.4521 - acc: 0.0000e+00 - val_loss: 0.5604 - val_acc: 0.0000e+00\n",
      "Epoch 169/170\n",
      " - 0s - loss: 0.4513 - acc: 0.0000e+00 - val_loss: 0.5608 - val_acc: 0.0000e+00\n",
      "Epoch 170/170\n",
      " - 0s - loss: 0.4514 - acc: 0.0000e+00 - val_loss: 0.5606 - val_acc: 0.0000e+00\n",
      "Test accuracy: 0.0\n",
      "Train on 176 samples, validate on 266 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 2.8030 - acc: 0.0000e+00 - val_loss: 2.1154 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 0s - loss: 2.7350 - acc: 0.0000e+00 - val_loss: 2.0676 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 0s - loss: 2.6646 - acc: 0.0000e+00 - val_loss: 2.0222 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " - 0s - loss: 2.6021 - acc: 0.0000e+00 - val_loss: 1.9775 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      " - 0s - loss: 2.5360 - acc: 0.0000e+00 - val_loss: 1.9353 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      " - 0s - loss: 2.4758 - acc: 0.0000e+00 - val_loss: 1.8944 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      " - 0s - loss: 2.4168 - acc: 0.0000e+00 - val_loss: 1.8551 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      " - 0s - loss: 2.3611 - acc: 0.0000e+00 - val_loss: 1.8173 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      " - 0s - loss: 2.3044 - acc: 0.0000e+00 - val_loss: 1.7816 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      " - 0s - loss: 2.2538 - acc: 0.0000e+00 - val_loss: 1.7467 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      " - 0s - loss: 2.2037 - acc: 0.0000e+00 - val_loss: 1.7129 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      " - 0s - loss: 2.1562 - acc: 0.0000e+00 - val_loss: 1.6803 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      " - 0s - loss: 2.1104 - acc: 0.0000e+00 - val_loss: 1.6489 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      " - 0s - loss: 2.0637 - acc: 0.0000e+00 - val_loss: 1.6192 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      " - 0s - loss: 2.0216 - acc: 0.0000e+00 - val_loss: 1.5903 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.9791 - acc: 0.0000e+00 - val_loss: 1.5629 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.9408 - acc: 0.0000e+00 - val_loss: 1.5359 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1.9026 - acc: 0.0000e+00 - val_loss: 1.5097 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1.8641 - acc: 0.0000e+00 - val_loss: 1.4847 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1.8284 - acc: 0.0000e+00 - val_loss: 1.4602 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1.7940 - acc: 0.0000e+00 - val_loss: 1.4367 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1.7600 - acc: 0.0000e+00 - val_loss: 1.4140 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1.7283 - acc: 0.0000e+00 - val_loss: 1.3919 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.6965 - acc: 0.0000e+00 - val_loss: 1.3706 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      " - 0s - loss: 1.6650 - acc: 0.0000e+00 - val_loss: 1.3502 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      " - 0s - loss: 1.6369 - acc: 0.0000e+00 - val_loss: 1.3297 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      " - 0s - loss: 1.6074 - acc: 0.0000e+00 - val_loss: 1.3102 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      " - 0s - loss: 1.5803 - acc: 0.0000e+00 - val_loss: 1.2910 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      " - 0s - loss: 1.5517 - acc: 0.0000e+00 - val_loss: 1.2730 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      " - 0s - loss: 1.5260 - acc: 0.0000e+00 - val_loss: 1.2553 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      " - 0s - loss: 1.5021 - acc: 0.0000e+00 - val_loss: 1.2372 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      " - 0s - loss: 1.4757 - acc: 0.0000e+00 - val_loss: 1.2205 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      " - 0s - loss: 1.4530 - acc: 0.0000e+00 - val_loss: 1.2035 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      " - 0s - loss: 1.4278 - acc: 0.0000e+00 - val_loss: 1.1875 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      " - 0s - loss: 1.4066 - acc: 0.0000e+00 - val_loss: 1.1712 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      " - 0s - loss: 1.3831 - acc: 0.0000e+00 - val_loss: 1.1558 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      " - 0s - loss: 1.3615 - acc: 0.0000e+00 - val_loss: 1.1407 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      " - 0s - loss: 1.3401 - acc: 0.0000e+00 - val_loss: 1.1260 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      " - 0s - loss: 1.3203 - acc: 0.0000e+00 - val_loss: 1.1116 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      " - 0s - loss: 1.2988 - acc: 0.0000e+00 - val_loss: 1.0979 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      " - 0s - loss: 1.2791 - acc: 0.0000e+00 - val_loss: 1.0845 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      " - 0s - loss: 1.2606 - acc: 0.0000e+00 - val_loss: 1.0711 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      " - 0s - loss: 1.2420 - acc: 0.0000e+00 - val_loss: 1.0582 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      " - 0s - loss: 1.2234 - acc: 0.0000e+00 - val_loss: 1.0457 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      " - 0s - loss: 1.2054 - acc: 0.0000e+00 - val_loss: 1.0335 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      " - 0s - loss: 1.1883 - acc: 0.0000e+00 - val_loss: 1.0212 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      " - 0s - loss: 1.1713 - acc: 0.0000e+00 - val_loss: 1.0095 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      " - 0s - loss: 1.1542 - acc: 0.0000e+00 - val_loss: 0.9979 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      " - 0s - loss: 1.1377 - acc: 0.0000e+00 - val_loss: 0.9866 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      " - 0s - loss: 1.1219 - acc: 0.0000e+00 - val_loss: 0.9756 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      " - 0s - loss: 1.1059 - acc: 0.0000e+00 - val_loss: 0.9649 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      " - 0s - loss: 1.0911 - acc: 0.0000e+00 - val_loss: 0.9542 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      " - 0s - loss: 1.0765 - acc: 0.0000e+00 - val_loss: 0.9437 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      " - 0s - loss: 1.0609 - acc: 0.0000e+00 - val_loss: 0.9340 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      " - 0s - loss: 1.0476 - acc: 0.0000e+00 - val_loss: 0.9241 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      " - 0s - loss: 1.0332 - acc: 0.0000e+00 - val_loss: 0.9146 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      " - 0s - loss: 1.0202 - acc: 0.0000e+00 - val_loss: 0.9051 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      " - 0s - loss: 1.0069 - acc: 0.0000e+00 - val_loss: 0.8962 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.9937 - acc: 0.0000e+00 - val_loss: 0.8874 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.9803 - acc: 0.0000e+00 - val_loss: 0.8789 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.9683 - acc: 0.0000e+00 - val_loss: 0.8706 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.9562 - acc: 0.0000e+00 - val_loss: 0.8625 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.9448 - acc: 0.0000e+00 - val_loss: 0.8543 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.9329 - acc: 0.0000e+00 - val_loss: 0.8466 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.9219 - acc: 0.0000e+00 - val_loss: 0.8388 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.9097 - acc: 0.0000e+00 - val_loss: 0.8318 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.8995 - acc: 0.0000e+00 - val_loss: 0.8248 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.8899 - acc: 0.0000e+00 - val_loss: 0.8175 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.8786 - acc: 0.0000e+00 - val_loss: 0.8106 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.8684 - acc: 0.0000e+00 - val_loss: 0.8039 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.8590 - acc: 0.0000e+00 - val_loss: 0.7974 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.8493 - acc: 0.0000e+00 - val_loss: 0.7911 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.8394 - acc: 0.0000e+00 - val_loss: 0.7850 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.8304 - acc: 0.0000e+00 - val_loss: 0.7789 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.8212 - acc: 0.0000e+00 - val_loss: 0.7732 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.8126 - acc: 0.0000e+00 - val_loss: 0.7675 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.8035 - acc: 0.0000e+00 - val_loss: 0.7620 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.7949 - acc: 0.0000e+00 - val_loss: 0.7566 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.7867 - acc: 0.0000e+00 - val_loss: 0.7515 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.7795 - acc: 0.0000e+00 - val_loss: 0.7461 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.7708 - acc: 0.0000e+00 - val_loss: 0.7411 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.7635 - acc: 0.0000e+00 - val_loss: 0.7362 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.7555 - acc: 0.0000e+00 - val_loss: 0.7315 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.7487 - acc: 0.0000e+00 - val_loss: 0.7268 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.7410 - acc: 0.0000e+00 - val_loss: 0.7224 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.7338 - acc: 0.0000e+00 - val_loss: 0.7182 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.7271 - acc: 0.0000e+00 - val_loss: 0.7139 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.7208 - acc: 0.0000e+00 - val_loss: 0.7096 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.7134 - acc: 0.0000e+00 - val_loss: 0.7057 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.7073 - acc: 0.0000e+00 - val_loss: 0.7018 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.7008 - acc: 0.0000e+00 - val_loss: 0.6980 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.6951 - acc: 0.0000e+00 - val_loss: 0.6944 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.6889 - acc: 0.0000e+00 - val_loss: 0.6907 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.6830 - acc: 0.0000e+00 - val_loss: 0.6874 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      " - 0s - loss: 0.6772 - acc: 0.0000e+00 - val_loss: 0.6841 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.6718 - acc: 0.0000e+00 - val_loss: 0.6807 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.6665 - acc: 0.0000e+00 - val_loss: 0.6776 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.6608 - acc: 0.0000e+00 - val_loss: 0.6747 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.6558 - acc: 0.0000e+00 - val_loss: 0.6716 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.6508 - acc: 0.0000e+00 - val_loss: 0.6686 - val_acc: 0.0000e+00\n",
      "Test accuracy: 0.0\n",
      "Train on 176 samples, validate on 266 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 5.3148 - acc: 0.0000e+00 - val_loss: 3.6639 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 0s - loss: 4.5647 - acc: 0.0000e+00 - val_loss: 3.1159 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 0s - loss: 3.8448 - acc: 0.0000e+00 - val_loss: 2.6434 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " - 0s - loss: 3.2392 - acc: 0.0000e+00 - val_loss: 2.2378 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      " - 0s - loss: 2.7215 - acc: 0.0000e+00 - val_loss: 1.9033 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      " - 0s - loss: 2.2965 - acc: 0.0000e+00 - val_loss: 1.6285 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.9373 - acc: 0.0000e+00 - val_loss: 1.4080 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1.6528 - acc: 0.0000e+00 - val_loss: 1.2294 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1.4198 - acc: 0.0000e+00 - val_loss: 1.0908 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.2332 - acc: 0.0000e+00 - val_loss: 0.9833 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1.0887 - acc: 0.0000e+00 - val_loss: 0.8992 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.9715 - acc: 0.0000e+00 - val_loss: 0.8368 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.8836 - acc: 0.0000e+00 - val_loss: 0.7885 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.8119 - acc: 0.0000e+00 - val_loss: 0.7533 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.7584 - acc: 0.0000e+00 - val_loss: 0.7261 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.7163 - acc: 0.0000e+00 - val_loss: 0.7058 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.6830 - acc: 0.0000e+00 - val_loss: 0.6909 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.6583 - acc: 0.0000e+00 - val_loss: 0.6789 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.6366 - acc: 0.0000e+00 - val_loss: 0.6702 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.6204 - acc: 0.0000e+00 - val_loss: 0.6629 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.6063 - acc: 0.0000e+00 - val_loss: 0.6562 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.5941 - acc: 0.0000e+00 - val_loss: 0.6508 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.5840 - acc: 0.0000e+00 - val_loss: 0.6459 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.5754 - acc: 0.0000e+00 - val_loss: 0.6416 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.5679 - acc: 0.0000e+00 - val_loss: 0.6373 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.5601 - acc: 0.0000e+00 - val_loss: 0.6332 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.5532 - acc: 0.0000e+00 - val_loss: 0.6294 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.5469 - acc: 0.0000e+00 - val_loss: 0.6251 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.5417 - acc: 0.0000e+00 - val_loss: 0.6222 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.5355 - acc: 0.0000e+00 - val_loss: 0.6188 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.5306 - acc: 0.0000e+00 - val_loss: 0.6152 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.5253 - acc: 0.0000e+00 - val_loss: 0.6121 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.5211 - acc: 0.0000e+00 - val_loss: 0.6086 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.5174 - acc: 0.0000e+00 - val_loss: 0.6057 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.5129 - acc: 0.0000e+00 - val_loss: 0.6024 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.5092 - acc: 0.0000e+00 - val_loss: 0.6004 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.5058 - acc: 0.0000e+00 - val_loss: 0.5978 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.5030 - acc: 0.0000e+00 - val_loss: 0.5953 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4991 - acc: 0.0000e+00 - val_loss: 0.5918 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.4965 - acc: 0.0000e+00 - val_loss: 0.5892 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.4935 - acc: 0.0000e+00 - val_loss: 0.5872 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4911 - acc: 0.0000e+00 - val_loss: 0.5854 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4884 - acc: 0.0000e+00 - val_loss: 0.5830 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4864 - acc: 0.0000e+00 - val_loss: 0.5816 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4844 - acc: 0.0000e+00 - val_loss: 0.5800 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4823 - acc: 0.0000e+00 - val_loss: 0.5779 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4801 - acc: 0.0000e+00 - val_loss: 0.5761 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4785 - acc: 0.0000e+00 - val_loss: 0.5745 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4763 - acc: 0.0000e+00 - val_loss: 0.5727 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4749 - acc: 0.0000e+00 - val_loss: 0.5707 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4737 - acc: 0.0000e+00 - val_loss: 0.5691 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4722 - acc: 0.0000e+00 - val_loss: 0.5679 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.4707 - acc: 0.0000e+00 - val_loss: 0.5670 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4696 - acc: 0.0000e+00 - val_loss: 0.5656 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4683 - acc: 0.0000e+00 - val_loss: 0.5644 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.4676 - acc: 0.0000e+00 - val_loss: 0.5630 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4665 - acc: 0.0000e+00 - val_loss: 0.5622 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4656 - acc: 0.0000e+00 - val_loss: 0.5610 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4643 - acc: 0.0000e+00 - val_loss: 0.5593 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4637 - acc: 0.0000e+00 - val_loss: 0.5579 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4627 - acc: 0.0000e+00 - val_loss: 0.5568 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4620 - acc: 0.0000e+00 - val_loss: 0.5552 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4612 - acc: 0.0000e+00 - val_loss: 0.5550 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4605 - acc: 0.0000e+00 - val_loss: 0.5547 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4596 - acc: 0.0000e+00 - val_loss: 0.5538 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4602 - acc: 0.0000e+00 - val_loss: 0.5532 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4583 - acc: 0.0000e+00 - val_loss: 0.5528 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4586 - acc: 0.0000e+00 - val_loss: 0.5523 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4575 - acc: 0.0000e+00 - val_loss: 0.5518 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4570 - acc: 0.0000e+00 - val_loss: 0.5514 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4568 - acc: 0.0000e+00 - val_loss: 0.5518 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4561 - acc: 0.0000e+00 - val_loss: 0.5506 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4556 - acc: 0.0000e+00 - val_loss: 0.5495 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4553 - acc: 0.0000e+00 - val_loss: 0.5493 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4553 - acc: 0.0000e+00 - val_loss: 0.5489 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4536 - acc: 0.0000e+00 - val_loss: 0.5484 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.4543 - acc: 0.0000e+00 - val_loss: 0.5478 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4531 - acc: 0.0000e+00 - val_loss: 0.5473 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4535 - acc: 0.0000e+00 - val_loss: 0.5472 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4532 - acc: 0.0000e+00 - val_loss: 0.5468 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4521 - acc: 0.0000e+00 - val_loss: 0.5461 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4518 - acc: 0.0000e+00 - val_loss: 0.5462 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      " - 0s - loss: 0.4521 - acc: 0.0000e+00 - val_loss: 0.5458 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4518 - acc: 0.0000e+00 - val_loss: 0.5462 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4518 - acc: 0.0000e+00 - val_loss: 0.5463 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4508 - acc: 0.0000e+00 - val_loss: 0.5458 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.4505 - acc: 0.0000e+00 - val_loss: 0.5452 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4501 - acc: 0.0000e+00 - val_loss: 0.5451 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4499 - acc: 0.0000e+00 - val_loss: 0.5444 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4502 - acc: 0.0000e+00 - val_loss: 0.5440 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4497 - acc: 0.0000e+00 - val_loss: 0.5447 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4493 - acc: 0.0000e+00 - val_loss: 0.5445 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4490 - acc: 0.0000e+00 - val_loss: 0.5443 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4489 - acc: 0.0000e+00 - val_loss: 0.5444 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4488 - acc: 0.0000e+00 - val_loss: 0.5436 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4485 - acc: 0.0000e+00 - val_loss: 0.5435 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4480 - acc: 0.0000e+00 - val_loss: 0.5431 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4476 - acc: 0.0000e+00 - val_loss: 0.5423 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4478 - acc: 0.0000e+00 - val_loss: 0.5421 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4477 - acc: 0.0000e+00 - val_loss: 0.5422 - val_acc: 0.0000e+00\n",
      "Test accuracy: 0.0\n",
      "Train on 176 samples, validate on 266 samples\n",
      "Epoch 1/170\n",
      " - 0s - loss: 1.6608 - acc: 0.0000e+00 - val_loss: 1.1954 - val_acc: 0.0000e+00\n",
      "Epoch 2/170\n",
      " - 0s - loss: 1.6198 - acc: 0.0000e+00 - val_loss: 1.1673 - val_acc: 0.0000e+00\n",
      "Epoch 3/170\n",
      " - 0s - loss: 1.5783 - acc: 0.0000e+00 - val_loss: 1.1391 - val_acc: 0.0000e+00\n",
      "Epoch 4/170\n",
      " - 0s - loss: 1.5354 - acc: 0.0000e+00 - val_loss: 1.1111 - val_acc: 0.0000e+00\n",
      "Epoch 5/170\n",
      " - 0s - loss: 1.4917 - acc: 0.0000e+00 - val_loss: 1.0835 - val_acc: 0.0000e+00\n",
      "Epoch 6/170\n",
      " - 0s - loss: 1.4479 - acc: 0.0000e+00 - val_loss: 1.0568 - val_acc: 0.0000e+00\n",
      "Epoch 7/170\n",
      " - 0s - loss: 1.4080 - acc: 0.0000e+00 - val_loss: 1.0314 - val_acc: 0.0000e+00\n",
      "Epoch 8/170\n",
      " - 0s - loss: 1.3663 - acc: 0.0000e+00 - val_loss: 1.0075 - val_acc: 0.0000e+00\n",
      "Epoch 9/170\n",
      " - 0s - loss: 1.3285 - acc: 0.0000e+00 - val_loss: 0.9844 - val_acc: 0.0000e+00\n",
      "Epoch 10/170\n",
      " - 0s - loss: 1.2912 - acc: 0.0000e+00 - val_loss: 0.9626 - val_acc: 0.0000e+00\n",
      "Epoch 11/170\n",
      " - 0s - loss: 1.2558 - acc: 0.0000e+00 - val_loss: 0.9423 - val_acc: 0.0000e+00\n",
      "Epoch 12/170\n",
      " - 0s - loss: 1.2206 - acc: 0.0000e+00 - val_loss: 0.9232 - val_acc: 0.0000e+00\n",
      "Epoch 13/170\n",
      " - 0s - loss: 1.1898 - acc: 0.0000e+00 - val_loss: 0.9049 - val_acc: 0.0000e+00\n",
      "Epoch 14/170\n",
      " - 0s - loss: 1.1581 - acc: 0.0000e+00 - val_loss: 0.8876 - val_acc: 0.0000e+00\n",
      "Epoch 15/170\n",
      " - 0s - loss: 1.1269 - acc: 0.0000e+00 - val_loss: 0.8714 - val_acc: 0.0000e+00\n",
      "Epoch 16/170\n",
      " - 0s - loss: 1.0976 - acc: 0.0000e+00 - val_loss: 0.8561 - val_acc: 0.0000e+00\n",
      "Epoch 17/170\n",
      " - 0s - loss: 1.0703 - acc: 0.0000e+00 - val_loss: 0.8415 - val_acc: 0.0000e+00\n",
      "Epoch 18/170\n",
      " - 0s - loss: 1.0441 - acc: 0.0000e+00 - val_loss: 0.8275 - val_acc: 0.0000e+00\n",
      "Epoch 19/170\n",
      " - 0s - loss: 1.0197 - acc: 0.0000e+00 - val_loss: 0.8143 - val_acc: 0.0000e+00\n",
      "Epoch 20/170\n",
      " - 0s - loss: 0.9943 - acc: 0.0000e+00 - val_loss: 0.8021 - val_acc: 0.0000e+00\n",
      "Epoch 21/170\n",
      " - 0s - loss: 0.9717 - acc: 0.0000e+00 - val_loss: 0.7905 - val_acc: 0.0000e+00\n",
      "Epoch 22/170\n",
      " - 0s - loss: 0.9492 - acc: 0.0000e+00 - val_loss: 0.7796 - val_acc: 0.0000e+00\n",
      "Epoch 23/170\n",
      " - 0s - loss: 0.9283 - acc: 0.0000e+00 - val_loss: 0.7694 - val_acc: 0.0000e+00\n",
      "Epoch 24/170\n",
      " - 0s - loss: 0.9075 - acc: 0.0000e+00 - val_loss: 0.7597 - val_acc: 0.0000e+00\n",
      "Epoch 25/170\n",
      " - 0s - loss: 0.8876 - acc: 0.0000e+00 - val_loss: 0.7506 - val_acc: 0.0000e+00\n",
      "Epoch 26/170\n",
      " - 0s - loss: 0.8697 - acc: 0.0000e+00 - val_loss: 0.7418 - val_acc: 0.0000e+00\n",
      "Epoch 27/170\n",
      " - 0s - loss: 0.8518 - acc: 0.0000e+00 - val_loss: 0.7335 - val_acc: 0.0000e+00\n",
      "Epoch 28/170\n",
      " - 0s - loss: 0.8337 - acc: 0.0000e+00 - val_loss: 0.7258 - val_acc: 0.0000e+00\n",
      "Epoch 29/170\n",
      " - 0s - loss: 0.8178 - acc: 0.0000e+00 - val_loss: 0.7185 - val_acc: 0.0000e+00\n",
      "Epoch 30/170\n",
      " - 0s - loss: 0.8028 - acc: 0.0000e+00 - val_loss: 0.7116 - val_acc: 0.0000e+00\n",
      "Epoch 31/170\n",
      " - 0s - loss: 0.7874 - acc: 0.0000e+00 - val_loss: 0.7050 - val_acc: 0.0000e+00\n",
      "Epoch 32/170\n",
      " - 0s - loss: 0.7728 - acc: 0.0000e+00 - val_loss: 0.6988 - val_acc: 0.0000e+00\n",
      "Epoch 33/170\n",
      " - 0s - loss: 0.7598 - acc: 0.0000e+00 - val_loss: 0.6930 - val_acc: 0.0000e+00\n",
      "Epoch 34/170\n",
      " - 0s - loss: 0.7465 - acc: 0.0000e+00 - val_loss: 0.6876 - val_acc: 0.0000e+00\n",
      "Epoch 35/170\n",
      " - 0s - loss: 0.7338 - acc: 0.0000e+00 - val_loss: 0.6823 - val_acc: 0.0000e+00\n",
      "Epoch 36/170\n",
      " - 0s - loss: 0.7220 - acc: 0.0000e+00 - val_loss: 0.6771 - val_acc: 0.0000e+00\n",
      "Epoch 37/170\n",
      " - 0s - loss: 0.7107 - acc: 0.0000e+00 - val_loss: 0.6723 - val_acc: 0.0000e+00\n",
      "Epoch 38/170\n",
      " - 0s - loss: 0.6994 - acc: 0.0000e+00 - val_loss: 0.6679 - val_acc: 0.0000e+00\n",
      "Epoch 39/170\n",
      " - 0s - loss: 0.6901 - acc: 0.0000e+00 - val_loss: 0.6636 - val_acc: 0.0000e+00\n",
      "Epoch 40/170\n",
      " - 0s - loss: 0.6789 - acc: 0.0000e+00 - val_loss: 0.6594 - val_acc: 0.0000e+00\n",
      "Epoch 41/170\n",
      " - 0s - loss: 0.6700 - acc: 0.0000e+00 - val_loss: 0.6553 - val_acc: 0.0000e+00\n",
      "Epoch 42/170\n",
      " - 0s - loss: 0.6604 - acc: 0.0000e+00 - val_loss: 0.6515 - val_acc: 0.0000e+00\n",
      "Epoch 43/170\n",
      " - 0s - loss: 0.6513 - acc: 0.0000e+00 - val_loss: 0.6480 - val_acc: 0.0000e+00\n",
      "Epoch 44/170\n",
      " - 0s - loss: 0.6429 - acc: 0.0000e+00 - val_loss: 0.6446 - val_acc: 0.0000e+00\n",
      "Epoch 45/170\n",
      " - 0s - loss: 0.6353 - acc: 0.0000e+00 - val_loss: 0.6414 - val_acc: 0.0000e+00\n",
      "Epoch 46/170\n",
      " - 0s - loss: 0.6268 - acc: 0.0000e+00 - val_loss: 0.6383 - val_acc: 0.0000e+00\n",
      "Epoch 47/170\n",
      " - 0s - loss: 0.6202 - acc: 0.0000e+00 - val_loss: 0.6354 - val_acc: 0.0000e+00\n",
      "Epoch 48/170\n",
      " - 0s - loss: 0.6131 - acc: 0.0000e+00 - val_loss: 0.6325 - val_acc: 0.0000e+00\n",
      "Epoch 49/170\n",
      " - 0s - loss: 0.6055 - acc: 0.0000e+00 - val_loss: 0.6298 - val_acc: 0.0000e+00\n",
      "Epoch 50/170\n",
      " - 0s - loss: 0.5997 - acc: 0.0000e+00 - val_loss: 0.6273 - val_acc: 0.0000e+00\n",
      "Epoch 51/170\n",
      " - 0s - loss: 0.5930 - acc: 0.0000e+00 - val_loss: 0.6248 - val_acc: 0.0000e+00\n",
      "Epoch 52/170\n",
      " - 0s - loss: 0.5877 - acc: 0.0000e+00 - val_loss: 0.6224 - val_acc: 0.0000e+00\n",
      "Epoch 53/170\n",
      " - 0s - loss: 0.5817 - acc: 0.0000e+00 - val_loss: 0.6202 - val_acc: 0.0000e+00\n",
      "Epoch 54/170\n",
      " - 0s - loss: 0.5770 - acc: 0.0000e+00 - val_loss: 0.6180 - val_acc: 0.0000e+00\n",
      "Epoch 55/170\n",
      " - 0s - loss: 0.5716 - acc: 0.0000e+00 - val_loss: 0.6156 - val_acc: 0.0000e+00\n",
      "Epoch 56/170\n",
      " - 0s - loss: 0.5661 - acc: 0.0000e+00 - val_loss: 0.6134 - val_acc: 0.0000e+00\n",
      "Epoch 57/170\n",
      " - 0s - loss: 0.5611 - acc: 0.0000e+00 - val_loss: 0.6114 - val_acc: 0.0000e+00\n",
      "Epoch 58/170\n",
      " - 0s - loss: 0.5568 - acc: 0.0000e+00 - val_loss: 0.6094 - val_acc: 0.0000e+00\n",
      "Epoch 59/170\n",
      " - 0s - loss: 0.5529 - acc: 0.0000e+00 - val_loss: 0.6074 - val_acc: 0.0000e+00\n",
      "Epoch 60/170\n",
      " - 0s - loss: 0.5486 - acc: 0.0000e+00 - val_loss: 0.6057 - val_acc: 0.0000e+00\n",
      "Epoch 61/170\n",
      " - 0s - loss: 0.5443 - acc: 0.0000e+00 - val_loss: 0.6041 - val_acc: 0.0000e+00\n",
      "Epoch 62/170\n",
      " - 0s - loss: 0.5407 - acc: 0.0000e+00 - val_loss: 0.6025 - val_acc: 0.0000e+00\n",
      "Epoch 63/170\n",
      " - 0s - loss: 0.5369 - acc: 0.0000e+00 - val_loss: 0.6009 - val_acc: 0.0000e+00\n",
      "Epoch 64/170\n",
      " - 0s - loss: 0.5335 - acc: 0.0000e+00 - val_loss: 0.5993 - val_acc: 0.0000e+00\n",
      "Epoch 65/170\n",
      " - 0s - loss: 0.5300 - acc: 0.0000e+00 - val_loss: 0.5978 - val_acc: 0.0000e+00\n",
      "Epoch 66/170\n",
      " - 0s - loss: 0.5263 - acc: 0.0000e+00 - val_loss: 0.5965 - val_acc: 0.0000e+00\n",
      "Epoch 67/170\n",
      " - 0s - loss: 0.5231 - acc: 0.0000e+00 - val_loss: 0.5950 - val_acc: 0.0000e+00\n",
      "Epoch 68/170\n",
      " - 0s - loss: 0.5209 - acc: 0.0000e+00 - val_loss: 0.5934 - val_acc: 0.0000e+00\n",
      "Epoch 69/170\n",
      " - 0s - loss: 0.5179 - acc: 0.0000e+00 - val_loss: 0.5922 - val_acc: 0.0000e+00\n",
      "Epoch 70/170\n",
      " - 0s - loss: 0.5144 - acc: 0.0000e+00 - val_loss: 0.5908 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/170\n",
      " - 0s - loss: 0.5124 - acc: 0.0000e+00 - val_loss: 0.5897 - val_acc: 0.0000e+00\n",
      "Epoch 72/170\n",
      " - 0s - loss: 0.5095 - acc: 0.0000e+00 - val_loss: 0.5884 - val_acc: 0.0000e+00\n",
      "Epoch 73/170\n",
      " - 0s - loss: 0.5076 - acc: 0.0000e+00 - val_loss: 0.5872 - val_acc: 0.0000e+00\n",
      "Epoch 74/170\n",
      " - 0s - loss: 0.5050 - acc: 0.0000e+00 - val_loss: 0.5862 - val_acc: 0.0000e+00\n",
      "Epoch 75/170\n",
      " - 0s - loss: 0.5029 - acc: 0.0000e+00 - val_loss: 0.5850 - val_acc: 0.0000e+00\n",
      "Epoch 76/170\n",
      " - 0s - loss: 0.5011 - acc: 0.0000e+00 - val_loss: 0.5838 - val_acc: 0.0000e+00\n",
      "Epoch 77/170\n",
      " - 0s - loss: 0.4985 - acc: 0.0000e+00 - val_loss: 0.5829 - val_acc: 0.0000e+00\n",
      "Epoch 78/170\n",
      " - 0s - loss: 0.4973 - acc: 0.0000e+00 - val_loss: 0.5820 - val_acc: 0.0000e+00\n",
      "Epoch 79/170\n",
      " - 0s - loss: 0.4950 - acc: 0.0000e+00 - val_loss: 0.5809 - val_acc: 0.0000e+00\n",
      "Epoch 80/170\n",
      " - 0s - loss: 0.4927 - acc: 0.0000e+00 - val_loss: 0.5800 - val_acc: 0.0000e+00\n",
      "Epoch 81/170\n",
      " - 0s - loss: 0.4916 - acc: 0.0000e+00 - val_loss: 0.5792 - val_acc: 0.0000e+00\n",
      "Epoch 82/170\n",
      " - 0s - loss: 0.4900 - acc: 0.0000e+00 - val_loss: 0.5783 - val_acc: 0.0000e+00\n",
      "Epoch 83/170\n",
      " - 0s - loss: 0.4878 - acc: 0.0000e+00 - val_loss: 0.5772 - val_acc: 0.0000e+00\n",
      "Epoch 84/170\n",
      " - 0s - loss: 0.4869 - acc: 0.0000e+00 - val_loss: 0.5763 - val_acc: 0.0000e+00\n",
      "Epoch 85/170\n",
      " - 0s - loss: 0.4847 - acc: 0.0000e+00 - val_loss: 0.5756 - val_acc: 0.0000e+00\n",
      "Epoch 86/170\n",
      " - 0s - loss: 0.4837 - acc: 0.0000e+00 - val_loss: 0.5749 - val_acc: 0.0000e+00\n",
      "Epoch 87/170\n",
      " - 0s - loss: 0.4820 - acc: 0.0000e+00 - val_loss: 0.5741 - val_acc: 0.0000e+00\n",
      "Epoch 88/170\n",
      " - 0s - loss: 0.4809 - acc: 0.0000e+00 - val_loss: 0.5735 - val_acc: 0.0000e+00\n",
      "Epoch 89/170\n",
      " - 0s - loss: 0.4797 - acc: 0.0000e+00 - val_loss: 0.5728 - val_acc: 0.0000e+00\n",
      "Epoch 90/170\n",
      " - 0s - loss: 0.4786 - acc: 0.0000e+00 - val_loss: 0.5722 - val_acc: 0.0000e+00\n",
      "Epoch 91/170\n",
      " - 0s - loss: 0.4777 - acc: 0.0000e+00 - val_loss: 0.5713 - val_acc: 0.0000e+00\n",
      "Epoch 92/170\n",
      " - 0s - loss: 0.4763 - acc: 0.0000e+00 - val_loss: 0.5707 - val_acc: 0.0000e+00\n",
      "Epoch 93/170\n",
      " - 0s - loss: 0.4749 - acc: 0.0000e+00 - val_loss: 0.5700 - val_acc: 0.0000e+00\n",
      "Epoch 94/170\n",
      " - 0s - loss: 0.4746 - acc: 0.0000e+00 - val_loss: 0.5694 - val_acc: 0.0000e+00\n",
      "Epoch 95/170\n",
      " - 0s - loss: 0.4732 - acc: 0.0000e+00 - val_loss: 0.5688 - val_acc: 0.0000e+00\n",
      "Epoch 96/170\n",
      " - 0s - loss: 0.4724 - acc: 0.0000e+00 - val_loss: 0.5682 - val_acc: 0.0000e+00\n",
      "Epoch 97/170\n",
      " - 0s - loss: 0.4717 - acc: 0.0000e+00 - val_loss: 0.5678 - val_acc: 0.0000e+00\n",
      "Epoch 98/170\n",
      " - 0s - loss: 0.4714 - acc: 0.0000e+00 - val_loss: 0.5672 - val_acc: 0.0000e+00\n",
      "Epoch 99/170\n",
      " - 0s - loss: 0.4697 - acc: 0.0000e+00 - val_loss: 0.5665 - val_acc: 0.0000e+00\n",
      "Epoch 100/170\n",
      " - 0s - loss: 0.4689 - acc: 0.0000e+00 - val_loss: 0.5660 - val_acc: 0.0000e+00\n",
      "Epoch 101/170\n",
      " - 0s - loss: 0.4683 - acc: 0.0000e+00 - val_loss: 0.5657 - val_acc: 0.0000e+00\n",
      "Epoch 102/170\n",
      " - 0s - loss: 0.4670 - acc: 0.0000e+00 - val_loss: 0.5652 - val_acc: 0.0000e+00\n",
      "Epoch 103/170\n",
      " - 0s - loss: 0.4667 - acc: 0.0000e+00 - val_loss: 0.5648 - val_acc: 0.0000e+00\n",
      "Epoch 104/170\n",
      " - 0s - loss: 0.4656 - acc: 0.0000e+00 - val_loss: 0.5644 - val_acc: 0.0000e+00\n",
      "Epoch 105/170\n",
      " - 0s - loss: 0.4658 - acc: 0.0000e+00 - val_loss: 0.5640 - val_acc: 0.0000e+00\n",
      "Epoch 106/170\n",
      " - 0s - loss: 0.4647 - acc: 0.0000e+00 - val_loss: 0.5635 - val_acc: 0.0000e+00\n",
      "Epoch 107/170\n",
      " - 0s - loss: 0.4637 - acc: 0.0000e+00 - val_loss: 0.5631 - val_acc: 0.0000e+00\n",
      "Epoch 108/170\n",
      " - 0s - loss: 0.4632 - acc: 0.0000e+00 - val_loss: 0.5627 - val_acc: 0.0000e+00\n",
      "Epoch 109/170\n",
      " - 0s - loss: 0.4625 - acc: 0.0000e+00 - val_loss: 0.5623 - val_acc: 0.0000e+00\n",
      "Epoch 110/170\n",
      " - 0s - loss: 0.4623 - acc: 0.0000e+00 - val_loss: 0.5620 - val_acc: 0.0000e+00\n",
      "Epoch 111/170\n",
      " - 0s - loss: 0.4619 - acc: 0.0000e+00 - val_loss: 0.5615 - val_acc: 0.0000e+00\n",
      "Epoch 112/170\n",
      " - 0s - loss: 0.4617 - acc: 0.0000e+00 - val_loss: 0.5612 - val_acc: 0.0000e+00\n",
      "Epoch 113/170\n",
      " - 0s - loss: 0.4606 - acc: 0.0000e+00 - val_loss: 0.5608 - val_acc: 0.0000e+00\n",
      "Epoch 114/170\n",
      " - 0s - loss: 0.4601 - acc: 0.0000e+00 - val_loss: 0.5604 - val_acc: 0.0000e+00\n",
      "Epoch 115/170\n",
      " - 0s - loss: 0.4597 - acc: 0.0000e+00 - val_loss: 0.5600 - val_acc: 0.0000e+00\n",
      "Epoch 116/170\n",
      " - 0s - loss: 0.4595 - acc: 0.0000e+00 - val_loss: 0.5599 - val_acc: 0.0000e+00\n",
      "Epoch 117/170\n",
      " - 0s - loss: 0.4588 - acc: 0.0000e+00 - val_loss: 0.5596 - val_acc: 0.0000e+00\n",
      "Epoch 118/170\n",
      " - 0s - loss: 0.4590 - acc: 0.0000e+00 - val_loss: 0.5594 - val_acc: 0.0000e+00\n",
      "Epoch 119/170\n",
      " - 0s - loss: 0.4580 - acc: 0.0000e+00 - val_loss: 0.5591 - val_acc: 0.0000e+00\n",
      "Epoch 120/170\n",
      " - 0s - loss: 0.4575 - acc: 0.0000e+00 - val_loss: 0.5587 - val_acc: 0.0000e+00\n",
      "Epoch 121/170\n",
      " - 0s - loss: 0.4583 - acc: 0.0000e+00 - val_loss: 0.5585 - val_acc: 0.0000e+00\n",
      "Epoch 122/170\n",
      " - 0s - loss: 0.4569 - acc: 0.0000e+00 - val_loss: 0.5583 - val_acc: 0.0000e+00\n",
      "Epoch 123/170\n",
      " - 0s - loss: 0.4563 - acc: 0.0000e+00 - val_loss: 0.5581 - val_acc: 0.0000e+00\n",
      "Epoch 124/170\n",
      " - 0s - loss: 0.4561 - acc: 0.0000e+00 - val_loss: 0.5578 - val_acc: 0.0000e+00\n",
      "Epoch 125/170\n",
      " - 0s - loss: 0.4555 - acc: 0.0000e+00 - val_loss: 0.5575 - val_acc: 0.0000e+00\n",
      "Epoch 126/170\n",
      " - 0s - loss: 0.4553 - acc: 0.0000e+00 - val_loss: 0.5571 - val_acc: 0.0000e+00\n",
      "Epoch 127/170\n",
      " - 0s - loss: 0.4552 - acc: 0.0000e+00 - val_loss: 0.5568 - val_acc: 0.0000e+00\n",
      "Epoch 128/170\n",
      " - 0s - loss: 0.4547 - acc: 0.0000e+00 - val_loss: 0.5567 - val_acc: 0.0000e+00\n",
      "Epoch 129/170\n",
      " - 0s - loss: 0.4545 - acc: 0.0000e+00 - val_loss: 0.5565 - val_acc: 0.0000e+00\n",
      "Epoch 130/170\n",
      " - 0s - loss: 0.4541 - acc: 0.0000e+00 - val_loss: 0.5564 - val_acc: 0.0000e+00\n",
      "Epoch 131/170\n",
      " - 0s - loss: 0.4539 - acc: 0.0000e+00 - val_loss: 0.5561 - val_acc: 0.0000e+00\n",
      "Epoch 132/170\n",
      " - 0s - loss: 0.4535 - acc: 0.0000e+00 - val_loss: 0.5560 - val_acc: 0.0000e+00\n",
      "Epoch 133/170\n",
      " - 0s - loss: 0.4535 - acc: 0.0000e+00 - val_loss: 0.5560 - val_acc: 0.0000e+00\n",
      "Epoch 134/170\n",
      " - 0s - loss: 0.4529 - acc: 0.0000e+00 - val_loss: 0.5559 - val_acc: 0.0000e+00\n",
      "Epoch 135/170\n",
      " - 0s - loss: 0.4528 - acc: 0.0000e+00 - val_loss: 0.5557 - val_acc: 0.0000e+00\n",
      "Epoch 136/170\n",
      " - 0s - loss: 0.4522 - acc: 0.0000e+00 - val_loss: 0.5556 - val_acc: 0.0000e+00\n",
      "Epoch 137/170\n",
      " - 0s - loss: 0.4526 - acc: 0.0000e+00 - val_loss: 0.5555 - val_acc: 0.0000e+00\n",
      "Epoch 138/170\n",
      " - 0s - loss: 0.4524 - acc: 0.0000e+00 - val_loss: 0.5554 - val_acc: 0.0000e+00\n",
      "Epoch 139/170\n",
      " - 0s - loss: 0.4521 - acc: 0.0000e+00 - val_loss: 0.5554 - val_acc: 0.0000e+00\n",
      "Epoch 140/170\n",
      " - 0s - loss: 0.4519 - acc: 0.0000e+00 - val_loss: 0.5554 - val_acc: 0.0000e+00\n",
      "Epoch 141/170\n",
      " - 0s - loss: 0.4515 - acc: 0.0000e+00 - val_loss: 0.5553 - val_acc: 0.0000e+00\n",
      "Epoch 142/170\n",
      " - 0s - loss: 0.4516 - acc: 0.0000e+00 - val_loss: 0.5551 - val_acc: 0.0000e+00\n",
      "Epoch 143/170\n",
      " - 0s - loss: 0.4515 - acc: 0.0000e+00 - val_loss: 0.5549 - val_acc: 0.0000e+00\n",
      "Epoch 144/170\n",
      " - 0s - loss: 0.4512 - acc: 0.0000e+00 - val_loss: 0.5548 - val_acc: 0.0000e+00\n",
      "Epoch 145/170\n",
      " - 0s - loss: 0.4509 - acc: 0.0000e+00 - val_loss: 0.5547 - val_acc: 0.0000e+00\n",
      "Epoch 146/170\n",
      " - 0s - loss: 0.4504 - acc: 0.0000e+00 - val_loss: 0.5544 - val_acc: 0.0000e+00\n",
      "Epoch 147/170\n",
      " - 0s - loss: 0.4505 - acc: 0.0000e+00 - val_loss: 0.5543 - val_acc: 0.0000e+00\n",
      "Epoch 148/170\n",
      " - 0s - loss: 0.4498 - acc: 0.0000e+00 - val_loss: 0.5542 - val_acc: 0.0000e+00\n",
      "Epoch 149/170\n",
      " - 0s - loss: 0.4496 - acc: 0.0000e+00 - val_loss: 0.5541 - val_acc: 0.0000e+00\n",
      "Epoch 150/170\n",
      " - 0s - loss: 0.4496 - acc: 0.0000e+00 - val_loss: 0.5542 - val_acc: 0.0000e+00\n",
      "Epoch 151/170\n",
      " - 0s - loss: 0.4498 - acc: 0.0000e+00 - val_loss: 0.5544 - val_acc: 0.0000e+00\n",
      "Epoch 152/170\n",
      " - 0s - loss: 0.4494 - acc: 0.0000e+00 - val_loss: 0.5542 - val_acc: 0.0000e+00\n",
      "Epoch 153/170\n",
      " - 0s - loss: 0.4491 - acc: 0.0000e+00 - val_loss: 0.5542 - val_acc: 0.0000e+00\n",
      "Epoch 154/170\n",
      " - 0s - loss: 0.4495 - acc: 0.0000e+00 - val_loss: 0.5541 - val_acc: 0.0000e+00\n",
      "Epoch 155/170\n",
      " - 0s - loss: 0.4489 - acc: 0.0000e+00 - val_loss: 0.5541 - val_acc: 0.0000e+00\n",
      "Epoch 156/170\n",
      " - 0s - loss: 0.4492 - acc: 0.0000e+00 - val_loss: 0.5542 - val_acc: 0.0000e+00\n",
      "Epoch 157/170\n",
      " - 0s - loss: 0.4486 - acc: 0.0000e+00 - val_loss: 0.5541 - val_acc: 0.0000e+00\n",
      "Epoch 158/170\n",
      " - 0s - loss: 0.4492 - acc: 0.0000e+00 - val_loss: 0.5542 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/170\n",
      " - 0s - loss: 0.4482 - acc: 0.0000e+00 - val_loss: 0.5541 - val_acc: 0.0000e+00\n",
      "Epoch 160/170\n",
      " - 0s - loss: 0.4480 - acc: 0.0000e+00 - val_loss: 0.5538 - val_acc: 0.0000e+00\n",
      "Epoch 161/170\n",
      " - 0s - loss: 0.4490 - acc: 0.0000e+00 - val_loss: 0.5537 - val_acc: 0.0000e+00\n",
      "Epoch 162/170\n",
      " - 0s - loss: 0.4478 - acc: 0.0000e+00 - val_loss: 0.5535 - val_acc: 0.0000e+00\n",
      "Epoch 163/170\n",
      " - 0s - loss: 0.4477 - acc: 0.0000e+00 - val_loss: 0.5535 - val_acc: 0.0000e+00\n",
      "Epoch 164/170\n",
      " - 0s - loss: 0.4482 - acc: 0.0000e+00 - val_loss: 0.5533 - val_acc: 0.0000e+00\n",
      "Epoch 165/170\n",
      " - 0s - loss: 0.4470 - acc: 0.0000e+00 - val_loss: 0.5532 - val_acc: 0.0000e+00\n",
      "Epoch 166/170\n",
      " - 0s - loss: 0.4468 - acc: 0.0000e+00 - val_loss: 0.5532 - val_acc: 0.0000e+00\n",
      "Epoch 167/170\n",
      " - 0s - loss: 0.4473 - acc: 0.0000e+00 - val_loss: 0.5530 - val_acc: 0.0000e+00\n",
      "Epoch 168/170\n",
      " - 0s - loss: 0.4469 - acc: 0.0000e+00 - val_loss: 0.5531 - val_acc: 0.0000e+00\n",
      "Epoch 169/170\n",
      " - 0s - loss: 0.4471 - acc: 0.0000e+00 - val_loss: 0.5531 - val_acc: 0.0000e+00\n",
      "Epoch 170/170\n",
      " - 0s - loss: 0.4465 - acc: 0.0000e+00 - val_loss: 0.5529 - val_acc: 0.0000e+00\n",
      "Test accuracy: 0.0\n",
      "Train on 176 samples, validate on 266 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 0.9854 - acc: 0.0000e+00 - val_loss: 1.0209 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.9266 - acc: 0.0000e+00 - val_loss: 0.9717 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.8710 - acc: 0.0000e+00 - val_loss: 0.9245 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.8180 - acc: 0.0000e+00 - val_loss: 0.8819 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.7710 - acc: 0.0000e+00 - val_loss: 0.8439 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.7329 - acc: 0.0000e+00 - val_loss: 0.8104 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.6979 - acc: 0.0000e+00 - val_loss: 0.7813 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.6689 - acc: 0.0000e+00 - val_loss: 0.7563 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.6426 - acc: 0.0000e+00 - val_loss: 0.7350 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.6217 - acc: 0.0000e+00 - val_loss: 0.7159 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.6018 - acc: 0.0000e+00 - val_loss: 0.6993 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.5846 - acc: 0.0000e+00 - val_loss: 0.6846 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.5705 - acc: 0.0000e+00 - val_loss: 0.6716 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.5564 - acc: 0.0000e+00 - val_loss: 0.6601 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.5446 - acc: 0.0000e+00 - val_loss: 0.6497 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.5343 - acc: 0.0000e+00 - val_loss: 0.6404 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.5245 - acc: 0.0000e+00 - val_loss: 0.6321 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.5153 - acc: 0.0000e+00 - val_loss: 0.6249 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.5079 - acc: 0.0000e+00 - val_loss: 0.6182 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.5003 - acc: 0.0000e+00 - val_loss: 0.6125 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.4939 - acc: 0.0000e+00 - val_loss: 0.6072 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.4890 - acc: 0.0000e+00 - val_loss: 0.6026 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.4835 - acc: 0.0000e+00 - val_loss: 0.5985 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.4791 - acc: 0.0000e+00 - val_loss: 0.5949 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.4749 - acc: 0.0000e+00 - val_loss: 0.5917 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.4711 - acc: 0.0000e+00 - val_loss: 0.5889 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.4675 - acc: 0.0000e+00 - val_loss: 0.5863 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.4650 - acc: 0.0000e+00 - val_loss: 0.5840 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.4624 - acc: 0.0000e+00 - val_loss: 0.5820 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.4604 - acc: 0.0000e+00 - val_loss: 0.5802 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.4578 - acc: 0.0000e+00 - val_loss: 0.5787 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.4561 - acc: 0.0000e+00 - val_loss: 0.5774 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.4540 - acc: 0.0000e+00 - val_loss: 0.5761 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.4531 - acc: 0.0000e+00 - val_loss: 0.5750 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.4513 - acc: 0.0000e+00 - val_loss: 0.5741 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.4501 - acc: 0.0000e+00 - val_loss: 0.5734 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.4492 - acc: 0.0000e+00 - val_loss: 0.5727 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.4480 - acc: 0.0000e+00 - val_loss: 0.5721 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.4470 - acc: 0.0000e+00 - val_loss: 0.5716 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.4469 - acc: 0.0000e+00 - val_loss: 0.5712 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.4456 - acc: 0.0000e+00 - val_loss: 0.5708 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.4454 - acc: 0.0000e+00 - val_loss: 0.5703 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.4445 - acc: 0.0000e+00 - val_loss: 0.5700 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.4448 - acc: 0.0000e+00 - val_loss: 0.5696 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.4437 - acc: 0.0000e+00 - val_loss: 0.5693 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.4434 - acc: 0.0000e+00 - val_loss: 0.5692 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.4431 - acc: 0.0000e+00 - val_loss: 0.5691 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.4427 - acc: 0.0000e+00 - val_loss: 0.5690 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.4423 - acc: 0.0000e+00 - val_loss: 0.5689 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.4421 - acc: 0.0000e+00 - val_loss: 0.5688 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.4427 - acc: 0.0000e+00 - val_loss: 0.5685 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.4414 - acc: 0.0000e+00 - val_loss: 0.5683 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.4413 - acc: 0.0000e+00 - val_loss: 0.5682 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.4413 - acc: 0.0000e+00 - val_loss: 0.5680 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.4408 - acc: 0.0000e+00 - val_loss: 0.5680 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.4408 - acc: 0.0000e+00 - val_loss: 0.5679 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.4407 - acc: 0.0000e+00 - val_loss: 0.5679 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.4403 - acc: 0.0000e+00 - val_loss: 0.5680 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.4411 - acc: 0.0000e+00 - val_loss: 0.5679 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.4405 - acc: 0.0000e+00 - val_loss: 0.5680 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.4401 - acc: 0.0000e+00 - val_loss: 0.5679 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.4399 - acc: 0.0000e+00 - val_loss: 0.5680 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.4398 - acc: 0.0000e+00 - val_loss: 0.5680 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.4400 - acc: 0.0000e+00 - val_loss: 0.5680 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.4396 - acc: 0.0000e+00 - val_loss: 0.5679 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.4403 - acc: 0.0000e+00 - val_loss: 0.5678 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.4400 - acc: 0.0000e+00 - val_loss: 0.5677 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.4404 - acc: 0.0000e+00 - val_loss: 0.5678 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.4397 - acc: 0.0000e+00 - val_loss: 0.5678 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.4394 - acc: 0.0000e+00 - val_loss: 0.5677 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.4394 - acc: 0.0000e+00 - val_loss: 0.5676 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.4388 - acc: 0.0000e+00 - val_loss: 0.5675 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.4392 - acc: 0.0000e+00 - val_loss: 0.5674 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.4396 - acc: 0.0000e+00 - val_loss: 0.5672 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.4389 - acc: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.4393 - acc: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      " - 0s - loss: 0.4392 - acc: 0.0000e+00 - val_loss: 0.5671 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.4391 - acc: 0.0000e+00 - val_loss: 0.5669 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.4399 - acc: 0.0000e+00 - val_loss: 0.5669 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.4392 - acc: 0.0000e+00 - val_loss: 0.5668 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.4390 - acc: 0.0000e+00 - val_loss: 0.5666 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.4388 - acc: 0.0000e+00 - val_loss: 0.5664 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.4388 - acc: 0.0000e+00 - val_loss: 0.5661 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.4387 - acc: 0.0000e+00 - val_loss: 0.5663 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.4386 - acc: 0.0000e+00 - val_loss: 0.5663 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.4388 - acc: 0.0000e+00 - val_loss: 0.5662 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.4384 - acc: 0.0000e+00 - val_loss: 0.5663 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.4386 - acc: 0.0000e+00 - val_loss: 0.5661 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.4395 - acc: 0.0000e+00 - val_loss: 0.5659 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.4382 - acc: 0.0000e+00 - val_loss: 0.5661 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.4390 - acc: 0.0000e+00 - val_loss: 0.5660 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.4386 - acc: 0.0000e+00 - val_loss: 0.5660 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.4388 - acc: 0.0000e+00 - val_loss: 0.5659 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.4392 - acc: 0.0000e+00 - val_loss: 0.5659 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.4387 - acc: 0.0000e+00 - val_loss: 0.5658 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.4381 - acc: 0.0000e+00 - val_loss: 0.5657 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.4388 - acc: 0.0000e+00 - val_loss: 0.5654 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.4386 - acc: 0.0000e+00 - val_loss: 0.5654 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.4387 - acc: 0.0000e+00 - val_loss: 0.5652 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.4379 - acc: 0.0000e+00 - val_loss: 0.5652 - val_acc: 0.0000e+00\n",
      "Test accuracy: 0.0\n",
      "Evalutation of best performing model:\n",
      "266/266 [==============================] - 0s 4us/step\n",
      "[0.5605926444207815, 0.0]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def data():\n",
    "    '''\n",
    "    Data providing function:\n",
    "\n",
    "    Make sure to have every relevant import statement included here and return data as\n",
    "    used in model function below. This function is separated from model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    '''\n",
    "    from os import path\n",
    "    import pandas as pd\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    url = \"../data/diabetes.csv\"\n",
    "    data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "    sc = StandardScaler()\n",
    "    data = sc.fit_transform(data)\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "    X = data.iloc[:,:-1]\n",
    "    Y = data.iloc[:,-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def model(x_train, y_train, x_test, y_test):\n",
    "    '''\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    '''\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=10, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer={{choice(['adam', 'nadam'])}})\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size={{choice([10, 30])}},\n",
    "              epochs={{choice([100, 170])}},\n",
    "              verbose=2,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='experiment')\n",
    "x_train, y_train, x_test, y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Hyperas(LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LogisticRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imly import dope\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LogisticRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import boto\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import sys\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from boto.s3.key import Key\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.utils.validation import column_or_1d\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LogisticRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from utils.losses import lda_loss\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import copy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import datasets\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import experiment_automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LinearRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import mean_squared_error\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import experiment_automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import re\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from automation_script import get_dataset_info\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imly import dope\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from utils.correlations import concordance_correlation_coefficient as ccc\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.linear_model import LinearRegression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from imly import dope\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from utils.correlations import concordance_correlation_coefficient as ccc\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import boto\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import sys\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from boto.s3.key import Key\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.datasets import make_regression\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import theano.tensor as T\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import theano\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from theano.compile.ops import as_op\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import automation_script\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from os import path\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.regularizers import l2\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'optimizer': hp.choice('optimizer', ['adam', 'nadam']),\n",
      "        'batch_size': hp.choice('batch_size', [10]),\n",
      "        'epochs': hp.choice('epochs', [100]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: '''\n",
      "  3: Data providing function:\n",
      "  4: \n",
      "  5: Make sure to have every relevant import statement included here and return data as\n",
      "  6: used in model function below. This function is separated from model() so that hyperopt\n",
      "  7: won't reload data for each evaluation run.\n",
      "  8: '''\n",
      "  9: url = \"../data/iris.csv\"\n",
      " 10: data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
      " 11: class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
      " 12: data.iloc[:,-1] = index\n",
      " 13: data = data.loc[data[4] != 2]\n",
      " 14: X = data.iloc[:,:-1]\n",
      " 15: Y = data.iloc[:,-1]\n",
      " 16: x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
      " 17: \n",
      " 18: \n",
      " 19: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     '''\n",
      "   4:     Model providing function:\n",
      "   5: \n",
      "   6:     Create Keras model with double curly brackets dropped-in as needed.\n",
      "   7:     Return value has to be a valid python dictionary with two customary keys:\n",
      "   8:         - loss: Specify a numeric evaluation metric to be minimized\n",
      "   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
      "  10:     The last one is optional, though recommended, namely:\n",
      "  11:         - model: specify the model just created so that we can later use it again.\n",
      "  12:     '''\n",
      "  13: \n",
      "  14:     model = Sequential()\n",
      "  15:     model.add(Dense(1, input_dim=4, activation='sigmoid',\n",
      "  16:                    kernel_regularizer=l2(1e-5)))\n",
      "  17: \n",
      "  18:     model.compile(loss=lda_loss(n_components=1, margin=1),\n",
      "  19:                  optimizer=space['optimizer'],\n",
      "  20:                  metrics=['accuracy'])\n",
      "  21: \n",
      "  22:     model.fit(x_train, y_train,\n",
      "  23:               batch_size=space['batch_size'],\n",
      "  24:               epochs=space['epochs'],\n",
      "  25:               verbose=2,\n",
      "  26:               validation_data=(x_test, y_test))\n",
      "  27:     score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
      "  28:     print('Test accuracy:', acc)\n",
      "  29:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  30: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40 samples, validate on 60 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shakk\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\compile\\nanguardmode.py:150: RuntimeWarning: All-NaN slice encountered\n",
      "  return np.isinf(np.nanmax(arr)) or np.isinf(np.nanmin(arr))\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "NaN detected\nNanGuardMode found an error in the output of a node in this variable:\nElemwise{true_div,no_inplace} [id A] ''   \n |Dot22 [id B] ''   \n | |InplaceDimShuffle{1,0} [id C] ''   \n | | |Elemwise{Sub}[(0, 0)] [id D] ''   \n | |   |AdvancedSubtensor1 [id E] ''   \n | |   | |<TensorType(float32, matrix)> [id F]\n | |   | |Subtensor{int64} [id G] ''   \n | |   |   |Nonzero [id H] ''   \n | |   |   | |<TensorType(bool, vector)> [id I]\n | |   |   |Constant{0} [id J]\n | |   |Elemwise{TrueDiv}[(0, 0)] [id K] ''   \n | |     |InplaceDimShuffle{x,0} [id L] ''   \n | |     | |Sum{axis=[0], acc_dtype=float64} [id M] ''   \n | |     |   |AdvancedSubtensor1 [id E] ''   \n | |     |Elemwise{Cast{float32}} [id N] ''   \n | |       |InplaceDimShuffle{x,x} [id O] ''   \n | |         |Shape_i{1} [id P] ''   \n | |           |Nonzero [id H] ''   \n | |Elemwise{Sub}[(0, 0)] [id D] ''   \n |Elemwise{Add}[(0, 1)] [id Q] ''   \n   |TensorConstant{(1, 1) of -1.0} [id R]\n   |Elemwise{Cast{float32}} [id N] ''   \n\n\n\nApply node that caused the error: Elemwise{true_div,no_inplace}(Dot22.0, Elemwise{Add}[(0, 1)].0)\nToposort index: 13\nInputs types: [TensorType(float32, matrix), TensorType(float32, (True, True))]\nInputs shapes: [(1, 1), (1, 1)]\nInputs strides: [(4, 4), (4, 4)]\nInputs values: [array([[0.]], dtype=float32), array([[0.]], dtype=float32)]\nOutputs clients: [['output']]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: for{cpu,scan_fn}(Shape_i{0}.0, Elemwise{eq,no_inplace}.0, Shape_i{0}.0, Elemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0)\nToposort index: 70\nInputs types: [TensorType(int64, scalar), TensorType(bool, matrix), TensorType(int64, scalar), TensorType(float32, matrix)]\nInputs shapes: [(), (2, 10), (), (10, 1)]\nInputs strides: [(), (10, 1), (), (4, 4)]\nInputs values: [array(2, dtype=int64), 'not shown', array(2, dtype=int64), 'not shown']\nOutputs clients: [[Sum{axis=[0], acc_dtype=float64}(for{cpu,scan_fn}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, output_subset)\u001b[0m\n\u001b[0;32m    489\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_thunk_of_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_apply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m                         \u001b[1;32mdel\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36mrun_thunk_of_node\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mstorage_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\compile\\nanguardmode.py\u001b[0m in \u001b[0;36mnan_check\u001b[1;34m(node, thunk, storage_map, compute_map)\u001b[0m\n\u001b[0;32m    272\u001b[0m                         getattr(var.tag, 'nan_guard_mode_check', True)):\n\u001b[1;32m--> 273\u001b[1;33m                     \u001b[0mdo_check_on\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\compile\\nanguardmode.py\u001b[0m in \u001b[0;36mdo_check_on\u001b[1;34m(value, nd, var)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNanGuardMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNanGuardMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pdb'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: NaN detected\nNanGuardMode found an error in the output of a node in this variable:\nElemwise{true_div,no_inplace} [id A] ''   \n |Dot22 [id B] ''   \n | |InplaceDimShuffle{1,0} [id C] ''   \n | | |Elemwise{Sub}[(0, 0)] [id D] ''   \n | |   |AdvancedSubtensor1 [id E] ''   \n | |   | |<TensorType(float32, matrix)> [id F]\n | |   | |Subtensor{int64} [id G] ''   \n | |   |   |Nonzero [id H] ''   \n | |   |   | |<TensorType(bool, vector)> [id I]\n | |   |   |Constant{0} [id J]\n | |   |Elemwise{TrueDiv}[(0, 0)] [id K] ''   \n | |     |InplaceDimShuffle{x,0} [id L] ''   \n | |     | |Sum{axis=[0], acc_dtype=float64} [id M] ''   \n | |     |   |AdvancedSubtensor1 [id E] ''   \n | |     |Elemwise{Cast{float32}} [id N] ''   \n | |       |InplaceDimShuffle{x,x} [id O] ''   \n | |         |Shape_i{1} [id P] ''   \n | |           |Nonzero [id H] ''   \n | |Elemwise{Sub}[(0, 0)] [id D] ''   \n |Elemwise{Add}[(0, 1)] [id Q] ''   \n   |TensorConstant{(1, 1) of -1.0} [id R]\n   |Elemwise{Cast{float32}} [id N] ''   \n\n\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 963\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    964\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36mp\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    951\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m                                                 self, node)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, output_subset)\u001b[0m\n\u001b[0;32m    522\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_apply\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m                             storage_map=storage_map)\n\u001b[0m\u001b[0;32m    524\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcurrent_apply\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, output_subset)\u001b[0m\n\u001b[0;32m    489\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_thunk_of_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_apply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m                         \u001b[1;32mdel\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36mrun_thunk_of_node\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mstorage_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m             )\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\compile\\nanguardmode.py\u001b[0m in \u001b[0;36mnan_check\u001b[1;34m(node, thunk, storage_map, compute_map)\u001b[0m\n\u001b[0;32m    272\u001b[0m                         getattr(var.tag, 'nan_guard_mode_check', True)):\n\u001b[1;32m--> 273\u001b[1;33m                     \u001b[0mdo_check_on\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\compile\\nanguardmode.py\u001b[0m in \u001b[0;36mdo_check_on\u001b[1;34m(value, nd, var)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNanGuardMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNanGuardMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pdb'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: NaN detected\nNanGuardMode found an error in the output of a node in this variable:\nElemwise{true_div,no_inplace} [id A] ''   \n |Dot22 [id B] ''   \n | |InplaceDimShuffle{1,0} [id C] ''   \n | | |Elemwise{Sub}[(0, 0)] [id D] ''   \n | |   |AdvancedSubtensor1 [id E] ''   \n | |   | |<TensorType(float32, matrix)> [id F]\n | |   | |Subtensor{int64} [id G] ''   \n | |   |   |Nonzero [id H] ''   \n | |   |   | |<TensorType(bool, vector)> [id I]\n | |   |   |Constant{0} [id J]\n | |   |Elemwise{TrueDiv}[(0, 0)] [id K] ''   \n | |     |InplaceDimShuffle{x,0} [id L] ''   \n | |     | |Sum{axis=[0], acc_dtype=float64} [id M] ''   \n | |     |   |AdvancedSubtensor1 [id E] ''   \n | |     |Elemwise{Cast{float32}} [id N] ''   \n | |       |InplaceDimShuffle{x,x} [id O] ''   \n | |         |Shape_i{1} [id P] ''   \n | |           |Nonzero [id H] ''   \n | |Elemwise{Sub}[(0, 0)] [id D] ''   \n |Elemwise{Add}[(0, 1)] [id Q] ''   \n   |TensorConstant{(1, 1) of -1.0} [id R]\n   |Elemwise{Cast{float32}} [id N] ''   \n\n\n\nApply node that caused the error: Elemwise{true_div,no_inplace}(Dot22.0, Elemwise{Add}[(0, 1)].0)\nToposort index: 13\nInputs types: [TensorType(float32, matrix), TensorType(float32, (True, True))]\nInputs shapes: [(1, 1), (1, 1)]\nInputs strides: [(4, 4), (4, 4)]\nInputs values: [array([[0.]], dtype=float32), array([[0.]], dtype=float32)]\nOutputs clients: [['output']]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bd9e63ea320b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                       notebook_name='experiment')\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Evalutation of best performing model:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                      verbose=verbose)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m    131\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m              return_argmin=True),\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    365\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m         )\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    383\u001b[0m                     max_queue_len=max_queue_len)\n\u001b[0;32m    384\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLSquare\\cook-imly\\imly\\temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[1;34m(space)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1388\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    918\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    690\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 963\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    964\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\scan_module\\scan_op.py\u001b[0m in \u001b[0;36mp\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    950\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m                                                 self, node)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, output_subset)\u001b[0m\n\u001b[0;32m    521\u001b[0m                             \u001b[0mcurrent_apply\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_apply\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m                             storage_map=storage_map)\n\u001b[0m\u001b[0;32m    524\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcurrent_apply\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                         \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    690\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, output_subset)\u001b[0m\n\u001b[0;32m    488\u001b[0m                     \u001b[1;31m# -- Non-lazy case: have inputs, time to compute outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_thunk_of_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_apply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m                         \u001b[1;32mdel\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_global_stats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36mrun_thunk_of_node\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                 \u001b[0mstorage_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m             )\n\u001b[0;32m    407\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\compile\\nanguardmode.py\u001b[0m in \u001b[0;36mnan_check\u001b[1;34m(node, thunk, storage_map, compute_map)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 if (compute_map[var][0] and\n\u001b[0;32m    272\u001b[0m                         getattr(var.tag, 'nan_guard_mode_check', True)):\n\u001b[1;32m--> 273\u001b[1;33m                     \u001b[0mdo_check_on\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mnan_check_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\theano\\compile\\nanguardmode.py\u001b[0m in \u001b[0;36mdo_check_on\u001b[1;34m(value, nd, var)\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNanGuardMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNanGuardMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pdb'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: NaN detected\nNanGuardMode found an error in the output of a node in this variable:\nElemwise{true_div,no_inplace} [id A] ''   \n |Dot22 [id B] ''   \n | |InplaceDimShuffle{1,0} [id C] ''   \n | | |Elemwise{Sub}[(0, 0)] [id D] ''   \n | |   |AdvancedSubtensor1 [id E] ''   \n | |   | |<TensorType(float32, matrix)> [id F]\n | |   | |Subtensor{int64} [id G] ''   \n | |   |   |Nonzero [id H] ''   \n | |   |   | |<TensorType(bool, vector)> [id I]\n | |   |   |Constant{0} [id J]\n | |   |Elemwise{TrueDiv}[(0, 0)] [id K] ''   \n | |     |InplaceDimShuffle{x,0} [id L] ''   \n | |     | |Sum{axis=[0], acc_dtype=float64} [id M] ''   \n | |     |   |AdvancedSubtensor1 [id E] ''   \n | |     |Elemwise{Cast{float32}} [id N] ''   \n | |       |InplaceDimShuffle{x,x} [id O] ''   \n | |         |Shape_i{1} [id P] ''   \n | |           |Nonzero [id H] ''   \n | |Elemwise{Sub}[(0, 0)] [id D] ''   \n |Elemwise{Add}[(0, 1)] [id Q] ''   \n   |TensorConstant{(1, 1) of -1.0} [id R]\n   |Elemwise{Cast{float32}} [id N] ''   \n\n\n\nApply node that caused the error: Elemwise{true_div,no_inplace}(Dot22.0, Elemwise{Add}[(0, 1)].0)\nToposort index: 13\nInputs types: [TensorType(float32, matrix), TensorType(float32, (True, True))]\nInputs shapes: [(1, 1), (1, 1)]\nInputs strides: [(4, 4), (4, 4)]\nInputs values: [array([[0.]], dtype=float32), array([[0.]], dtype=float32)]\nOutputs clients: [['output']]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.\nApply node that caused the error: for{cpu,scan_fn}(Shape_i{0}.0, Elemwise{eq,no_inplace}.0, Shape_i{0}.0, Elemwise{Composite{scalar_sigmoid((i0 + i1))}}[(0, 0)].0)\nToposort index: 70\nInputs types: [TensorType(int64, scalar), TensorType(bool, matrix), TensorType(int64, scalar), TensorType(float32, matrix)]\nInputs shapes: [(), (2, 10), (), (10, 1)]\nInputs strides: [(), (10, 1), (), (4, 4)]\nInputs values: [array(2, dtype=int64), 'not shown', array(2, dtype=int64), 'not shown']\nOutputs clients: [[Sum{axis=[0], acc_dtype=float64}(for{cpu,scan_fn}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.regularizers import l2\n",
    "from utils.losses import lda_loss\n",
    "\n",
    "def data():\n",
    "    '''\n",
    "    Data providing function:\n",
    "\n",
    "    Make sure to have every relevant import statement included here and return data as\n",
    "    used in model function below. This function is separated from model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    '''\n",
    "    url = \"../data/iris.csv\"\n",
    "    data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "    class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "    data.iloc[:,-1] = index\n",
    "    data = data.loc[data[4] != 2]\n",
    "    X = data.iloc[:,:-1]\n",
    "    Y = data.iloc[:,-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def model(x_train, y_train, x_test, y_test):\n",
    "    '''\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    '''\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1, input_dim=4, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-5)))\n",
    "\n",
    "    model.compile(loss=lda_loss(n_components=1, margin=1),\n",
    "                 optimizer={{choice(['adam', 'nadam'])}},\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size={{choice([10])}},\n",
    "              epochs={{choice([100])}},\n",
    "              verbose=2,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='experiment')\n",
    "x_train, y_train, x_test, y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = \"../data/iris.csv\"\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def make_model(config):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1, input_dim=4, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 11:23:48,162\tINFO node.py:278 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-02-25_11-23-46_9918/logs.\n",
      "2019-02-25 11:23:48,275\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:23634 to respond...\n",
      "2019-02-25 11:23:48,394\tINFO services.py:396 -- Waiting for redis server at 127.0.0.1:51440 to respond...\n",
      "2019-02-25 11:23:48,396\tINFO services.py:798 -- Starting Redis shard with 10.0 GB max memory.\n",
      "2019-02-25 11:23:48,431\tINFO services.py:1360 -- Starting the Plasma object store with 3.2851689470000003 GB memory using /dev/shm.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui.ipynb?token=7e1c769c9dbab3c86415c6ebfb51e2d1bc8bf762fe807762\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': None,\n",
       " 'redis_address': '192.168.1.4:23634',\n",
       " 'object_store_address': '/tmp/ray/session_2019-02-25_11-23-46_9918/sockets/plasma_store',\n",
       " 'webui_url': 'http://localhost:8889/notebooks/ray_ui.ipynb?token=7e1c769c9dbab3c86415c6ebfb51e2d1bc8bf762fe807762',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-02-25_11-23-46_9918/sockets/raylet'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize tune\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the signature of your function to match that of Tune #\n",
    "def train_iris_tune(config, reporter):\n",
    "    model = make_model(config)\n",
    "    last_checkpoint = \"weights_tune_{}.h5\".format(config)\n",
    "    model.save_weights(last_checkpoint)\n",
    "    accuracy = model.evaluate(x_train, y_train)[1]\n",
    "    reporter(mean_accuracy=accuracy, checkpoint=last_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define experiment config\n",
    "configuration = tune.Experiment(\n",
    "    \"experiment_name\",\n",
    "    run=train_iris_tune,\n",
    "    resources_per_trial={\"cpu\": 4},\n",
    "    stop={\"mean_accuracy\": 95},  # TODO: Part 1\n",
    "    config={\n",
    "        \"optimizer\": tune.grid_search(['adam', 'nadam']),\n",
    "        \"activation\": {\n",
    "            \"grid_search\": ['relu', 'sigmoid']\n",
    "        }\n",
    "    }  # TODO: Part 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-25 11:25:06,155\tINFO tune.py:135 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run_experiments()\n",
      "2019-02-25 11:25:06,156\tINFO tune.py:145 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/8.2 GB\n",
      "\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/8 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.9/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_iris_tune_1_activation=sigmoid,optimizer=adam:\tPENDING\n",
      " - train_iris_tune_2_activation=relu,optimizer=nadam:\tPENDING\n",
      " - train_iris_tune_3_activation=sigmoid,optimizer=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_iris_tune_0_activation=relu,optimizer=adam:\tRUNNING\n",
      "\n",
      "Result for train_iris_tune_1_activation=sigmoid,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''optimizer'': ''adam'', ''activation'': ''sigmoid''}.h5'\n",
      "  date: 2019-02-25_11-25-09\n",
      "  done: false\n",
      "  experiment_id: 43f472c81d014bc59faf5e66095953b5\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.45\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 9955\n",
      "  time_since_restore: 2.002084493637085\n",
      "  time_this_iter_s: 2.002084493637085\n",
      "  time_total_s: 2.002084493637085\n",
      "  timestamp: 1551074109\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_iris_tune_0_activation=relu,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''optimizer'': ''adam'', ''activation'': ''relu''}.h5'\n",
      "  date: 2019-02-25_11-25-10\n",
      "  done: false\n",
      "  experiment_id: 3aae8497d0a04586b604e74d24398ce3\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.45\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 9958\n",
      "  time_since_restore: 3.0030441284179688\n",
      "  time_this_iter_s: 3.0030441284179688\n",
      "  time_total_s: 3.0030441284179688\n",
      "  timestamp: 1551074110\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_iris_tune_1_activation=sigmoid,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''optimizer'': ''adam'', ''activation'': ''sigmoid''}.h5'\n",
      "  date: 2019-02-25_11-25-10\n",
      "  done: true\n",
      "  experiment_id: 43f472c81d014bc59faf5e66095953b5\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.45\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 9955\n",
      "  time_since_restore: 3.0026144981384277\n",
      "  time_this_iter_s: 1.0005300045013428\n",
      "  time_total_s: 3.0026144981384277\n",
      "  timestamp: 1551074110\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_iris_tune_0_activation=relu,optimizer=adam:\n",
      "  checkpoint: 'weights_tune_{''optimizer'': ''adam'', ''activation'': ''relu''}.h5'\n",
      "  date: 2019-02-25_11-25-11\n",
      "  done: true\n",
      "  experiment_id: 3aae8497d0a04586b604e74d24398ce3\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.45\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 9958\n",
      "  time_since_restore: 4.0045082569122314\n",
      "  time_this_iter_s: 1.0014641284942627\n",
      "  time_total_s: 4.0045082569122314\n",
      "  timestamp: 1551074111\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 4/8 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 7.0/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "PENDING trials:\n",
      " - train_iris_tune_3_activation=sigmoid,optimizer=nadam:\tPENDING\n",
      "RUNNING trials:\n",
      " - train_iris_tune_2_activation=relu,optimizer=nadam:\tRUNNING\n",
      "TERMINATED trials:\n",
      " - train_iris_tune_0_activation=relu,optimizer=adam:\tTERMINATED [pid=9958], 4 s, 2 iter, 0.45 acc\n",
      " - train_iris_tune_1_activation=sigmoid,optimizer=adam:\tTERMINATED [pid=9955], 3 s, 2 iter, 0.45 acc\n",
      "\n",
      "Result for train_iris_tune_2_activation=relu,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''optimizer'': ''nadam'', ''activation'': ''relu''}.h5'\n",
      "  date: 2019-02-25_11-25-12\n",
      "  done: false\n",
      "  experiment_id: 9b12c49f3c94474c88d57818fe10026a\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.55\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 9960\n",
      "  time_since_restore: 1.0011799335479736\n",
      "  time_this_iter_s: 1.0011799335479736\n",
      "  time_total_s: 1.0011799335479736\n",
      "  timestamp: 1551074112\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_iris_tune_2_activation=relu,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''optimizer'': ''nadam'', ''activation'': ''relu''}.h5'\n",
      "  date: 2019-02-25_11-25-13\n",
      "  done: true\n",
      "  experiment_id: 9b12c49f3c94474c88d57818fe10026a\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.55\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 9960\n",
      "  time_since_restore: 2.0022482872009277\n",
      "  time_this_iter_s: 1.001068353652954\n",
      "  time_total_s: 2.0022482872009277\n",
      "  timestamp: 1551074113\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "Result for train_iris_tune_3_activation=sigmoid,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''optimizer'': ''nadam'', ''activation'': ''sigmoid''}.h5'\n",
      "  date: 2019-02-25_11-25-13\n",
      "  done: false\n",
      "  experiment_id: e38abc52f3fc4c1dbd9cdfbd4c6ff6b2\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.45\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 9954\n",
      "  time_since_restore: 1.0006685256958008\n",
      "  time_this_iter_s: 1.0006685256958008\n",
      "  time_total_s: 1.0006685256958008\n",
      "  timestamp: 1551074113\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  \n",
      "Result for train_iris_tune_3_activation=sigmoid,optimizer=nadam:\n",
      "  checkpoint: 'weights_tune_{''optimizer'': ''nadam'', ''activation'': ''sigmoid''}.h5'\n",
      "  date: 2019-02-25_11-25-14\n",
      "  done: true\n",
      "  experiment_id: e38abc52f3fc4c1dbd9cdfbd4c6ff6b2\n",
      "  hostname: shakkeel-TUF-GAMING-FX504GD-FX80GD\n",
      "  iterations_since_restore: 2\n",
      "  mean_accuracy: 0.45\n",
      "  node_ip: 192.168.1.4\n",
      "  pid: 9954\n",
      "  time_since_restore: 2.0018787384033203\n",
      "  time_this_iter_s: 1.0012102127075195\n",
      "  time_total_s: 2.0018787384033203\n",
      "  timestamp: 1551074114\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  \n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.8/8.2 GB\n",
      "Result logdir: /home/shakkeel/ray_results/experiment_name\n",
      "TERMINATED trials:\n",
      " - train_iris_tune_0_activation=relu,optimizer=adam:\tTERMINATED [pid=9958], 4 s, 2 iter, 0.45 acc\n",
      " - train_iris_tune_1_activation=sigmoid,optimizer=adam:\tTERMINATED [pid=9955], 3 s, 2 iter, 0.45 acc\n",
      " - train_iris_tune_2_activation=relu,optimizer=nadam:\tTERMINATED [pid=9960], 2 s, 2 iter, 0.55 acc\n",
      " - train_iris_tune_3_activation=sigmoid,optimizer=nadam:\tTERMINATED [pid=9954], 2 s, 2 iter, 0.45 acc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trials = tune.run_experiments(configuration, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'adam', 'activation': 'relu'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials[0].config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils from Tune #\n",
    "import os\n",
    "\n",
    "def get_best_trial(trial_list, metric):\n",
    "    \"\"\"Retrieve the best trial.\"\"\"\n",
    "    return max(trial_list, key=lambda trial: trial.last_result.get(metric, 0))\n",
    "\n",
    "def get_sorted_trials(trial_list, metric):\n",
    "    return sorted(trial_list, key=lambda trial: trial.last_result.get(metric, 0), reverse=True)\n",
    "\n",
    "\n",
    "def get_best_result(trial_list, metric):\n",
    "    \"\"\"Retrieve the last result from the best trial.\"\"\"\n",
    "    return {metric: get_best_trial(trial_list, metric).last_result[metric]}\n",
    "\n",
    "\n",
    "def get_best_model(model_creator, trial_list, metric):\n",
    "    \"\"\"Restore a model from the best trial.\"\"\"\n",
    "    sorted_trials = get_sorted_trials(trial_list, metric)\n",
    "    for best_trial in sorted_trials:\n",
    "        try:\n",
    "            print(\"Creating model...\")\n",
    "            model = model_creator(best_trial.config)\n",
    "            weights = os.path.join(best_trial.logdir, best_trial.last_result[\"checkpoint\"])\n",
    "            print(\"Loading from\", weights)\n",
    "            model.load_weights(weights)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Loading failed. Trying next model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_iris_tune_2_activation=relu,optimizer=nadam_2019-02-25_11-25-10h_29nt8m/weights_tune_{'optimizer': 'nadam', 'activation': 'relu'}.h5\n"
     ]
    }
   ],
   "source": [
    "# Get best model #\n",
    "final_model = get_best_model(make_model, trials, metric=\"mean_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.5333333373069763}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result = get_best_result(trials, metric=\"mean_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'events.out.tfevents.1551022839.shakkeel-TUF-GAMING-FX504GD-FX80GD.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-9d0194744034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'events.out.tfevents.1551022839.shakkeel-TUF-GAMING-FX504GD-FX80GD.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'events.out.tfevents.1551022839.shakkeel-TUF-GAMING-FX504GD-FX80GD.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "final_model.save_weights('test_weight_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_accuracy': 0.5333333373069763,\n",
       " 'done': True,\n",
       " 'timesteps_total': None,\n",
       " 'episodes_total': None,\n",
       " 'experiment_id': '582783da69934b25855ace6145ef9937',\n",
       " 'date': '2019-02-24_21-10-36',\n",
       " 'timestamp': 1551022836,\n",
       " 'training_iteration': 2,\n",
       " 'time_this_iter_s': 1.0006427764892578,\n",
       " 'time_total_s': 2.001708745956421,\n",
       " 'pid': 5566,\n",
       " 'hostname': 'shakkeel-TUF-GAMING-FX504GD-FX80GD',\n",
       " 'node_ip': '192.168.1.4',\n",
       " 'config': {'optimizer': 'adam', 'activation': 'relu'},\n",
       " 'time_since_restore': 2.001708745956421,\n",
       " 'timesteps_since_restore': 0,\n",
       " 'iterations_since_restore': 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials[0].last_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_trials = get_sorted_trials(trials, metric='mean_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/shakkeel/ray_results/experiment_name/train_iris_tune_0_activation=relu,optimizer=adam_2019-02-24_21-10-32txqiiqe4'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-24 21:50:05,379\tERROR worker.py:1632 -- The node with client ID fcae37c0a6177ae8267a4555f61db6161214821e has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    }
   ],
   "source": [
    "sorted_trials[0].logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.path.join('/home/shakkeel/ray_results/experiment_name/train_iris_tune_3_activation=sigmoid,optimizer=nadam_2019-02-24_17-42-01rtdbsg5p', 'events.out.tfevents.1551010324.shakkeel-TUF-GAMING-FX504GD-FX80GD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "Loading from /home/shakkeel/ray_results/experiment_name/train_iris_tune_3_activation=sigmoid,optimizer=nadam_2019-02-24_17-42-01rtdbsg5p/events.out.tfevents.1551010324.shakkeel-TUF-GAMING-FX504GD-FX80GD\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-902c45df4eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading from\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "print(\"Creating model...\")\n",
    "model = make_model(None)\n",
    "weights = path\n",
    "print(\"Loading from\", weights)\n",
    "model.load_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.6546545 ],\n",
       "        [0.47185266],\n",
       "        [0.24574947],\n",
       "        [0.19877207]], dtype=float32), array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weight_model = make_model(None)\n",
    "test_weight_model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Tune integration with IMLY(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakkeel/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.4413 - acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from imly import dope\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ray import tune\n",
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "\n",
    "url = \"../data/iris.csv\"\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.60, random_state=0)\n",
    "glm_1 = {\n",
    "    \"epochs\": tune.grid_search([100, 200]),\n",
    "    \"optimizer\": tune.grid_search([\"adam\", \"nadam\"])\n",
    "}\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.uniform(\"lr\", 0.001, 0.1),\n",
    "    'activation': hp.choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "}\n",
    "\n",
    "m = dope(LogisticRegression())\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wrappers.sklearn.keras_classifier.SklearnKerasClassifier at 0x7f51b06dde80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 653us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8833333373069763"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Keras MNIST Example')\n",
    "parser.add_argument('--lr', type=float, default=0.1, help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.0, help='SGD momentum')\n",
    "parser.add_argument('--kernel1', type=int, default=3, help='Size of first kernel')\n",
    "parser.add_argument('--kernel2', type=int, default=3, help='Size of second kernel')\n",
    "parser.add_argument('--poolsize', type=int, default=2, help='Size of Poolin')\n",
    "parser.add_argument('--dropout1', type=float, default=0.25, help='Size of first kernel')\n",
    "parser.add_argument('--hidden', type=int, default=4, help='Size of Hidden Layer')\n",
    "parser.add_argument('--dropout2', type=float, default=0.5, help='Size of first kernel')\n",
    "\n",
    "DEFAULT_ARGS = vars(parser.parse_known_args()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.1,\n",
       " 'momentum': 0.0,\n",
       " 'kernel1': 3,\n",
       " 'kernel2': 3,\n",
       " 'poolsize': 2,\n",
       " 'dropout1': 0.25,\n",
       " 'hidden': 4,\n",
       " 'dropout2': 0.5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-19 18:08:25,085\tERROR worker.py:1632 -- The node with client ID 5626a904d1847aa6a026fc204de5c26fb852e18b has been marked dead because the monitor has missed too many heartbeats from it.\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SklearnKerasClassifier' object has no attribute 'get_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4a6344f61237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SklearnKerasClassifier' object has no attribute 'get_config'"
     ]
    }
   ],
   "source": [
    "m.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Tune's compatibility with IMLY's Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "176/176 [==============================] - 0s 483us/step - loss: 1.0402 - acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from imly import dope\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ray import tune\n",
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "url = \"../data/diabetes.csv\"\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.60, random_state=0)\n",
    "glm_1 = {\n",
    "    \"epochs\": tune.grid_search([100, 200]),\n",
    "    \"optimizer\": tune.grid_search([\"adam\", \"nadam\"])\n",
    "}\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.uniform(\"lr\", 0.001, 0.1),\n",
    "    'activation': hp.choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "}\n",
    "\n",
    "m = dope(LinearRegression())\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 0s 91us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3672893154890018"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Hyperopt functionality #\n",
    "# WILL IT WORK WITHOUT THE HYPERBAND SCHEDULER? #\n",
    "from hyperopt import hp\n",
    "from ray.tune.suggest import HyperOptSearch\n",
    "\n",
    "space = {\n",
    "    \"lr\": hp.uniform(\"lr\", 0.001, 0.1),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.1, 0.9),\n",
    "    \"hidden\": hp.choice(\"hidden\", np.arange(16, 256, dtype=int)),\n",
    "}\n",
    "\n",
    "## TODO: CREATE A HyperOptObject\n",
    "hyperopt_search = HyperOptSearch(space, reward_attr=\"mean_accuracy\")\n",
    "\n",
    "## TODO: Pass in the object to Tune.\n",
    "good_results = tune.run_experiments(\n",
    "    configuration2, search_alg=hyperopt_search, scheduler=hyperband, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinearRegression'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "\n",
    "model_name = 'linear_regression'\n",
    "model_mappings = {\n",
    "    'linear_regression': 'LinearRegression',\n",
    "    'logistic_regression': 'LogisticRegression'\n",
    "}\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "for key, value in model_mappings.items():\n",
    "    if key == model_name:\n",
    "        name = value\n",
    "\n",
    "module = __import__('sklearn.linear_model', fromlist=[name])\n",
    "imported_module = getattr(module, name)\n",
    "model = imported_module\n",
    "\n",
    "primal_model = model()\n",
    "\n",
    "# Primal\n",
    "primal_model.fit(x_train, y_train)\n",
    "primal_model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "import experiment_automation_script\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "dataset_info = experiment_automation_script.get_dataset_info(\"diabetes\")\n",
    "url = \"../data/diabetes.csv\" if path.exists(\"../data/diabetes.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "# diabetes = datasets.load_diabetes()\n",
    "# sc = StandardScaler()\n",
    "# diabetes = sc.fit_transform(diabetes)\n",
    "#####\n",
    "# # Use only one feature\n",
    "# diabetes_X = diabetes.data\n",
    "# # sc = StandardScaler()\n",
    "# # diabetes.data = sc.fit_transform(diabetes.data)\n",
    "\n",
    "# X = diabetes.data\n",
    "# Y = diabetes.target\n",
    "#####\n",
    "\n",
    "# X = preprocessing.scale(X)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "# # Split the data into training/testing sets\n",
    "# x_train = diabetes_X[:-20]\n",
    "# x_test = diabetes_X[-20:]\n",
    "\n",
    "# # Split the targets into training/testing sets\n",
    "# y_train = diabetes.target[:-20]\n",
    "# y_test = diabetes.target[-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5481227216244245"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score = mean_squared_error(y_test, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x17f81a0aeb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm.__call__(param_name=\"log_reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import experiment_automation_script\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dataset_info = experiment_automation_script.get_dataset_info(\"diabetes\")\n",
    "url = \"../data/diabetes.csv\" if path.exists(\"../data/diabetes.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wrappers.sklearn.keras_classifier.SklearnKerasClassifier"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "wrapper_class = 'SklearnKerasClassifier'\n",
    "\n",
    "path = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', wrapper_class)\n",
    "module_path = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', path).lower()\n",
    "package_name = module_path.split('_')[0]\n",
    "wrapper_name = '_'.join(module_path.split('_')[1:3])\n",
    "\n",
    "module_path = 'wrappers.' + package_name + '.' + wrapper_name\n",
    "module_path\n",
    "wrapper_module = __import__(module_path, fromlist=[wrapper_class])\n",
    "function = getattr(wrapper_module, wrapper_class)\n",
    "function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = 'sklearn_keras_classifier'\n",
    "'_'.join(module_path.split('_')[1:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"../data/uci_carbon_nanotubes.csv\"\n",
    "data = pd.read_csv(url, delimiter=\";\")\n",
    "data\n",
    "# frames = [X, Y]\n",
    "# data = pd.concat(frames, axis=1)\n",
    "# data.to_csv('../data/uci_auto_mpg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras classifier chosen\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-463eefa48d20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# score = m.score(x_test, y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\MLSquare\\cook-imly\\imly\\wrappers\\sklearn\\keras_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x_train, y_train, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m                                                                        \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                                                                        \u001b[0mval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_metric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                                                                        metric=self.metric) \n\u001b[0m\u001b[0;32m     40\u001b[0m             self.model.fit(x_train, y_train, epochs=final_epoch,\n\u001b[0;32m     41\u001b[0m                            batch_size=final_batch_size, verbose=0)\n",
      "\u001b[1;32m~\\Desktop\\MLSquare\\cook-imly\\imly\\optimizers\\talos\\talos.py\u001b[0m in \u001b[0;36mget_best_model\u001b[1;34m(x_train, y_train, **kwargs)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mexperiment_no\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexperiment_no\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtalos_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 grid_downsample=0.5)\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\talos\\scan\\Scan.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, params, model, dataset_name, experiment_no, x_val, y_val, val_split, shuffle, round_limit, grid_downsample, random_method, seed, search_method, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, reduce_loss, last_epoch_value, clear_tf_session, disable_progress_bar, print_params, debug)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# input parameters section ends\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_null\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mruntime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\talos\\scan\\Scan.py\u001b[0m in \u001b[0;36mruntime\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mruntime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscan_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\talos\\scan\\scan_prepare.py\u001b[0m in \u001b[0;36mscan_prepare\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# create the data asset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     26\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[0;32m     27\u001b[0m           initial=_NoValue):\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "### Testing concordance ###\n",
    "\n",
    "from automation_script import get_dataset_info\n",
    "from imly import dope\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_info = get_dataset_info(\"uci_iris_lda\")\n",
    "url = dataset_info['url']\n",
    "data = pd.read_csv(url, delimiter=\",\", header=None, index_col=False)\n",
    "# sc = StandardScaler()\n",
    "# data = sc.fit_transform(data)\n",
    "# data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "\n",
    "m = dope(model)\n",
    "\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "m.fit(x_train, y_train)\n",
    "\n",
    "# score = m.score(x_test, y_test)\n",
    "\n",
    "\n",
    "### Automation script ###\n",
    "\n",
    "# params = {\n",
    "#     'epochs': 200\n",
    "# }\n",
    "\n",
    "# experiment_automation_script.dopify(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)\n",
    "sklearn_pred = model.predict(x_test)\n",
    "keras_pred = m.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989899125789394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.correlations import concordance_correlation_coefficient as ccc\n",
    "\n",
    "ccc(sklearn_pred, keras_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22704f6fb38>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.scatter(sklearn_pred, keras_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan Finished!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x261561d9358>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Testing CCC ###\n",
    "\n",
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from imly import dope\n",
    "\n",
    "dataset_name = \"uci_auto_mpg\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "data = pd.read_csv(\"../data/uci_auto_mpg.csv\", delimiter=\",\", header=0, index_col='car name')\n",
    "data = data[data.horsepower != '?']\n",
    "sc = StandardScaler()\n",
    "data = sc.fit_transform(data)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "Y = data.iloc[:,1]\n",
    "X = data.iloc[:,2:]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "m = dope(model)\n",
    "\n",
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "m.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)\n",
    "sklearn_pred = model.predict(x_test)\n",
    "keras_pred = m.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9894374129958334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.correlations import concordance_correlation_coefficient as ccc\n",
    "\n",
    "ccc(sklearn_pred, keras_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x26156618e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(sklearn_pred, keras_pred)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"../data/test2_pdf.pdf\", bbox_inches='tight') # write pdf to local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ../data/test_pdf.pdf to Amazon S3 bucket mlsquare-datasets\n",
      "..."
     ]
    }
   ],
   "source": [
    "### Test upload to AWS S3 ###\n",
    "import boto\n",
    "import sys\n",
    "from boto.s3.key import Key\n",
    "# from boto.s3.key import Key\n",
    "bucket_name = 'mlsquare-datasets'\n",
    "AWS_ACCESS_KEY_ID = 'AKIAJXRNK62PGFLPIJTA'\n",
    "AWS_SECRET_ACCESS_KEY = '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'\n",
    "REGION_HOST = 's3.ap-south-1.amazonaws.com'\n",
    "\n",
    "# bucket_name = AWS_ACCESS_KEY_ID.lower() + '-dump'\n",
    "conn = boto.connect_s3(AWS_ACCESS_KEY_ID,\n",
    "        AWS_SECRET_ACCESS_KEY, host=REGION_HOST)\n",
    "bucket = conn.get_bucket('mlsquare-pdf', validate=False)\n",
    "\n",
    "# bucket = conn.create_bucket(bucket_name,\n",
    "#     location=boto.s3.connection.Location.DEFAULT)\n",
    "\n",
    "testfile = \"../data/test_pdf.pdf\"\n",
    "print ('Uploading %s to Amazon S3 bucket %s' % (testfile, bucket_name))\n",
    "\n",
    "def percent_cb(complete, total):\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "k = Key(bucket)\n",
    "k.key = 'my test file'\n",
    "k.set_contents_from_filename(testfile,\n",
    "    cb=percent_cb, num_cb=10) # upload file\n",
    "url = k.generate_url(expires_in=0, query_auth=False) # get url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/uci_abalone_logistic.pdf'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'uci_abalone'\n",
    "algo = 'logistic'\n",
    "'../data/' + ('_').join([name,algo]) + '.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate datasets #\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)\n",
    "df = pd.concat([X, y], axis=1)\n",
    "# testData3 = np.concatenate((X,y), axis=1)\n",
    "# testData3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/testData4.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y type --  <class 'theano.tensor.var.TensorVariable'>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "40/40 [==============================] - 0s 449us/step - loss: -6.6398\n",
      "60/60 [==============================] - 0s 50us/step\n",
      "-5.562779839833578\n"
     ]
    }
   ],
   "source": [
    "### Testing Deep LDA implementation with Theano loss ###\n",
    "\n",
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_name = \"uci_iris\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "url = \"../data/iris.csv\" if path.exists(\"../data/iris.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "# params = {\n",
    "#     'epochs': 170\n",
    "# }\n",
    "\n",
    "# automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "\n",
    "## Create model ##\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "def create_model(input_dim, reg_par):\n",
    "    \"\"\"\n",
    "    Builds the model\n",
    "    The structure of the model can get easily substituted with a more efficient and powerful network like CNN\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(1, input_shape=(input_dim,), activation='sigmoid', kernel_regularizer=l2(reg_par)))\n",
    "#     model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(reg_par)))\n",
    "#     model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(reg_par)))\n",
    "#     model.add(Dense(2, activation='linear', kernel_regularizer=l2(reg_par))) \n",
    "#     outdim_size is passed via arguments\n",
    "\n",
    "    return model\n",
    "\n",
    "## Define loss function ##\n",
    "\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "from theano.compile.ops import as_op\n",
    "\n",
    "\n",
    "@as_op(itypes=[theano.tensor.ivector],  # Why? What is the need for such an op?\n",
    "       otypes=[theano.tensor.ivector])\n",
    "def numpy_unique(a):\n",
    "    return np.unique(a)\n",
    "\n",
    "\n",
    "def lda_loss(n_components, margin):\n",
    "    \"\"\"\n",
    "    The main loss function (inner_lda_objective) is wrapped in this function due to\n",
    "    the constraints imposed by Keras on objective functions\n",
    "    \"\"\"\n",
    "    def inner_lda_objective(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        It is the loss function of LDA as introduced in the original paper. \n",
    "        It is adopted from the the original implementation in the following link:\n",
    "        https://github.com/CPJKU/deep_lda\n",
    "        Note: it is implemented by Theano tensor operations, and does not work on Tensorflow backend\n",
    "        \"\"\"\n",
    "        r = 1e-4\n",
    "\n",
    "        # init groups\n",
    "        print('y type -- ',type(y_true))\n",
    "        yt = T.cast(y_true.flatten(), \"int32\")\n",
    "        groups = numpy_unique(yt)\n",
    "\n",
    "        def compute_cov(group, Xt, yt):\n",
    "            Xgt = Xt[T.eq(yt, group).nonzero()[0], :]\n",
    "            Xgt_bar = Xgt - T.mean(Xgt, axis=0)\n",
    "            m = T.cast(Xgt_bar.shape[0], 'float32')\n",
    "            return (1.0 / (m - 1)) * T.dot(Xgt_bar.T, Xgt_bar)\n",
    "\n",
    "        # scan over groups\n",
    "        covs_t, updates = theano.scan(fn=compute_cov, outputs_info=None,\n",
    "                                      sequences=[groups], non_sequences=[y_pred, yt])\n",
    "\n",
    "        # compute average covariance matrix (within scatter)\n",
    "        Sw_t = T.mean(covs_t, axis=0)\n",
    "\n",
    "        # compute total scatter\n",
    "        Xt_bar = y_pred - T.mean(y_pred, axis=0)\n",
    "        m = T.cast(Xt_bar.shape[0], 'float32')\n",
    "        St_t = (1.0 / (m - 1)) * T.dot(Xt_bar.T, Xt_bar)\n",
    "\n",
    "        # compute between scatter\n",
    "        Sb_t = St_t - Sw_t\n",
    "\n",
    "        # cope for numerical instability (regularize)\n",
    "        Sw_t += T.identity_like(Sw_t) * r\n",
    "\n",
    "        # return T.cast(T.neq(yt[0], -1), 'float32')*T.nlinalg.trace(T.dot(T.nlinalg.matrix_inverse(St_t), Sb_t))\n",
    "\n",
    "        # compute eigenvalues\n",
    "        evals_t = T.slinalg.eigvalsh(Sb_t, Sw_t)\n",
    "\n",
    "        # get eigenvalues\n",
    "        top_k_evals = evals_t[-n_components:]\n",
    "\n",
    "        # maximize variance between classes\n",
    "        # (k smallest eigenvalues below threshold)\n",
    "        thresh = T.min(top_k_evals) + margin\n",
    "        top_k_evals = top_k_evals[(top_k_evals <= thresh).nonzero()]\n",
    "        costs = T.mean(top_k_evals)\n",
    "\n",
    "        return -costs\n",
    "\n",
    "    return inner_lda_objective\n",
    "\n",
    "## Fit the model ##\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = create_model(x_train.shape[-1], reg_par=1e-5)\n",
    "\n",
    "model_optimizer = Adam()\n",
    "model.compile(loss=lda_loss(n_components=1, margin=1), optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lda_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c4fa72ce1ce2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlda_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lda_loss' is not defined"
     ]
    }
   ],
   "source": [
    "### Testing Keras with Theano backend ###\n",
    "\n",
    "import automation_script\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset_name = \"uci_iris\"\n",
    "dataset_info = automation_script.get_dataset_info(dataset_name)\n",
    "\n",
    "url = \"../data/iris.csv\" if path.exists(\"../data/iris.csv\") else dataset_info['url']\n",
    "data = pd.read_csv(url , delimiter=\",\", header=None, index_col=False)\n",
    "class_name,index = np.unique(data.iloc[:,-1],return_inverse=True)\n",
    "data.iloc[:,-1] = index\n",
    "data = data.loc[data[4] != 2]\n",
    "X = data.iloc[:,:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "# params = {\n",
    "#     'epochs': 170\n",
    "# }\n",
    "\n",
    "# automation_script.run_imly(dataset_info, 'logistic_regression', X, Y, 0.60, params=params)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.60, random_state=0)\n",
    "\n",
    "\n",
    "## Create model ##\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"\n",
    "    Builds the model\n",
    "    The structure of the model can get easily substituted with a more efficient and powerful network like CNN\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(1, input_shape=(4,), activation='sigmoid', kernel_regularizer=l2(1e-5))) \n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.compile(loss=lda_loss(n_components=1, margin=1), optimizer='adam')\n",
    "model.fit(x_train, y_train)\n",
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3719358722368876"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "247.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
